{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-fold_0923.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hui09241/10-fold/blob/master/10_fold_0923_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSDmYPM-NtrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f6c1338-6bb5-45cc-8201-71a13be5312f"
      },
      "source": [
        "!pip install pydrive\n",
        "!pip install scikit-learn==0.20.0\n",
        "!pip show scikit-learn # to see which version and where scikit-learn is installed\n",
        "!pip freeze # to see all packages installed in the active virtualenv\n",
        "\"import sklearn; sklearn.show_versions()\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.12)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (4.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (50.3.0)\n",
            "Requirement already satisfied: scikit-learn==0.20.0 in /usr/local/lib/python3.6/dist-packages (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.0) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.0) (1.4.1)\n",
            "Name: scikit-learn\n",
            "Version: 0.20.0\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: http://scikit-learn.org\n",
            "Author: None\n",
            "Author-email: None\n",
            "License: new BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: scipy, numpy\n",
            "Required-by: yellowbrick, umap-learn, textgenrnn, sklearn, sklearn-pandas, mlxtend, lucid, lightgbm, librosa, imbalanced-learn, fancyimpute\n",
            "absl-py==0.10.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "argon2-cffi==20.1.0\n",
            "asgiref==3.2.10\n",
            "astor==0.8.1\n",
            "astropy==4.0.1.post1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.4.0\n",
            "attrs==20.2.0\n",
            "audioread==2.1.8\n",
            "autograd==1.3\n",
            "Babel==2.8.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.2.0\n",
            "blis==0.4.1\n",
            "bokeh==2.1.1\n",
            "boto==2.49.0\n",
            "boto3==1.14.63\n",
            "botocore==1.17.63\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.1\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cachetools==4.1.1\n",
            "catalogue==1.0.0\n",
            "certifi==2020.6.20\n",
            "cffi==1.14.2\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.2.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.2.5\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.3\n",
            "Cython==0.29.21\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "dataclasses==0.7\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0rc2\n",
            "decorator==4.4.2\n",
            "defusedxml==0.6.0\n",
            "descartes==1.1.0\n",
            "dill==0.3.2\n",
            "distributed==1.25.3\n",
            "Django==3.1.1\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.5\n",
            "docopt==0.6.2\n",
            "docutils==0.15.2\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.235\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.5\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.2\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.3.3\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.3.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.16.0\n",
            "google-api-python-client==1.7.12\n",
            "google-auth==1.17.2\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.1\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.52.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "grpcio==1.32.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.2\n",
            "h5py==2.10.0\n",
            "HeapDict==1.0.1\n",
            "holidays==0.10.3\n",
            "holoviews==1.13.4\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "image==1.5.32\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==1.7.0\n",
            "imutils==0.5.3\n",
            "inflect==2.1.0\n",
            "iniconfig==1.0.1\n",
            "intel-openmp==2020.0.133\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.5.1\n",
            "itsdangerous==1.1.0\n",
            "jax==0.1.75\n",
            "jaxlib==0.1.52\n",
            "jdcal==1.4.1\n",
            "jedi==0.17.2\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.2\n",
            "jmespath==0.10.0\n",
            "joblib==0.16.0\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.6.3\n",
            "jupyterlab-pygments==0.1.1\n",
            "kaggle==1.5.8\n",
            "kapre==0.1.3.1\n",
            "Keras==2.4.3\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.2.0\n",
            "knnimpute==0.1.0\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.6.3\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.31.0\n",
            "lmdb==0.99\n",
            "lucid==0.3.8\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.2.2\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-venn==0.11.5\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.5.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.1.0\n",
            "msgpack==1.0.0\n",
            "multiprocess==0.70.10\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.2\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.0\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.0.7\n",
            "nest-asyncio==1.4.0\n",
            "networkx==2.5\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "np-utils==0.5.12.1\n",
            "numba==0.48.0\n",
            "numexpr==2.7.1\n",
            "numpy==1.18.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.1\n",
            "packaging==20.4\n",
            "palettable==3.3.0\n",
            "pandas==1.0.5\n",
            "pandas-datareader==0.8.1\n",
            "pandas-gbq==0.11.0\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.2\n",
            "panel==0.9.7\n",
            "param==1.9.3\n",
            "parso==0.7.1\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.0.0\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "portpicker==1.3.1\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.2\n",
            "prettytable==0.7.2\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.8.0\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.6.0\n",
            "py==1.9.0\n",
            "pyarrow==0.14.1\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.1.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "PyMeeus==0.3.7\n",
            "pymongo==3.11.0\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==1.6.5+ubuntu0.3\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.14\n",
            "python-slugify==4.0.1\n",
            "python-utils==2.4.0\n",
            "pytz==2018.9\n",
            "pyviz-comms==0.7.6\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==19.0.2\n",
            "qtconsole==4.7.7\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.2.7\n",
            "rsa==4.6\n",
            "s3transfer==0.3.3\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.20.0\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.2\n",
            "seaborn==0.10.1\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "slugify==0.0.1\n",
            "smart-open==2.1.1\n",
            "snowballstemmer==2.0.0\n",
            "sortedcontainers==2.2.2\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.3.19\n",
            "sqlparse==0.3.1\n",
            "srsly==1.0.2\n",
            "statsmodels==0.10.2\n",
            "sympy==1.1.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.7\n",
            "tblib==1.7.0\n",
            "tensorboard==2.3.0\n",
            "tensorboard-plugin-wit==1.7.0\n",
            "tensorboardcolab==0.0.22\n",
            "tensorflow==2.3.0\n",
            "tensorflow-addons==0.8.3\n",
            "tensorflow-datasets==2.1.0\n",
            "tensorflow-estimator==2.3.0\n",
            "tensorflow-gcs-config==2.3.0\n",
            "tensorflow-hub==0.9.0\n",
            "tensorflow-metadata==0.24.0\n",
            "tensorflow-privacy==0.2.2\n",
            "tensorflow-probability==0.11.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.8.3\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "Theano==1.0.5\n",
            "thinc==7.4.0\n",
            "tifffile==2020.9.3\n",
            "toml==0.10.1\n",
            "toolz==0.10.0\n",
            "torch==1.6.0+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.7.0+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==4.3.3\n",
            "tweepy==3.6.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.4.6\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.8.0\n",
            "wasabi==0.8.0\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.15.1\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import sklearn; sklearn.show_versions()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XwgjR5ZN43n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,BatchNormalization #這行milk02.ipynb\n",
        "from keras.layers import LSTM\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error  #02.ipynb\n",
        "\n",
        "import pandas as pd\n",
        "from pydrive.auth import GoogleAuth #雲端部分#載入資料用\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#把要one hot的類別轉換成數字                           #從這以下milk02.ipynb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#把要的類別轉換成one hot\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqCtCYmwN5Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##載入new_train\n",
        "auth.authenticate_user()                  \n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '11jLvYsp8RkDqZioXL5j2Qitx7C2lwM79'  #雲端硬碟檔案連結碼\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('our_new_train.csv')\n",
        "new_train = pd.read_csv('our_new_train.csv', sep=',')\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyggkcMtN6WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##載入new_test\n",
        "auth.authenticate_user()                  \n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '1pQC3R9smKnmsqQEU3BUoWVmEk7YRK5Io'  #雲端硬碟檔案連結碼\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('newtest17.csv')\n",
        "new_test = pd.read_csv('newtest17.csv', sep=',')\n",
        "#print(new_test.loc[[48]])\n",
        "#new_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-KC97dcN9aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        " \n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '1TgijKpsq6haP2C6yHsA7_bVtf5Ra6Cps'  #雲端硬碟檔案連結碼\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('spec01.csv')\n",
        "spec = pd.read_csv('spec01.csv',sep=',')\n",
        "#print(spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThqfMyyjN-ZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "933d9773-2182-4b8f-a2ec-0e336f33bef4"
      },
      "source": [
        "for i in range(len(spec['7'])):\n",
        "    if(str(spec['7'][i])==str(\"A\")):\n",
        "          spec['7'][i]=1\n",
        "for i in range(len(spec['7'])):\n",
        "    if(str(spec['7'][i])==str('B')):\n",
        "          spec['7'][i]=2\n",
        "for i in range(len(spec['7'])):\n",
        "    if(str(spec['7'][i])==str('C')):\n",
        "          spec['7'][i]=3\n",
        "#spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_NhTrl2N_pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#測試spec\n",
        "#spec.loc[[4290]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2AFW8tOBhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','DadID','BabyNum','FeedDay','Milk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSpOBcEvOD_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_test=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','DadID','BabyNum','FeedDay','Milk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "#new_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT3FI164OFUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5af1e7b8-0f16-42ff-80a3-eb0c75075027"
      },
      "source": [
        "new_train['Milk']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        20.0\n",
              "1        43.0\n",
              "2        24.0\n",
              "3        18.2\n",
              "4        10.0\n",
              "         ... \n",
              "30009    24.0\n",
              "30010    20.4\n",
              "30011    19.0\n",
              "30012     NaN\n",
              "30013    25.5\n",
              "Name: Milk, Length: 30014, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn9JLnEuOHe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e1622da9-a72c-43f6-821d-fb72a93e0011"
      },
      "source": [
        "import math\n",
        "bool = False\n",
        "for i in range(len(new_train['Milk'])):\n",
        "    bool = False\n",
        "    bool=math.isnan(new_train['Milk'][i])\n",
        "    if(bool):\n",
        "       new_train['Milk'][i]=0\n",
        "#print(new_train['Milk'].loc[[15]])\n",
        "#print(new_train['Milk'].loc[[16]])\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps8su1as-4vL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "297c769a-8a07-4e40-9f1f-ca73139845e7"
      },
      "source": [
        "import math\n",
        "bool = False\n",
        "for i in range(len(new_test['Milk'])):\n",
        "    bool = False\n",
        "    bool=math.isnan(new_test['Milk'][i])\n",
        "    if(bool):\n",
        "       new_test['Milk'][i]=0\n",
        "#print(new_train['Milk'].loc[[15]])\n",
        "#print(new_test['Milk'].loc[[9]])\n",
        "#new_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqcFWInXOIi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train有不需要判斷的編號就去掉\n",
        "for i in range(len(new_test['CowID'])):\n",
        "    if len(new_train.index[new_train['CowID'] == new_test['CowID'][i]]) == 0:\n",
        "        new_train=new_train.drop([i])\n",
        "new_train.reset_index(inplace=True)\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu1pgHrQktaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train牛乳產量是0，則丟棄不用\n",
        "for i in range(len(new_train['Milk'])): \n",
        "    if new_train['Milk'][i] == 0 :\n",
        "        new_train = new_train.drop([i])\n",
        "new_train.reset_index(inplace=True)\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0K7p113_B8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "d02e9776-dba3-48cc-b7ed-5c9970d25723"
      },
      "source": [
        "#test牛乳產量是0，則丟棄不用(未來測試需要)\n",
        "for i in range(len(new_test['Milk'])): \n",
        "    if new_test['Milk'][i] == 0 :\n",
        "        new_test = new_test.drop([i])\n",
        "new_test.reset_index(inplace=True)\n",
        "print(new_test['Milk'].loc[[9]])\n",
        "new_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9    11.6\n",
            "Name: Milk, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ID</th>\n",
              "      <th>firm</th>\n",
              "      <th>CowID</th>\n",
              "      <th>MomID</th>\n",
              "      <th>DadID</th>\n",
              "      <th>BabyNum</th>\n",
              "      <th>FeedDay</th>\n",
              "      <th>Milk</th>\n",
              "      <th>Sampling date</th>\n",
              "      <th>Age</th>\n",
              "      <th>BreedNum</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>T Max</th>\n",
              "      <th>RH</th>\n",
              "      <th>RHMin</th>\n",
              "      <th>Precp</th>\n",
              "      <th>THI</th>\n",
              "      <th>cycle</th>\n",
              "      <th>tcalving number</th>\n",
              "      <th>disease</th>\n",
              "      <th>Sampling D Year</th>\n",
              "      <th>Sampling D Month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18072</td>\n",
              "      <td>2</td>\n",
              "      <td>122630</td>\n",
              "      <td>98111436.0</td>\n",
              "      <td>007HO08361</td>\n",
              "      <td>3</td>\n",
              "      <td>183</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2017/1/19</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>20.8</td>\n",
              "      <td>25.5</td>\n",
              "      <td>85.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.236278</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15357</td>\n",
              "      <td>2</td>\n",
              "      <td>2122398</td>\n",
              "      <td>98111423.0</td>\n",
              "      <td>7H7536</td>\n",
              "      <td>3</td>\n",
              "      <td>71</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2017/7/18</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>37069</td>\n",
              "      <td>3</td>\n",
              "      <td>99183211</td>\n",
              "      <td>94172172.0</td>\n",
              "      <td>1H8328</td>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2013/6/25</td>\n",
              "      <td>38</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17574</td>\n",
              "      <td>2</td>\n",
              "      <td>122607</td>\n",
              "      <td>98115809.0</td>\n",
              "      <td>029HO11295</td>\n",
              "      <td>4</td>\n",
              "      <td>177</td>\n",
              "      <td>35.0</td>\n",
              "      <td>2017/3/20</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>24.3</td>\n",
              "      <td>29.1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.221440</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3256</td>\n",
              "      <td>1</td>\n",
              "      <td>1051850</td>\n",
              "      <td>96040547.0</td>\n",
              "      <td>7H9502</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>28.8</td>\n",
              "      <td>2015/2/5</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>71.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>10.980262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6678</th>\n",
              "      <td>7496</td>\n",
              "      <td>11987</td>\n",
              "      <td>2</td>\n",
              "      <td>1123347</td>\n",
              "      <td>99116307.0</td>\n",
              "      <td>7H8361</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2015/8/20</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>34.9</td>\n",
              "      <td>82.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.323086</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6679</th>\n",
              "      <td>7497</td>\n",
              "      <td>23863</td>\n",
              "      <td>2</td>\n",
              "      <td>99127667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200H1715</td>\n",
              "      <td>2</td>\n",
              "      <td>508</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2014/7/21</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>31.5</td>\n",
              "      <td>34.8</td>\n",
              "      <td>72.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.814617</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6680</th>\n",
              "      <td>7498</td>\n",
              "      <td>24192</td>\n",
              "      <td>2</td>\n",
              "      <td>97124147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7H6155</td>\n",
              "      <td>3</td>\n",
              "      <td>158</td>\n",
              "      <td>30.6</td>\n",
              "      <td>2013/5/27</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>29.3</td>\n",
              "      <td>34.4</td>\n",
              "      <td>75.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.200232</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6681</th>\n",
              "      <td>7500</td>\n",
              "      <td>14623</td>\n",
              "      <td>2</td>\n",
              "      <td>2122364</td>\n",
              "      <td>95110600.0</td>\n",
              "      <td>29H10124</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2014/12/25</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>16.9</td>\n",
              "      <td>19.5</td>\n",
              "      <td>80.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>16.578618</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6682</th>\n",
              "      <td>7501</td>\n",
              "      <td>27986</td>\n",
              "      <td>2</td>\n",
              "      <td>4123090</td>\n",
              "      <td>2111107.0</td>\n",
              "      <td>501HO2611</td>\n",
              "      <td>1</td>\n",
              "      <td>204</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2018/4/18</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>21.7</td>\n",
              "      <td>25.9</td>\n",
              "      <td>72.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.509629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6683 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index     ID  firm  ...  disease  Sampling D Year Sampling D Month\n",
              "0         0  18072     2  ...      NaN              NaN              NaN\n",
              "1         1  15357     2  ...      NaN              NaN              NaN\n",
              "2         2  37069     3  ...      NaN              NaN              NaN\n",
              "3         3  17574     2  ...      NaN              NaN              NaN\n",
              "4         4   3256     1  ...      NaN              NaN              NaN\n",
              "...     ...    ...   ...  ...      ...              ...              ...\n",
              "6678   7496  11987     2  ...      NaN              NaN              NaN\n",
              "6679   7497  23863     2  ...      NaN              NaN              NaN\n",
              "6680   7498  24192     2  ...      NaN              NaN              NaN\n",
              "6681   7500  14623     2  ...      NaN              NaN              NaN\n",
              "6682   7501  27986     2  ...      NaN              NaN              NaN\n",
              "\n",
              "[6683 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53GcIgqFOMh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#處理new_train的\n",
        "#父親精液編號 \n",
        "new_train['DadID']=new_train['DadID'].fillna(\"NoData\").astype(\"str\")\n",
        "\n",
        "#將MomID中沒有編號的打為NoData \n",
        "new_train['MomID']=new_train['MomID'].fillna(\"NoData\").astype(\"str\")\n",
        "\n",
        "avg_Temperature_tr=new_train['Temperature'].mean() #將平均溫度Nan部分以算術平均數之平均溫度取代\n",
        "new_train['Temperature']= new_train['Temperature'].fillna(avg_Temperature_tr)\n",
        "\n",
        "\n",
        "avg_T_Max_tr=new_train['T Max'].mean()          #將最高溫度Nan部分以算術平均數之最高溫度取代\n",
        "new_train['T Max']= new_train['T Max'].fillna(avg_T_Max_tr)\n",
        "\n",
        "\n",
        "avg_RH_tr=new_train['RH'].mean()                  #將相對濕度Nan部分以算術平均數之相對濕度取代\n",
        "new_train['RH']= new_train['RH'].fillna(avg_RH_tr)\n",
        "\n",
        "\n",
        "avg_RH_Min_tr=new_train['RHMin'].mean()         #將最小相對濕度Nan部分以算術平均數之最小相對濕度取代\n",
        "new_train['RHMin']= new_train['RHMin'].fillna(avg_RH_Min_tr)\n",
        "\n",
        "\n",
        "avg_Precp_tr=new_train['Precp'].mean()          #將降水量Nan部分以算術平均數之降水量取代\n",
        "new_train['Precp']= new_train['Precp'].fillna(avg_Precp_tr)\n",
        "\n",
        "avg_THI_tr=new_train['THI'].mean()          #將THI Nan部分以算術平均數之THI取代\n",
        "new_train['THI']= new_train['THI'].fillna(avg_THI_tr)\n",
        "\n",
        "new_train.dropna(subset=['FeedDay','DadID','MomID'], inplace=True)\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRuXAuAOOOKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#處理new_test的\n",
        "#父親精液編號\n",
        "new_test['DadID']=new_test['DadID'].fillna(\"NoData\").astype(\"str\")\n",
        "\n",
        "#將MomID中沒有編號的打為NoData \n",
        "new_test['MomID']=new_test['MomID'].fillna(\"NoData\").astype(\"str\")\n",
        "\n",
        "avg_Temperature=new_test['Temperature'].mean() #將平均溫度Nan部分以算術平均數之平均溫度取代\n",
        "new_test['Temperature']= new_test['Temperature'].fillna(avg_Temperature)\n",
        "\n",
        "\n",
        "avg_T_Max=new_test['T Max'].mean()          #將最高溫度Nan部分以算術平均數之最高溫度取代\n",
        "new_test['T Max']= new_test['T Max'].fillna(avg_T_Max)\n",
        "\n",
        "\n",
        "avg_RH=new_test['RH'].mean()                  #將相對濕度Nan部分以算術平均數之相對濕度取代\n",
        "new_test['RH']= new_test['RH'].fillna(avg_RH)\n",
        "\n",
        "\n",
        "avg_RH_Min=new_test['RHMin'].mean()         #將最小相對濕度Nan部分以算術平均數之最小相對濕度取代\n",
        "new_test['RHMin']= new_test['RHMin'].fillna(avg_RH_Min)\n",
        "\n",
        "\n",
        "avg_Precp=new_test['Precp'].mean()          #將降水量Nan部分以算術平均數之降水量取代\n",
        "new_test['Precp']= new_test['Precp'].fillna(avg_Precp)\n",
        "\n",
        "avg_THI=new_test['THI'].mean()          #將THI Nan部分以算術平均數之THI取代\n",
        "new_test['THI']= new_test['THI'].fillna(avg_THI)\n",
        "#\n",
        "#new_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WTevp9ROPdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b5131ac8-e772-4f50-c3a9-e92c70a22ce1"
      },
      "source": [
        "from datetime import datetime\n",
        "for i in range(len(new_train['Sampling date'])):\n",
        "          sdate=datetime.strptime(new_train['Sampling date'][i], \"%Y/%m/%d\")\n",
        "          new_train['Sampling D Year'][i]= sdate.year\n",
        "          new_train['Sampling D Month'][i]= sdate.month\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7wu_JFEOQz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bdc84251-dab9-4703-9a9b-649cf672b798"
      },
      "source": [
        "for i in range(len(new_test['Sampling date'])):\n",
        "          sdate=datetime.strptime(new_test['Sampling date'][i], \"%Y/%m/%d\")\n",
        "          new_test['Sampling D Year'][i]= sdate.year\n",
        "          new_test['Sampling D Month'][i]= sdate.month\n",
        "#new_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0UXtTi9OSHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "85006257-2a36-4fe1-96aa-d1bf87bdfc4d"
      },
      "source": [
        "#new_train把當月有病的標記起來(為1)\n",
        "for i in range(len(spec)):\n",
        "    dd=datetime.strptime(spec['4'][i], \"%Y/%m/%d %H:%M\")\n",
        "    if len(new_train.index[new_train['CowID'] == spec['1'][i]])>0:\n",
        "        for j in new_train.index[new_train['CowID'] == spec['1'][i]]:\n",
        "            if new_train['Sampling D Year'][j] == dd.year and new_train['Sampling D Month'][j] == dd.month and new_train['firm'][j]==spec['7'][i]:\n",
        "                new_train['disease'][j] = 1\n",
        "                #print(j,new_train['CowID'][j],new_train['Sampling D Year'][j],new_train['Sampling D Month'][j])\n",
        "\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BN-ljceOTSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3376aa74-42cc-4a42-8f20-91cf2a6e61bc"
      },
      "source": [
        "#new_test把當月有病的標記起來(為1)\n",
        "for i in range(len(spec)):\n",
        "    dd=datetime.strptime(spec['4'][i], \"%Y/%m/%d %H:%M\")\n",
        "    if len(new_test.index[new_test['CowID'] == spec['1'][i]])>0:\n",
        "        for j in new_test.index[new_test['CowID'] == spec['1'][i]]:\n",
        "            if new_test['Sampling D Year'][j] == dd.year and new_test['Sampling D Month'][j] == dd.month and new_test['firm'][j]==spec['7'][i]:\n",
        "                new_test['disease'][j] = 1\n",
        "                #print(j,new_test['CowID'][j],new_test['Sampling D Year'][j],new_test['Sampling D Month'][j])\n",
        "\n",
        "#new_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ZFaMLuOUlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train=new_train.fillna(0)\n",
        "new_test=new_test.fillna(0)\n",
        "new_train.reset_index(inplace=True,drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R_oe_o6OVAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Kz5jCdOWEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a0127e21-a89a-4328-d47a-d784c916f149"
      },
      "source": [
        "#改new_train\n",
        "i=0\n",
        "for i in range(len(new_train['Sampling D Month'])):\n",
        "          if int(new_train['Sampling D Month'][i]) >=3 and int(new_train['Sampling D Month'][i])<=5:\n",
        "              new_train['Sampling D Month'][i] = \"Spring\"\n",
        "          elif int(new_train['Sampling D Month'][i]) >=6 and int(new_train['Sampling D Month'][i])<=8:\n",
        "              new_train['Sampling D Month'][i] = \"Summer\"\n",
        "          elif int(new_train['Sampling D Month'][i]) >=9 and int(new_train['Sampling D Month'][i])<=11:\n",
        "              new_train['Sampling D Month'][i] = \"Autumn\"\n",
        "          else:\n",
        "              new_train['Sampling D Month'][i] = \"Winter\"   \n",
        "#改new_train的feedday以及babynum\n",
        "for i in range(len(new_train['ID'])):\n",
        "    if int(new_train['FeedDay'][i]) <=100:\n",
        "        new_train['cycle'][i] = 0\n",
        "    elif int(new_train['FeedDay'][i]) >=101 and int(new_train['FeedDay'][i]) <=200 :\n",
        "        new_train['cycle'][i] = 1\n",
        "    elif int(new_train['FeedDay'][i]) >=201 and int(new_train['FeedDay'][i]) <=305:\n",
        "        new_train['cycle'][i] = 2\n",
        "    else:\n",
        "        new_train['cycle'][i] = 3\n",
        "\n",
        "    if int(new_train['BabyNum'][i]) <=2:\n",
        "        new_train['tcalving number'][i] = 0\n",
        "    elif int(new_train['BabyNum'][i])>=7:\n",
        "        new_train['tcalving number'][i] = 2\n",
        "    else:\n",
        "        new_train['tcalving number'][i] = 1\n",
        "\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XtSP6BZOXm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "04b4783b-6bdb-4488-85dd-35ac66e5c758"
      },
      "source": [
        "#改new_test\n",
        "i=0\n",
        "for i in range(len(new_test['Sampling D Month'])):\n",
        "          if int(new_test['Sampling D Month'][i]) >=3 and int(new_test['Sampling D Month'][i])<=5:\n",
        "              new_test['Sampling D Month'][i] = \"Spring\"\n",
        "          elif int(new_test['Sampling D Month'][i]) >=6 and int(new_test['Sampling D Month'][i])<=8:\n",
        "              new_test['Sampling D Month'][i] = \"Summer\"\n",
        "          elif int(new_test['Sampling D Month'][i]) >=9 and int(new_test['Sampling D Month'][i])<=11:\n",
        "              new_test['Sampling D Month'][i] = \"Autumn\"\n",
        "          else:\n",
        "              new_test['Sampling D Month'][i] = \"Winter\"\n",
        "#改new_test的feedday以及babynum\n",
        "for i in range(len(new_test['ID'])):\n",
        "    if int(new_test['FeedDay'][i]) <=100:\n",
        "        new_test['cycle'][i] = 0\n",
        "    elif int(new_train['FeedDay'][i]) >=101 and int(new_test['FeedDay'][i]) <=200 :\n",
        "        new_test['cycle'][i] = 1\n",
        "    elif int(new_test['FeedDay'][i]) >=201 and int(new_test['FeedDay'][i]) <=305:\n",
        "        new_test['cycle'][i] = 2\n",
        "    else:\n",
        "        new_test['cycle'][i] = 2\n",
        "    if int(new_test['BabyNum'][i]) <=2:\n",
        "        new_test['tcalving number'][i] = 0\n",
        "    elif int(new_test['BabyNum'][i])>=7:\n",
        "        new_test['tcalving number'][i] = 2\n",
        "    else:\n",
        "        new_test['tcalving number'][i] = 1    \n",
        "#new_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeHtnt4bOZVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train=new_train.fillna(0)\n",
        "new_test=new_test.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AqMIEL3ObQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##測試為毛y_test會有0的部分 ，勿管\n",
        "new_train_backup01 = new_train\n",
        "new_train_backup01\n",
        "y__tt=pd.DataFrame(data=new_train_backup01,columns=['ID','Milk'])\n",
        "#y__tt\n",
        "#print(y__tt.loc[[3427]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plSzSFvf_ONi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "343ed219-5eef-4c79-855e-3d01cd57e3dd"
      },
      "source": [
        "y_fortest=new_test['Milk']\n",
        "y_fortest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       40.0\n",
              "1       28.0\n",
              "2       12.0\n",
              "3       35.0\n",
              "4       28.8\n",
              "        ... \n",
              "6678    39.0\n",
              "6679    10.0\n",
              "6680    30.6\n",
              "6681    20.0\n",
              "6682    16.0\n",
              "Name: Milk, Length: 6683, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTpeS-6SOcbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cf990050-3793-4e30-9502-d24f6d11ef76"
      },
      "source": [
        "y=new_train['Milk']\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        20.0\n",
              "1        43.0\n",
              "2        24.0\n",
              "3        18.2\n",
              "4        10.0\n",
              "         ... \n",
              "26475    33.0\n",
              "26476    24.0\n",
              "26477    20.4\n",
              "26478    19.0\n",
              "26479    25.5\n",
              "Name: Milk, Length: 26480, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPbRPuTxhDlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "savefornew_train01=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test01=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train02=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test02=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train03=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test03=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train04=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test04=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train05=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test05=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train06=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test06=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train07=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test07=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train08=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test08=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train09=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test09=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "\n",
        "savefornew_train10=pd.DataFrame(data=new_train,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])\n",
        "savefornew_test10=pd.DataFrame(data=new_test,columns=['ID','firm','CowID','MomID','BabyNum','FeedDay','Milk','preMilk','Sampling date','Age','BreedNum','Temperature','T Max','RH','RHMin','Precp','THI','cycle','tcalving number','disease','Sampling D Year','Sampling D Month'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPuuyTrmOfty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train_backup = new_train\n",
        "new_test_backup = new_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooFKIIeGOg8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#挑選靠賽要訓練的資料\n",
        "new_train=pd.DataFrame(data=new_train_backup,columns=['firm','CowID','BabyNum','FeedDay','Age','BreedNum','T Max','THI','disease','Sampling D Month'])\n",
        "#new_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLzp7n4uOha1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_test=pd.DataFrame(data=new_test_backup,columns=['firm','CowID','BabyNum','FeedDay','Age','BreedNum','T Max','THI','disease','Sampling D Month'])\n",
        "#new_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNTI_rKoOigv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#把要one hot的類別轉換成數字\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "all_data=pd.concat([new_train,new_test])\n",
        "#all_data['3'] = labelencoder.fit_transform(all_data['3'])\n",
        "all_data['CowID'] = labelencoder.fit_transform(all_data['CowID'])\n",
        "#all_data['MomID'] = labelencoder.fit_transform(all_data['MomID'])\n",
        "#all_data['DadID'] = labelencoder.fit_transform(all_data['DadID'])\n",
        "all_data['Sampling D Month'] = labelencoder.fit_transform(all_data['Sampling D Month'])\n",
        "new_train = all_data[0:len(new_train)]\n",
        "new_test = all_data[len(new_train)::]\n",
        "all_data=pd.concat([new_train,new_test])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPvPGadmOj6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c94a8544-852d-4532-e5ba-3268ca6ed99b"
      },
      "source": [
        "all_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>firm</th>\n",
              "      <th>CowID</th>\n",
              "      <th>BabyNum</th>\n",
              "      <th>FeedDay</th>\n",
              "      <th>Age</th>\n",
              "      <th>BreedNum</th>\n",
              "      <th>T Max</th>\n",
              "      <th>THI</th>\n",
              "      <th>disease</th>\n",
              "      <th>Sampling D Month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>728</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>27.826169</td>\n",
              "      <td>22.850519</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>736</td>\n",
              "      <td>2</td>\n",
              "      <td>62</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>34.900000</td>\n",
              "      <td>27.093337</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>781</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>23.800000</td>\n",
              "      <td>21.498437</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>388</td>\n",
              "      <td>2</td>\n",
              "      <td>290</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>12.100133</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>189</td>\n",
              "      <td>2</td>\n",
              "      <td>156</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>17.597478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6678</th>\n",
              "      <td>2</td>\n",
              "      <td>280</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>34.900000</td>\n",
              "      <td>29.323086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6679</th>\n",
              "      <td>2</td>\n",
              "      <td>1790</td>\n",
              "      <td>2</td>\n",
              "      <td>508</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>34.800000</td>\n",
              "      <td>28.814617</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6680</th>\n",
              "      <td>2</td>\n",
              "      <td>1555</td>\n",
              "      <td>3</td>\n",
              "      <td>158</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>34.400000</td>\n",
              "      <td>27.200232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6681</th>\n",
              "      <td>2</td>\n",
              "      <td>466</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>16.578618</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6682</th>\n",
              "      <td>2</td>\n",
              "      <td>980</td>\n",
              "      <td>1</td>\n",
              "      <td>204</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>25.900000</td>\n",
              "      <td>20.509629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33163 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      firm  CowID  BabyNum  ...        THI  disease  Sampling D Month\n",
              "0        2    728        1  ...  22.850519      1.0                 2\n",
              "1        2    736        2  ...  27.093337      0.0                 1\n",
              "2        2    781        1  ...  21.498437      0.0                 0\n",
              "3        1    388        2  ...  12.100133      0.0                 1\n",
              "4        2    189        2  ...  17.597478      0.0                 3\n",
              "...    ...    ...      ...  ...        ...      ...               ...\n",
              "6678     2    280        3  ...  29.323086      0.0                 2\n",
              "6679     2   1790        2  ...  28.814617      0.0                 2\n",
              "6680     2   1555        3  ...  27.200232      0.0                 1\n",
              "6681     2    466        1  ...  16.578618      1.0                 3\n",
              "6682     2    980        1  ...  20.509629      0.0                 1\n",
              "\n",
              "[33163 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "majAv8pDFqO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "67300b85-eb21-4a66-92d3-3ac1100f7d56"
      },
      "source": [
        "#把要的類別轉換成one hot\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(categorical_features =[0,1,2,5,8,9])#6\n",
        "enc.fit(all_data)\n",
        "X=enc.transform(new_train).toarray()\n",
        "X_test=enc.transform(new_test).toarray()\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26480, 1858)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVHWkLJgH7wH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb79af9b-a9b8-4707-94cc-0e029ef74ae9"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6683, 1858)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StuiAXygddR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8af60b1e-b830-49f6-e61b-72869442f9b2"
      },
      "source": [
        "new_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>firm</th>\n",
              "      <th>CowID</th>\n",
              "      <th>BabyNum</th>\n",
              "      <th>FeedDay</th>\n",
              "      <th>Age</th>\n",
              "      <th>BreedNum</th>\n",
              "      <th>T Max</th>\n",
              "      <th>THI</th>\n",
              "      <th>disease</th>\n",
              "      <th>Sampling D Month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>96</td>\n",
              "      <td>3</td>\n",
              "      <td>183</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>25.500000</td>\n",
              "      <td>20.236278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>494</td>\n",
              "      <td>3</td>\n",
              "      <td>71</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>35.200000</td>\n",
              "      <td>22.838761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1817</td>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "      <td>38</td>\n",
              "      <td>5</td>\n",
              "      <td>27.808703</td>\n",
              "      <td>22.838761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>4</td>\n",
              "      <td>177</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>29.100000</td>\n",
              "      <td>23.221440</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>250</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>10.980262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6678</th>\n",
              "      <td>2</td>\n",
              "      <td>280</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>34.900000</td>\n",
              "      <td>29.323086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6679</th>\n",
              "      <td>2</td>\n",
              "      <td>1790</td>\n",
              "      <td>2</td>\n",
              "      <td>508</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>34.800000</td>\n",
              "      <td>28.814617</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6680</th>\n",
              "      <td>2</td>\n",
              "      <td>1555</td>\n",
              "      <td>3</td>\n",
              "      <td>158</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>34.400000</td>\n",
              "      <td>27.200232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6681</th>\n",
              "      <td>2</td>\n",
              "      <td>466</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>16.578618</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6682</th>\n",
              "      <td>2</td>\n",
              "      <td>980</td>\n",
              "      <td>1</td>\n",
              "      <td>204</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>25.900000</td>\n",
              "      <td>20.509629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6683 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      firm  CowID  BabyNum  ...        THI  disease  Sampling D Month\n",
              "0        2     96        3  ...  20.236278      0.0                 3\n",
              "1        2    494        3  ...  22.838761      0.0                 2\n",
              "2        3   1817        1  ...  22.838761      0.0                 2\n",
              "3        2     76        4  ...  23.221440      0.0                 1\n",
              "4        1    250        1  ...  10.980262      0.0                 3\n",
              "...    ...    ...      ...  ...        ...      ...               ...\n",
              "6678     2    280        3  ...  29.323086      0.0                 2\n",
              "6679     2   1790        2  ...  28.814617      0.0                 2\n",
              "6680     2   1555        3  ...  27.200232      0.0                 1\n",
              "6681     2    466        1  ...  16.578618      1.0                 3\n",
              "6682     2    980        1  ...  20.509629      0.0                 1\n",
              "\n",
              "[6683 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnfAbfP0GfCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ae72cb90-efb0-48c3-c6a5-6a8959e7a428"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  1.        ,  0.        , ..., 30.        ,\n",
              "        27.82616918, 22.85051932],\n",
              "       [ 0.        ,  1.        ,  0.        , ..., 38.        ,\n",
              "        34.9       , 27.09333711],\n",
              "       [ 0.        ,  1.        ,  0.        , ..., 27.        ,\n",
              "        23.8       , 21.4984371 ],\n",
              "       ...,\n",
              "       [ 0.        ,  1.        ,  0.        , ..., 26.        ,\n",
              "        16.2       , 13.40103018],\n",
              "       [ 1.        ,  0.        ,  0.        , ..., 34.        ,\n",
              "        34.1       , 26.27994148],\n",
              "       [ 1.        ,  0.        ,  0.        , ..., 70.        ,\n",
              "        33.8       , 26.86139404]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZaaNOl2OpGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X=X.values\n",
        "X = X.astype('float32')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(X)\n",
        "#y=y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWd6pyJkSIA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c83c1b48-f65d-499c-f093-0340af3afa3e"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 1.        , 0.        , ..., 0.18867923, 0.61618984,\n",
              "        0.6523535 ],\n",
              "       [0.        , 1.        , 0.        , ..., 0.2389937 , 0.8338462 ,\n",
              "        0.82666194],\n",
              "       [0.        , 1.        , 0.        , ..., 0.16981131, 0.49230766,\n",
              "        0.5968058 ],\n",
              "       ...,\n",
              "       [0.        , 1.        , 0.        , ..., 0.163522  , 0.25846156,\n",
              "        0.26413873],\n",
              "       [1.        , 0.        , 0.        , ..., 0.21383648, 0.8092307 ,\n",
              "        0.7932451 ],\n",
              "       [1.        , 0.        , 0.        , ..., 0.44025156, 0.79999995,\n",
              "        0.81713307]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC0MD2pFPXuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_test=X_test.values\n",
        "X_test=X_test.astype('float32')\n",
        "X_test=scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfeCtS4-ICTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0f642e4-3c15-44ee-aeef-4c254399e0ec"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6683, 1858)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSyiOY3H-iGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test= np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znchq0qU3sPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9ca8876-10a3-480c-c0ed-6a02703349f0"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6683, 1, 1858)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnkk7bxDO89G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def rmse(y_pred, y_true):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj00-1KuKE1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18dbd0de-71b5-40b8-e687-80e267065913"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras import regularizers\n",
        "from matplotlib import pyplot\n",
        "from keras import optimizers\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Embedding, Bidirectional,TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from numpy import ndarray\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "time=1\n",
        "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "for train_index, test_index in cv.split(X):\n",
        "    x_train, x_test =X[train_index], X[test_index],\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    print(\"Please show me the shape of x_train:\",x_train.shape)\n",
        "    print(\"Please show me the shape of x_test:\",x_test.shape)\n",
        "    print(\"Please show me the shape of y_train:\",y_train.shape)\n",
        "    print(\"Please show me the shape of y_test:\",y_test.shape)\n",
        "\n",
        "    print(\"y_test:\") #看每次y_test一不一樣\n",
        "    print(y_test)\n",
        "\n",
        "    x_train = np.reshape(x_train,(x_train.shape[0],1,x_train.shape[1]))#做成三維\n",
        "    x_test = np.reshape(x_test,(x_test.shape[0],1,x_test.shape[1]))\n",
        "\n",
        "    model = Sequential()#LSTM\n",
        "    model.add(LSTM(64, input_shape=(1,x_train.shape[2])))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    ADAM=keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "    model.compile(loss=rmse, optimizer=ADAM,metrics=[rmse])\n",
        "    early_stopping=EarlyStopping(monitor='val_loss', patience=10)\n",
        "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
        "    history=model.fit(x_train, y_train, epochs=500,validation_data=(x_test, y_test), batch_size=5, verbose=2, callbacks=[early_stopping])#epochs要改回1000\n",
        "\n",
        "    Predicts = model.predict(x_train)#TrainRMSE\n",
        "    testScore = math.sqrt(mean_squared_error(y_train, Predicts))\n",
        "    print('Train Score: %.2f RMSE' % (testScore))\n",
        "    \n",
        "\n",
        "    Predict = model.predict(x_test)#TestRMSE\n",
        "    testScore = math.sqrt(mean_squared_error(y_test, Predict))\n",
        "    print('Validation Score: %.2f RMSE' % (testScore))\n",
        "    #print(Predict)\n",
        "\n",
        "    Prediction = model.predict(X_test)\n",
        "    Prediction\n",
        "    testScore = math.sqrt(mean_squared_error(y_fortest, Prediction))\n",
        "    print('Test Score: %.2f RMSE' % (testScore))\n",
        "\n",
        "    if time == 1:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train01['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train01['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test01['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "      \n",
        "      print(savefornew_train01)\n",
        "\n",
        "    elif time == 2:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train02['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train02['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test02['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "\n",
        "      print(savefornew_train02)\n",
        "\n",
        "    elif time == 3:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train03['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train03['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test03['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    elif time == 4:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train04['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train04['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test04['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    elif time == 5:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train05['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train05['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test05['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    elif time == 6:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train06['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train06['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test06['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    elif time == 7:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train07['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train07['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test07['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    elif time == 8:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train08['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train08['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test08['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    elif time == 9:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train09['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train09['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test09['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    elif time == 7:\n",
        "      i=0\n",
        "      for i in range(len(y_train)):\n",
        "        savefornew_train10['preMilk'][y_train.index[i]]=Predicts[i]\n",
        "      i=0\n",
        "      for i in range(len(y_test)):\n",
        "        savefornew_train10['preMilk'][y_test.index[i]]=Predict[i]\n",
        "      i=0\n",
        "      for i in range(len(y_fortest)):\n",
        "        savefornew_test10['preMilk'][y_fortest.index[i]]=Prediction[i]\n",
        "    time=time+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "6        15.4\n",
            "17       25.0\n",
            "34       23.0\n",
            "35       17.0\n",
            "52       28.0\n",
            "         ... \n",
            "26388    19.9\n",
            "26428    34.0\n",
            "26436    17.0\n",
            "26437    16.0\n",
            "26448    17.2\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 22s - loss: 8.9134 - rmse: 8.9137 - val_loss: 6.5702 - val_rmse: 6.5701\n",
            "Epoch 2/500\n",
            "4767/4767 - 19s - loss: 6.9605 - rmse: 6.9603 - val_loss: 6.0142 - val_rmse: 6.0146\n",
            "Epoch 3/500\n",
            "4767/4767 - 19s - loss: 6.4275 - rmse: 6.4279 - val_loss: 5.5945 - val_rmse: 5.5946\n",
            "Epoch 4/500\n",
            "4767/4767 - 19s - loss: 6.1016 - rmse: 6.1015 - val_loss: 5.3876 - val_rmse: 5.3874\n",
            "Epoch 5/500\n",
            "4767/4767 - 21s - loss: 5.9076 - rmse: 5.9070 - val_loss: 5.2481 - val_rmse: 5.2489\n",
            "Epoch 6/500\n",
            "4767/4767 - 19s - loss: 5.7997 - rmse: 5.7997 - val_loss: 5.2323 - val_rmse: 5.2333\n",
            "Epoch 7/500\n",
            "4767/4767 - 19s - loss: 5.7441 - rmse: 5.7434 - val_loss: 5.1473 - val_rmse: 5.1469\n",
            "Epoch 8/500\n",
            "4767/4767 - 19s - loss: 5.6324 - rmse: 5.6328 - val_loss: 5.0648 - val_rmse: 5.0646\n",
            "Epoch 9/500\n",
            "4767/4767 - 19s - loss: 5.5880 - rmse: 5.5890 - val_loss: 5.0404 - val_rmse: 5.0397\n",
            "Epoch 10/500\n",
            "4767/4767 - 19s - loss: 5.5194 - rmse: 5.5192 - val_loss: 5.0346 - val_rmse: 5.0340\n",
            "Epoch 11/500\n",
            "4767/4767 - 19s - loss: 5.4693 - rmse: 5.4693 - val_loss: 4.9810 - val_rmse: 4.9805\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.4630 - rmse: 5.4630 - val_loss: 4.9389 - val_rmse: 4.9384\n",
            "Epoch 13/500\n",
            "4767/4767 - 20s - loss: 5.3807 - rmse: 5.3805 - val_loss: 4.9236 - val_rmse: 4.9232\n",
            "Epoch 14/500\n",
            "4767/4767 - 21s - loss: 5.2780 - rmse: 5.2780 - val_loss: 4.9059 - val_rmse: 4.9049\n",
            "Epoch 15/500\n",
            "4767/4767 - 19s - loss: 5.2849 - rmse: 5.2848 - val_loss: 4.8791 - val_rmse: 4.8789\n",
            "Epoch 16/500\n",
            "4767/4767 - 19s - loss: 5.2267 - rmse: 5.2264 - val_loss: 4.8472 - val_rmse: 4.8466\n",
            "Epoch 17/500\n",
            "4767/4767 - 23s - loss: 5.1585 - rmse: 5.1581 - val_loss: 4.8067 - val_rmse: 4.8064\n",
            "Epoch 18/500\n",
            "4767/4767 - 20s - loss: 5.1258 - rmse: 5.1254 - val_loss: 4.8259 - val_rmse: 4.8261\n",
            "Epoch 19/500\n",
            "4767/4767 - 20s - loss: 5.0846 - rmse: 5.0841 - val_loss: 4.7635 - val_rmse: 4.7632\n",
            "Epoch 20/500\n",
            "4767/4767 - 21s - loss: 5.0470 - rmse: 5.0468 - val_loss: 4.7617 - val_rmse: 4.7615\n",
            "Epoch 21/500\n",
            "4767/4767 - 19s - loss: 5.0164 - rmse: 5.0162 - val_loss: 4.7269 - val_rmse: 4.7265\n",
            "Epoch 22/500\n",
            "4767/4767 - 19s - loss: 4.9627 - rmse: 4.9621 - val_loss: 4.7135 - val_rmse: 4.7129\n",
            "Epoch 23/500\n",
            "4767/4767 - 19s - loss: 4.8814 - rmse: 4.8815 - val_loss: 4.6719 - val_rmse: 4.6715\n",
            "Epoch 24/500\n",
            "4767/4767 - 20s - loss: 4.8545 - rmse: 4.8546 - val_loss: 4.6750 - val_rmse: 4.6748\n",
            "Epoch 25/500\n",
            "4767/4767 - 20s - loss: 4.8257 - rmse: 4.8254 - val_loss: 4.6682 - val_rmse: 4.6677\n",
            "Epoch 26/500\n",
            "4767/4767 - 19s - loss: 4.7654 - rmse: 4.7655 - val_loss: 4.6956 - val_rmse: 4.6949\n",
            "Epoch 27/500\n",
            "4767/4767 - 19s - loss: 4.7562 - rmse: 4.7560 - val_loss: 4.6736 - val_rmse: 4.6737\n",
            "Epoch 28/500\n",
            "4767/4767 - 19s - loss: 4.6749 - rmse: 4.6762 - val_loss: 4.6294 - val_rmse: 4.6291\n",
            "Epoch 29/500\n",
            "4767/4767 - 19s - loss: 4.6913 - rmse: 4.6911 - val_loss: 4.6064 - val_rmse: 4.6057\n",
            "Epoch 30/500\n",
            "4767/4767 - 19s - loss: 4.6195 - rmse: 4.6193 - val_loss: 4.6081 - val_rmse: 4.6073\n",
            "Epoch 31/500\n",
            "4767/4767 - 19s - loss: 4.5840 - rmse: 4.5835 - val_loss: 4.5751 - val_rmse: 4.5746\n",
            "Epoch 32/500\n",
            "4767/4767 - 19s - loss: 4.5541 - rmse: 4.5544 - val_loss: 4.5759 - val_rmse: 4.5754\n",
            "Epoch 33/500\n",
            "4767/4767 - 21s - loss: 4.4994 - rmse: 4.4991 - val_loss: 4.5546 - val_rmse: 4.5541\n",
            "Epoch 34/500\n",
            "4767/4767 - 23s - loss: 4.4840 - rmse: 4.4838 - val_loss: 4.5276 - val_rmse: 4.5272\n",
            "Epoch 35/500\n",
            "4767/4767 - 20s - loss: 4.4295 - rmse: 4.4295 - val_loss: 4.5279 - val_rmse: 4.5275\n",
            "Epoch 36/500\n",
            "4767/4767 - 21s - loss: 4.4125 - rmse: 4.4122 - val_loss: 4.5334 - val_rmse: 4.5327\n",
            "Epoch 37/500\n",
            "4767/4767 - 19s - loss: 4.3942 - rmse: 4.3938 - val_loss: 4.5010 - val_rmse: 4.5004\n",
            "Epoch 38/500\n",
            "4767/4767 - 19s - loss: 4.3442 - rmse: 4.3442 - val_loss: 4.4888 - val_rmse: 4.4888\n",
            "Epoch 39/500\n",
            "4767/4767 - 19s - loss: 4.3259 - rmse: 4.3256 - val_loss: 4.4865 - val_rmse: 4.4870\n",
            "Epoch 40/500\n",
            "4767/4767 - 19s - loss: 4.2729 - rmse: 4.2728 - val_loss: 4.4725 - val_rmse: 4.4726\n",
            "Epoch 41/500\n",
            "4767/4767 - 19s - loss: 4.2819 - rmse: 4.2822 - val_loss: 4.4789 - val_rmse: 4.4788\n",
            "Epoch 42/500\n",
            "4767/4767 - 19s - loss: 4.2324 - rmse: 4.2325 - val_loss: 4.4692 - val_rmse: 4.4690\n",
            "Epoch 43/500\n",
            "4767/4767 - 20s - loss: 4.2290 - rmse: 4.2288 - val_loss: 4.4586 - val_rmse: 4.4587\n",
            "Epoch 44/500\n",
            "4767/4767 - 21s - loss: 4.1730 - rmse: 4.1727 - val_loss: 4.4493 - val_rmse: 4.4494\n",
            "Epoch 45/500\n",
            "4767/4767 - 20s - loss: 4.1885 - rmse: 4.1886 - val_loss: 4.4499 - val_rmse: 4.4497\n",
            "Epoch 46/500\n",
            "4767/4767 - 19s - loss: 4.1289 - rmse: 4.1286 - val_loss: 4.4521 - val_rmse: 4.4523\n",
            "Epoch 47/500\n",
            "4767/4767 - 19s - loss: 4.1105 - rmse: 4.1106 - val_loss: 4.4361 - val_rmse: 4.4359\n",
            "Epoch 48/500\n",
            "4767/4767 - 19s - loss: 4.0676 - rmse: 4.0676 - val_loss: 4.4367 - val_rmse: 4.4364\n",
            "Epoch 49/500\n",
            "4767/4767 - 19s - loss: 4.0635 - rmse: 4.0636 - val_loss: 4.4390 - val_rmse: 4.4387\n",
            "Epoch 50/500\n",
            "4767/4767 - 23s - loss: 4.0454 - rmse: 4.0454 - val_loss: 4.4054 - val_rmse: 4.4052\n",
            "Epoch 51/500\n",
            "4767/4767 - 20s - loss: 4.0156 - rmse: 4.0154 - val_loss: 4.3977 - val_rmse: 4.3979\n",
            "Epoch 52/500\n",
            "4767/4767 - 20s - loss: 4.0222 - rmse: 4.0221 - val_loss: 4.3930 - val_rmse: 4.3936\n",
            "Epoch 53/500\n",
            "4767/4767 - 20s - loss: 3.9635 - rmse: 3.9636 - val_loss: 4.3794 - val_rmse: 4.3793\n",
            "Epoch 54/500\n",
            "4767/4767 - 19s - loss: 3.9622 - rmse: 3.9622 - val_loss: 4.3650 - val_rmse: 4.3648\n",
            "Epoch 55/500\n",
            "4767/4767 - 20s - loss: 3.9265 - rmse: 3.9266 - val_loss: 4.3850 - val_rmse: 4.3851\n",
            "Epoch 56/500\n",
            "4767/4767 - 20s - loss: 3.9421 - rmse: 3.9419 - val_loss: 4.3907 - val_rmse: 4.3911\n",
            "Epoch 57/500\n",
            "4767/4767 - 20s - loss: 3.9041 - rmse: 3.9042 - val_loss: 4.3664 - val_rmse: 4.3663\n",
            "Epoch 58/500\n",
            "4767/4767 - 21s - loss: 3.8993 - rmse: 3.8994 - val_loss: 4.3700 - val_rmse: 4.3700\n",
            "Epoch 59/500\n",
            "4767/4767 - 20s - loss: 3.8605 - rmse: 3.8607 - val_loss: 4.3758 - val_rmse: 4.3759\n",
            "Epoch 60/500\n",
            "4767/4767 - 19s - loss: 3.8538 - rmse: 3.8541 - val_loss: 4.3735 - val_rmse: 4.3735\n",
            "Epoch 61/500\n",
            "4767/4767 - 20s - loss: 3.8458 - rmse: 3.8456 - val_loss: 4.3722 - val_rmse: 4.3722\n",
            "Epoch 62/500\n",
            "4767/4767 - 20s - loss: 3.8276 - rmse: 3.8278 - val_loss: 4.4164 - val_rmse: 4.4166\n",
            "Epoch 63/500\n",
            "4767/4767 - 19s - loss: 3.8080 - rmse: 3.8078 - val_loss: 4.3879 - val_rmse: 4.3874\n",
            "Epoch 64/500\n",
            "4767/4767 - 19s - loss: 3.7771 - rmse: 3.7770 - val_loss: 4.3599 - val_rmse: 4.3601\n",
            "Epoch 65/500\n",
            "4767/4767 - 20s - loss: 3.7646 - rmse: 3.7642 - val_loss: 4.3485 - val_rmse: 4.3483\n",
            "Epoch 66/500\n",
            "4767/4767 - 23s - loss: 3.7443 - rmse: 3.7442 - val_loss: 4.3405 - val_rmse: 4.3407\n",
            "Epoch 67/500\n",
            "4767/4767 - 23s - loss: 3.7616 - rmse: 3.7613 - val_loss: 4.3669 - val_rmse: 4.3670\n",
            "Epoch 68/500\n",
            "4767/4767 - 19s - loss: 3.7454 - rmse: 3.7452 - val_loss: 4.3783 - val_rmse: 4.3787\n",
            "Epoch 69/500\n",
            "4767/4767 - 19s - loss: 3.7018 - rmse: 3.7023 - val_loss: 4.3609 - val_rmse: 4.3609\n",
            "Epoch 70/500\n",
            "4767/4767 - 20s - loss: 3.7265 - rmse: 3.7265 - val_loss: 4.3871 - val_rmse: 4.3875\n",
            "Epoch 71/500\n",
            "4767/4767 - 20s - loss: 3.7116 - rmse: 3.7113 - val_loss: 4.3511 - val_rmse: 4.3513\n",
            "Epoch 72/500\n",
            "4767/4767 - 19s - loss: 3.6875 - rmse: 3.6874 - val_loss: 4.3389 - val_rmse: 4.3392\n",
            "Epoch 73/500\n",
            "4767/4767 - 19s - loss: 3.6805 - rmse: 3.6810 - val_loss: 4.3412 - val_rmse: 4.3413\n",
            "Epoch 74/500\n",
            "4767/4767 - 19s - loss: 3.6829 - rmse: 3.6832 - val_loss: 4.3453 - val_rmse: 4.3452\n",
            "Epoch 75/500\n",
            "4767/4767 - 22s - loss: 3.6564 - rmse: 3.6567 - val_loss: 4.3469 - val_rmse: 4.3470\n",
            "Epoch 76/500\n",
            "4767/4767 - 19s - loss: 3.6330 - rmse: 3.6327 - val_loss: 4.3513 - val_rmse: 4.3512\n",
            "Epoch 77/500\n",
            "4767/4767 - 19s - loss: 3.6389 - rmse: 3.6389 - val_loss: 4.3437 - val_rmse: 4.3441\n",
            "Epoch 78/500\n",
            "4767/4767 - 20s - loss: 3.6284 - rmse: 3.6280 - val_loss: 4.3561 - val_rmse: 4.3563\n",
            "Epoch 79/500\n",
            "4767/4767 - 21s - loss: 3.6071 - rmse: 3.6069 - val_loss: 4.3628 - val_rmse: 4.3632\n",
            "Epoch 80/500\n",
            "4767/4767 - 21s - loss: 3.5972 - rmse: 3.5972 - val_loss: 4.3474 - val_rmse: 4.3476\n",
            "Epoch 81/500\n",
            "4767/4767 - 21s - loss: 3.6007 - rmse: 3.6004 - val_loss: 4.3587 - val_rmse: 4.3589\n",
            "Epoch 82/500\n",
            "4767/4767 - 30s - loss: 3.5957 - rmse: 3.5957 - val_loss: 4.3689 - val_rmse: 4.3692\n",
            "Train Score: 3.46 RMSE\n",
            "Validation Score: 4.83 RMSE\n",
            "Test Score: 4.94 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "          ID  firm     CowID  ... disease  Sampling D Year  Sampling D Month\n",
            "0      10806     2   3126105  ...     1.0           2016.0            Summer\n",
            "1      10950     2   3126118  ...     0.0           2017.0            Spring\n",
            "2      30007     2   3126179  ...     0.0           2016.0            Autumn\n",
            "3       2137     1   2052011  ...     0.0           2018.0            Spring\n",
            "4      20955     2    127993  ...     0.0           2016.0            Winter\n",
            "...      ...   ...       ...  ...     ...              ...               ...\n",
            "26475  15392     2   2122400  ...     0.0           2018.0            Spring\n",
            "26476  25883     2  10837415  ...     0.0           2018.0            Autumn\n",
            "26477  19848     2    124308  ...     0.0           2013.0            Winter\n",
            "26478   3360     1   1051856  ...     0.0           2015.0            Summer\n",
            "26479   6626     1  96051858  ...     0.0           2013.0            Summer\n",
            "\n",
            "[26480 rows x 22 columns]\n",
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "29       36.0\n",
            "30       22.0\n",
            "44       16.0\n",
            "46       25.0\n",
            "54       35.0\n",
            "         ... \n",
            "26445    19.5\n",
            "26449    22.5\n",
            "26450    29.6\n",
            "26463    31.8\n",
            "26465    19.2\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 21s - loss: 8.8916 - rmse: 8.8908 - val_loss: 6.7452 - val_rmse: 6.7429\n",
            "Epoch 2/500\n",
            "4767/4767 - 20s - loss: 6.9304 - rmse: 6.9296 - val_loss: 6.2253 - val_rmse: 6.2229\n",
            "Epoch 3/500\n",
            "4767/4767 - 20s - loss: 6.4247 - rmse: 6.4244 - val_loss: 5.8789 - val_rmse: 5.8768\n",
            "Epoch 4/500\n",
            "4767/4767 - 20s - loss: 6.0982 - rmse: 6.0982 - val_loss: 5.6719 - val_rmse: 5.6701\n",
            "Epoch 5/500\n",
            "4767/4767 - 20s - loss: 5.8875 - rmse: 5.8875 - val_loss: 5.5244 - val_rmse: 5.5228\n",
            "Epoch 6/500\n",
            "4767/4767 - 19s - loss: 5.7963 - rmse: 5.7972 - val_loss: 5.4196 - val_rmse: 5.4179\n",
            "Epoch 7/500\n",
            "4767/4767 - 20s - loss: 5.7409 - rmse: 5.7406 - val_loss: 5.3718 - val_rmse: 5.3701\n",
            "Epoch 8/500\n",
            "4767/4767 - 20s - loss: 5.6107 - rmse: 5.6107 - val_loss: 5.3914 - val_rmse: 5.3898\n",
            "Epoch 9/500\n",
            "4767/4767 - 19s - loss: 5.5470 - rmse: 5.5476 - val_loss: 5.2493 - val_rmse: 5.2471\n",
            "Epoch 10/500\n",
            "4767/4767 - 20s - loss: 5.5311 - rmse: 5.5308 - val_loss: 5.2336 - val_rmse: 5.2315\n",
            "Epoch 11/500\n",
            "4767/4767 - 20s - loss: 5.4471 - rmse: 5.4472 - val_loss: 5.2247 - val_rmse: 5.2226\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.3945 - rmse: 5.3944 - val_loss: 5.1495 - val_rmse: 5.1475\n",
            "Epoch 13/500\n",
            "4767/4767 - 19s - loss: 5.3166 - rmse: 5.3163 - val_loss: 5.0921 - val_rmse: 5.0899\n",
            "Epoch 14/500\n",
            "4767/4767 - 19s - loss: 5.2813 - rmse: 5.2809 - val_loss: 5.0817 - val_rmse: 5.0793\n",
            "Epoch 15/500\n",
            "4767/4767 - 21s - loss: 5.2349 - rmse: 5.2346 - val_loss: 5.1358 - val_rmse: 5.1335\n",
            "Epoch 16/500\n",
            "4767/4767 - 23s - loss: 5.2204 - rmse: 5.2203 - val_loss: 5.1156 - val_rmse: 5.1131\n",
            "Epoch 17/500\n",
            "4767/4767 - 20s - loss: 5.1505 - rmse: 5.1507 - val_loss: 4.9846 - val_rmse: 4.9825\n",
            "Epoch 18/500\n",
            "4767/4767 - 20s - loss: 5.0928 - rmse: 5.0927 - val_loss: 5.0630 - val_rmse: 5.0607\n",
            "Epoch 19/500\n",
            "4767/4767 - 20s - loss: 5.0491 - rmse: 5.0488 - val_loss: 4.9432 - val_rmse: 4.9404\n",
            "Epoch 20/500\n",
            "4767/4767 - 20s - loss: 5.0131 - rmse: 5.0127 - val_loss: 4.9264 - val_rmse: 4.9238\n",
            "Epoch 21/500\n",
            "4767/4767 - 20s - loss: 4.9704 - rmse: 4.9716 - val_loss: 4.9619 - val_rmse: 4.9592\n",
            "Epoch 22/500\n",
            "4767/4767 - 20s - loss: 4.9501 - rmse: 4.9499 - val_loss: 4.8947 - val_rmse: 4.8923\n",
            "Epoch 23/500\n",
            "4767/4767 - 22s - loss: 4.9141 - rmse: 4.9137 - val_loss: 4.8988 - val_rmse: 4.8963\n",
            "Epoch 24/500\n",
            "4767/4767 - 19s - loss: 4.8716 - rmse: 4.8714 - val_loss: 4.8618 - val_rmse: 4.8592\n",
            "Epoch 25/500\n",
            "4767/4767 - 20s - loss: 4.8013 - rmse: 4.8019 - val_loss: 4.8236 - val_rmse: 4.8216\n",
            "Epoch 26/500\n",
            "4767/4767 - 20s - loss: 4.7877 - rmse: 4.7879 - val_loss: 4.8022 - val_rmse: 4.8001\n",
            "Epoch 27/500\n",
            "4767/4767 - 20s - loss: 4.7514 - rmse: 4.7517 - val_loss: 4.8800 - val_rmse: 4.8783\n",
            "Epoch 28/500\n",
            "4767/4767 - 20s - loss: 4.6838 - rmse: 4.6834 - val_loss: 4.7546 - val_rmse: 4.7527\n",
            "Epoch 29/500\n",
            "4767/4767 - 20s - loss: 4.6541 - rmse: 4.6546 - val_loss: 4.7659 - val_rmse: 4.7640\n",
            "Epoch 30/500\n",
            "4767/4767 - 20s - loss: 4.6248 - rmse: 4.6244 - val_loss: 4.7382 - val_rmse: 4.7366\n",
            "Epoch 31/500\n",
            "4767/4767 - 22s - loss: 4.6147 - rmse: 4.6146 - val_loss: 4.7367 - val_rmse: 4.7346\n",
            "Epoch 32/500\n",
            "4767/4767 - 25s - loss: 4.5580 - rmse: 4.5580 - val_loss: 4.6647 - val_rmse: 4.6633\n",
            "Epoch 33/500\n",
            "4767/4767 - 20s - loss: 4.4913 - rmse: 4.4915 - val_loss: 4.6637 - val_rmse: 4.6623\n",
            "Epoch 34/500\n",
            "4767/4767 - 20s - loss: 4.4861 - rmse: 4.4860 - val_loss: 4.6470 - val_rmse: 4.6452\n",
            "Epoch 35/500\n",
            "4767/4767 - 20s - loss: 4.4755 - rmse: 4.4752 - val_loss: 4.6758 - val_rmse: 4.6742\n",
            "Epoch 36/500\n",
            "4767/4767 - 20s - loss: 4.4235 - rmse: 4.4237 - val_loss: 4.6215 - val_rmse: 4.6197\n",
            "Epoch 37/500\n",
            "4767/4767 - 21s - loss: 4.4066 - rmse: 4.4062 - val_loss: 4.6125 - val_rmse: 4.6109\n",
            "Epoch 38/500\n",
            "4767/4767 - 21s - loss: 4.3147 - rmse: 4.3142 - val_loss: 4.7286 - val_rmse: 4.7271\n",
            "Epoch 39/500\n",
            "4767/4767 - 21s - loss: 4.3136 - rmse: 4.3134 - val_loss: 4.5639 - val_rmse: 4.5626\n",
            "Epoch 40/500\n",
            "4767/4767 - 21s - loss: 4.3106 - rmse: 4.3103 - val_loss: 4.5663 - val_rmse: 4.5647\n",
            "Epoch 41/500\n",
            "4767/4767 - 20s - loss: 4.2561 - rmse: 4.2560 - val_loss: 4.5435 - val_rmse: 4.5424\n",
            "Epoch 42/500\n",
            "4767/4767 - 20s - loss: 4.2581 - rmse: 4.2580 - val_loss: 4.5700 - val_rmse: 4.5690\n",
            "Epoch 43/500\n",
            "4767/4767 - 21s - loss: 4.2073 - rmse: 4.2074 - val_loss: 4.5595 - val_rmse: 4.5582\n",
            "Epoch 44/500\n",
            "4767/4767 - 20s - loss: 4.1920 - rmse: 4.1924 - val_loss: 4.4901 - val_rmse: 4.4891\n",
            "Epoch 45/500\n",
            "4767/4767 - 22s - loss: 4.1679 - rmse: 4.1680 - val_loss: 4.4987 - val_rmse: 4.4979\n",
            "Epoch 46/500\n",
            "4767/4767 - 21s - loss: 4.1562 - rmse: 4.1577 - val_loss: 4.4842 - val_rmse: 4.4837\n",
            "Epoch 47/500\n",
            "4767/4767 - 23s - loss: 4.1085 - rmse: 4.1086 - val_loss: 4.4647 - val_rmse: 4.4640\n",
            "Epoch 48/500\n",
            "4767/4767 - 22s - loss: 4.1092 - rmse: 4.1092 - val_loss: 4.4528 - val_rmse: 4.4526\n",
            "Epoch 49/500\n",
            "4767/4767 - 21s - loss: 4.0723 - rmse: 4.0725 - val_loss: 4.4885 - val_rmse: 4.4881\n",
            "Epoch 50/500\n",
            "4767/4767 - 20s - loss: 4.0327 - rmse: 4.0326 - val_loss: 4.4586 - val_rmse: 4.4583\n",
            "Epoch 51/500\n",
            "4767/4767 - 20s - loss: 4.0579 - rmse: 4.0581 - val_loss: 4.4375 - val_rmse: 4.4370\n",
            "Epoch 52/500\n",
            "4767/4767 - 22s - loss: 4.0122 - rmse: 4.0117 - val_loss: 4.5179 - val_rmse: 4.5175\n",
            "Epoch 53/500\n",
            "4767/4767 - 20s - loss: 3.9903 - rmse: 3.9909 - val_loss: 4.4690 - val_rmse: 4.4685\n",
            "Epoch 54/500\n",
            "4767/4767 - 20s - loss: 3.9877 - rmse: 3.9876 - val_loss: 4.4680 - val_rmse: 4.4674\n",
            "Epoch 55/500\n",
            "4767/4767 - 20s - loss: 3.9480 - rmse: 3.9485 - val_loss: 4.4099 - val_rmse: 4.4095\n",
            "Epoch 56/500\n",
            "4767/4767 - 20s - loss: 3.9317 - rmse: 3.9321 - val_loss: 4.4282 - val_rmse: 4.4278\n",
            "Epoch 57/500\n",
            "4767/4767 - 20s - loss: 3.9099 - rmse: 3.9096 - val_loss: 4.4097 - val_rmse: 4.4094\n",
            "Epoch 58/500\n",
            "4767/4767 - 20s - loss: 3.9140 - rmse: 3.9138 - val_loss: 4.3964 - val_rmse: 4.3960\n",
            "Epoch 59/500\n",
            "4767/4767 - 20s - loss: 3.8871 - rmse: 3.8868 - val_loss: 4.4055 - val_rmse: 4.4054\n",
            "Epoch 60/500\n",
            "4767/4767 - 21s - loss: 3.8688 - rmse: 3.8686 - val_loss: 4.3953 - val_rmse: 4.3951\n",
            "Epoch 61/500\n",
            "4767/4767 - 20s - loss: 3.8434 - rmse: 3.8432 - val_loss: 4.4529 - val_rmse: 4.4524\n",
            "Epoch 62/500\n",
            "4767/4767 - 20s - loss: 3.8200 - rmse: 3.8200 - val_loss: 4.3938 - val_rmse: 4.3937\n",
            "Epoch 63/500\n",
            "4767/4767 - 24s - loss: 3.8090 - rmse: 3.8087 - val_loss: 4.4782 - val_rmse: 4.4779\n",
            "Epoch 64/500\n",
            "4767/4767 - 20s - loss: 3.8030 - rmse: 3.8036 - val_loss: 4.3787 - val_rmse: 4.3785\n",
            "Epoch 65/500\n",
            "4767/4767 - 20s - loss: 3.7824 - rmse: 3.7824 - val_loss: 4.3693 - val_rmse: 4.3690\n",
            "Epoch 66/500\n",
            "4767/4767 - 20s - loss: 3.7858 - rmse: 3.7854 - val_loss: 4.3811 - val_rmse: 4.3812\n",
            "Epoch 67/500\n",
            "4767/4767 - 20s - loss: 3.7680 - rmse: 3.7678 - val_loss: 4.3691 - val_rmse: 4.3687\n",
            "Epoch 68/500\n",
            "4767/4767 - 20s - loss: 3.7495 - rmse: 3.7496 - val_loss: 4.3572 - val_rmse: 4.3573\n",
            "Epoch 69/500\n",
            "4767/4767 - 20s - loss: 3.7264 - rmse: 3.7265 - val_loss: 4.3565 - val_rmse: 4.3565\n",
            "Epoch 70/500\n",
            "4767/4767 - 20s - loss: 3.7127 - rmse: 3.7132 - val_loss: 4.3439 - val_rmse: 4.3438\n",
            "Epoch 71/500\n",
            "4767/4767 - 20s - loss: 3.7190 - rmse: 3.7186 - val_loss: 4.3547 - val_rmse: 4.3547\n",
            "Epoch 72/500\n",
            "4767/4767 - 20s - loss: 3.7004 - rmse: 3.7002 - val_loss: 4.3545 - val_rmse: 4.3546\n",
            "Epoch 73/500\n",
            "4767/4767 - 20s - loss: 3.6882 - rmse: 3.6880 - val_loss: 4.3460 - val_rmse: 4.3461\n",
            "Epoch 74/500\n",
            "4767/4767 - 20s - loss: 3.6672 - rmse: 3.6669 - val_loss: 4.4244 - val_rmse: 4.4240\n",
            "Epoch 75/500\n",
            "4767/4767 - 22s - loss: 3.6654 - rmse: 3.6651 - val_loss: 4.3539 - val_rmse: 4.3538\n",
            "Epoch 76/500\n",
            "4767/4767 - 21s - loss: 3.6479 - rmse: 3.6476 - val_loss: 4.3823 - val_rmse: 4.3821\n",
            "Epoch 77/500\n",
            "4767/4767 - 21s - loss: 3.6585 - rmse: 3.6583 - val_loss: 4.3670 - val_rmse: 4.3671\n",
            "Epoch 78/500\n",
            "4767/4767 - 22s - loss: 3.6571 - rmse: 3.6568 - val_loss: 4.3677 - val_rmse: 4.3674\n",
            "Epoch 79/500\n",
            "4767/4767 - 25s - loss: 3.6282 - rmse: 3.6280 - val_loss: 4.3600 - val_rmse: 4.3601\n",
            "Epoch 80/500\n",
            "4767/4767 - 21s - loss: 3.6078 - rmse: 3.6075 - val_loss: 4.3478 - val_rmse: 4.3481\n",
            "Train Score: 3.54 RMSE\n",
            "Validation Score: 4.90 RMSE\n",
            "Test Score: 4.99 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "          ID  firm     CowID  ... disease  Sampling D Year  Sampling D Month\n",
            "0      10806     2   3126105  ...     1.0           2016.0            Summer\n",
            "1      10950     2   3126118  ...     0.0           2017.0            Spring\n",
            "2      30007     2   3126179  ...     0.0           2016.0            Autumn\n",
            "3       2137     1   2052011  ...     0.0           2018.0            Spring\n",
            "4      20955     2    127993  ...     0.0           2016.0            Winter\n",
            "...      ...   ...       ...  ...     ...              ...               ...\n",
            "26475  15392     2   2122400  ...     0.0           2018.0            Spring\n",
            "26476  25883     2  10837415  ...     0.0           2018.0            Autumn\n",
            "26477  19848     2    124308  ...     0.0           2013.0            Winter\n",
            "26478   3360     1   1051856  ...     0.0           2015.0            Summer\n",
            "26479   6626     1  96051858  ...     0.0           2013.0            Summer\n",
            "\n",
            "[26480 rows x 22 columns]\n",
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "3        18.2\n",
            "31       32.6\n",
            "41       39.0\n",
            "42       12.0\n",
            "59        5.0\n",
            "         ... \n",
            "26447    47.3\n",
            "26454    34.0\n",
            "26464    18.6\n",
            "26468    28.0\n",
            "26477    20.4\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 23s - loss: 9.0012 - rmse: 9.0012 - val_loss: 6.6263 - val_rmse: 6.6248\n",
            "Epoch 2/500\n",
            "4767/4767 - 20s - loss: 6.9613 - rmse: 6.9607 - val_loss: 6.0664 - val_rmse: 6.0655\n",
            "Epoch 3/500\n",
            "4767/4767 - 20s - loss: 6.4534 - rmse: 6.4530 - val_loss: 5.6448 - val_rmse: 5.6438\n",
            "Epoch 4/500\n",
            "4767/4767 - 20s - loss: 6.1301 - rmse: 6.1301 - val_loss: 5.4433 - val_rmse: 5.4421\n",
            "Epoch 5/500\n",
            "4767/4767 - 19s - loss: 5.9553 - rmse: 5.9555 - val_loss: 5.3501 - val_rmse: 5.3484\n",
            "Epoch 6/500\n",
            "4767/4767 - 20s - loss: 5.8260 - rmse: 5.8261 - val_loss: 5.2201 - val_rmse: 5.2184\n",
            "Epoch 7/500\n",
            "4767/4767 - 19s - loss: 5.6957 - rmse: 5.6964 - val_loss: 5.1420 - val_rmse: 5.1412\n",
            "Epoch 8/500\n",
            "4767/4767 - 20s - loss: 5.6382 - rmse: 5.6378 - val_loss: 5.0541 - val_rmse: 5.0529\n",
            "Epoch 9/500\n",
            "4767/4767 - 20s - loss: 5.5649 - rmse: 5.5653 - val_loss: 5.0066 - val_rmse: 5.0050\n",
            "Epoch 10/500\n",
            "4767/4767 - 21s - loss: 5.5008 - rmse: 5.5002 - val_loss: 5.0066 - val_rmse: 5.0049\n",
            "Epoch 11/500\n",
            "4767/4767 - 20s - loss: 5.4811 - rmse: 5.4807 - val_loss: 4.9509 - val_rmse: 4.9490\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.3854 - rmse: 5.3849 - val_loss: 4.8821 - val_rmse: 4.8806\n",
            "Epoch 13/500\n",
            "4767/4767 - 20s - loss: 5.3730 - rmse: 5.3728 - val_loss: 4.8796 - val_rmse: 4.8779\n",
            "Epoch 14/500\n",
            "4767/4767 - 23s - loss: 5.2902 - rmse: 5.2900 - val_loss: 4.8231 - val_rmse: 4.8223\n",
            "Epoch 15/500\n",
            "4767/4767 - 21s - loss: 5.2743 - rmse: 5.2738 - val_loss: 4.8508 - val_rmse: 4.8488\n",
            "Epoch 16/500\n",
            "4767/4767 - 20s - loss: 5.2005 - rmse: 5.2001 - val_loss: 4.8121 - val_rmse: 4.8100\n",
            "Epoch 17/500\n",
            "4767/4767 - 20s - loss: 5.2113 - rmse: 5.2119 - val_loss: 4.7819 - val_rmse: 4.7803\n",
            "Epoch 18/500\n",
            "4767/4767 - 20s - loss: 5.1368 - rmse: 5.1367 - val_loss: 4.8110 - val_rmse: 4.8095\n",
            "Epoch 19/500\n",
            "4767/4767 - 20s - loss: 5.1082 - rmse: 5.1082 - val_loss: 4.7109 - val_rmse: 4.7098\n",
            "Epoch 20/500\n",
            "4767/4767 - 20s - loss: 5.0335 - rmse: 5.0332 - val_loss: 4.6949 - val_rmse: 4.6939\n",
            "Epoch 21/500\n",
            "4767/4767 - 20s - loss: 5.0065 - rmse: 5.0060 - val_loss: 4.6825 - val_rmse: 4.6811\n",
            "Epoch 22/500\n",
            "4767/4767 - 20s - loss: 4.9624 - rmse: 4.9619 - val_loss: 4.6501 - val_rmse: 4.6488\n",
            "Epoch 23/500\n",
            "4767/4767 - 20s - loss: 4.9405 - rmse: 4.9408 - val_loss: 4.6033 - val_rmse: 4.6020\n",
            "Epoch 24/500\n",
            "4767/4767 - 20s - loss: 4.8429 - rmse: 4.8427 - val_loss: 4.5666 - val_rmse: 4.5656\n",
            "Epoch 25/500\n",
            "4767/4767 - 21s - loss: 4.8225 - rmse: 4.8221 - val_loss: 4.5296 - val_rmse: 4.5288\n",
            "Epoch 26/500\n",
            "4767/4767 - 19s - loss: 4.7862 - rmse: 4.7861 - val_loss: 4.5874 - val_rmse: 4.5858\n",
            "Epoch 27/500\n",
            "4767/4767 - 20s - loss: 4.7496 - rmse: 4.7498 - val_loss: 4.5286 - val_rmse: 4.5271\n",
            "Epoch 28/500\n",
            "4767/4767 - 20s - loss: 4.6897 - rmse: 4.6896 - val_loss: 4.5765 - val_rmse: 4.5747\n",
            "Epoch 29/500\n",
            "4767/4767 - 20s - loss: 4.7036 - rmse: 4.7045 - val_loss: 4.5175 - val_rmse: 4.5158\n",
            "Epoch 30/500\n",
            "4767/4767 - 23s - loss: 4.6840 - rmse: 4.6835 - val_loss: 4.5250 - val_rmse: 4.5235\n",
            "Epoch 31/500\n",
            "4767/4767 - 25s - loss: 4.6045 - rmse: 4.6041 - val_loss: 4.4624 - val_rmse: 4.4614\n",
            "Epoch 32/500\n",
            "4767/4767 - 20s - loss: 4.5629 - rmse: 4.5626 - val_loss: 4.4579 - val_rmse: 4.4565\n",
            "Epoch 33/500\n",
            "4767/4767 - 21s - loss: 4.5157 - rmse: 4.5153 - val_loss: 4.5797 - val_rmse: 4.5776\n",
            "Epoch 34/500\n",
            "4767/4767 - 20s - loss: 4.5056 - rmse: 4.5058 - val_loss: 4.4436 - val_rmse: 4.4422\n",
            "Epoch 35/500\n",
            "4767/4767 - 20s - loss: 4.4391 - rmse: 4.4388 - val_loss: 4.4272 - val_rmse: 4.4258\n",
            "Epoch 36/500\n",
            "4767/4767 - 19s - loss: 4.4278 - rmse: 4.4277 - val_loss: 4.4360 - val_rmse: 4.4344\n",
            "Epoch 37/500\n",
            "4767/4767 - 19s - loss: 4.3808 - rmse: 4.3807 - val_loss: 4.4385 - val_rmse: 4.4369\n",
            "Epoch 38/500\n",
            "4767/4767 - 20s - loss: 4.3562 - rmse: 4.3562 - val_loss: 4.3600 - val_rmse: 4.3586\n",
            "Epoch 39/500\n",
            "4767/4767 - 19s - loss: 4.3332 - rmse: 4.3329 - val_loss: 4.3298 - val_rmse: 4.3289\n",
            "Epoch 40/500\n",
            "4767/4767 - 21s - loss: 4.2851 - rmse: 4.2848 - val_loss: 4.3244 - val_rmse: 4.3230\n",
            "Epoch 41/500\n",
            "4767/4767 - 20s - loss: 4.2591 - rmse: 4.2589 - val_loss: 4.3184 - val_rmse: 4.3180\n",
            "Epoch 42/500\n",
            "4767/4767 - 20s - loss: 4.2409 - rmse: 4.2413 - val_loss: 4.3258 - val_rmse: 4.3248\n",
            "Epoch 43/500\n",
            "4767/4767 - 20s - loss: 4.2034 - rmse: 4.2034 - val_loss: 4.3061 - val_rmse: 4.3053\n",
            "Epoch 44/500\n",
            "4767/4767 - 20s - loss: 4.1667 - rmse: 4.1668 - val_loss: 4.3032 - val_rmse: 4.3022\n",
            "Epoch 45/500\n",
            "4767/4767 - 20s - loss: 4.1571 - rmse: 4.1569 - val_loss: 4.3223 - val_rmse: 4.3209\n",
            "Epoch 46/500\n",
            "4767/4767 - 22s - loss: 4.1610 - rmse: 4.1614 - val_loss: 4.3013 - val_rmse: 4.3003\n",
            "Epoch 47/500\n",
            "4767/4767 - 22s - loss: 4.0986 - rmse: 4.0989 - val_loss: 4.2864 - val_rmse: 4.2854\n",
            "Epoch 48/500\n",
            "4767/4767 - 20s - loss: 4.0895 - rmse: 4.0892 - val_loss: 4.2546 - val_rmse: 4.2536\n",
            "Epoch 49/500\n",
            "4767/4767 - 20s - loss: 4.0811 - rmse: 4.0817 - val_loss: 4.2712 - val_rmse: 4.2701\n",
            "Epoch 50/500\n",
            "4767/4767 - 20s - loss: 4.0803 - rmse: 4.0800 - val_loss: 4.2917 - val_rmse: 4.2909\n",
            "Epoch 51/500\n",
            "4767/4767 - 20s - loss: 4.0516 - rmse: 4.0517 - val_loss: 4.2785 - val_rmse: 4.2774\n",
            "Epoch 52/500\n",
            "4767/4767 - 20s - loss: 4.0087 - rmse: 4.0083 - val_loss: 4.2913 - val_rmse: 4.2904\n",
            "Epoch 53/500\n",
            "4767/4767 - 21s - loss: 4.0111 - rmse: 4.0133 - val_loss: 4.2558 - val_rmse: 4.2552\n",
            "Epoch 54/500\n",
            "4767/4767 - 20s - loss: 3.9918 - rmse: 3.9914 - val_loss: 4.2433 - val_rmse: 4.2425\n",
            "Epoch 55/500\n",
            "4767/4767 - 21s - loss: 3.9325 - rmse: 3.9330 - val_loss: 4.2610 - val_rmse: 4.2597\n",
            "Epoch 56/500\n",
            "4767/4767 - 20s - loss: 3.9196 - rmse: 3.9192 - val_loss: 4.2513 - val_rmse: 4.2498\n",
            "Epoch 57/500\n",
            "4767/4767 - 19s - loss: 3.9031 - rmse: 3.9028 - val_loss: 4.2411 - val_rmse: 4.2401\n",
            "Epoch 58/500\n",
            "4767/4767 - 19s - loss: 3.8811 - rmse: 3.8806 - val_loss: 4.2378 - val_rmse: 4.2367\n",
            "Epoch 59/500\n",
            "4767/4767 - 20s - loss: 3.8981 - rmse: 3.8979 - val_loss: 4.2230 - val_rmse: 4.2222\n",
            "Epoch 60/500\n",
            "4767/4767 - 20s - loss: 3.8535 - rmse: 3.8536 - val_loss: 4.2323 - val_rmse: 4.2315\n",
            "Epoch 61/500\n",
            "4767/4767 - 22s - loss: 3.8517 - rmse: 3.8516 - val_loss: 4.2352 - val_rmse: 4.2345\n",
            "Epoch 62/500\n",
            "4767/4767 - 22s - loss: 3.8181 - rmse: 3.8178 - val_loss: 4.3172 - val_rmse: 4.3159\n",
            "Epoch 63/500\n",
            "4767/4767 - 21s - loss: 3.8027 - rmse: 3.8027 - val_loss: 4.3057 - val_rmse: 4.3042\n",
            "Epoch 64/500\n",
            "4767/4767 - 20s - loss: 3.7933 - rmse: 3.7939 - val_loss: 4.2758 - val_rmse: 4.2744\n",
            "Epoch 65/500\n",
            "4767/4767 - 20s - loss: 3.7857 - rmse: 3.7856 - val_loss: 4.2267 - val_rmse: 4.2258\n",
            "Epoch 66/500\n",
            "4767/4767 - 20s - loss: 3.7685 - rmse: 3.7683 - val_loss: 4.2274 - val_rmse: 4.2266\n",
            "Epoch 67/500\n",
            "4767/4767 - 19s - loss: 3.7705 - rmse: 3.7704 - val_loss: 4.2902 - val_rmse: 4.2891\n",
            "Epoch 68/500\n",
            "4767/4767 - 19s - loss: 3.7339 - rmse: 3.7340 - val_loss: 4.2557 - val_rmse: 4.2550\n",
            "Epoch 69/500\n",
            "4767/4767 - 20s - loss: 3.7266 - rmse: 3.7263 - val_loss: 4.2351 - val_rmse: 4.2341\n",
            "Train Score: 3.62 RMSE\n",
            "Validation Score: 4.67 RMSE\n",
            "Test Score: 4.95 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "0        20.0\n",
            "19       14.0\n",
            "47       19.9\n",
            "49       16.0\n",
            "50       32.4\n",
            "         ... \n",
            "26433    14.0\n",
            "26435    30.0\n",
            "26438    34.0\n",
            "26466    13.6\n",
            "26472    36.0\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 20s - loss: 8.8971 - rmse: 8.8977 - val_loss: 6.7985 - val_rmse: 6.8000\n",
            "Epoch 2/500\n",
            "4767/4767 - 21s - loss: 6.9454 - rmse: 6.9459 - val_loss: 6.2025 - val_rmse: 6.2041\n",
            "Epoch 3/500\n",
            "4767/4767 - 20s - loss: 6.4642 - rmse: 6.4641 - val_loss: 5.7413 - val_rmse: 5.7426\n",
            "Epoch 4/500\n",
            "4767/4767 - 20s - loss: 6.0994 - rmse: 6.0990 - val_loss: 5.5990 - val_rmse: 5.6005\n",
            "Epoch 5/500\n",
            "4767/4767 - 20s - loss: 5.9524 - rmse: 5.9527 - val_loss: 5.3588 - val_rmse: 5.3603\n",
            "Epoch 6/500\n",
            "4767/4767 - 20s - loss: 5.7859 - rmse: 5.7853 - val_loss: 5.2878 - val_rmse: 5.2894\n",
            "Epoch 7/500\n",
            "4767/4767 - 20s - loss: 5.6983 - rmse: 5.6987 - val_loss: 5.1684 - val_rmse: 5.1699\n",
            "Epoch 8/500\n",
            "4767/4767 - 20s - loss: 5.6393 - rmse: 5.6390 - val_loss: 5.2353 - val_rmse: 5.2371\n",
            "Epoch 9/500\n",
            "4767/4767 - 24s - loss: 5.5464 - rmse: 5.5464 - val_loss: 5.1207 - val_rmse: 5.1223\n",
            "Epoch 10/500\n",
            "4767/4767 - 20s - loss: 5.5104 - rmse: 5.5104 - val_loss: 5.0246 - val_rmse: 5.0266\n",
            "Epoch 11/500\n",
            "4767/4767 - 20s - loss: 5.4371 - rmse: 5.4367 - val_loss: 4.9844 - val_rmse: 4.9861\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.4213 - rmse: 5.4209 - val_loss: 4.9692 - val_rmse: 4.9711\n",
            "Epoch 13/500\n",
            "4767/4767 - 20s - loss: 5.3948 - rmse: 5.3945 - val_loss: 4.9127 - val_rmse: 4.9148\n",
            "Epoch 14/500\n",
            "4767/4767 - 20s - loss: 5.2950 - rmse: 5.2950 - val_loss: 4.9616 - val_rmse: 4.9636\n",
            "Epoch 15/500\n",
            "4767/4767 - 20s - loss: 5.2605 - rmse: 5.2602 - val_loss: 4.9193 - val_rmse: 4.9214\n",
            "Epoch 16/500\n",
            "4767/4767 - 20s - loss: 5.1928 - rmse: 5.1926 - val_loss: 4.8737 - val_rmse: 4.8758\n",
            "Epoch 17/500\n",
            "4767/4767 - 22s - loss: 5.1705 - rmse: 5.1706 - val_loss: 4.8719 - val_rmse: 4.8737\n",
            "Epoch 18/500\n",
            "4767/4767 - 20s - loss: 5.1058 - rmse: 5.1058 - val_loss: 4.8461 - val_rmse: 4.8480\n",
            "Epoch 19/500\n",
            "4767/4767 - 20s - loss: 5.0789 - rmse: 5.0786 - val_loss: 4.8148 - val_rmse: 4.8164\n",
            "Epoch 20/500\n",
            "4767/4767 - 20s - loss: 5.0470 - rmse: 5.0466 - val_loss: 4.7852 - val_rmse: 4.7868\n",
            "Epoch 21/500\n",
            "4767/4767 - 20s - loss: 4.9798 - rmse: 4.9798 - val_loss: 4.7116 - val_rmse: 4.7134\n",
            "Epoch 22/500\n",
            "4767/4767 - 22s - loss: 4.9404 - rmse: 4.9403 - val_loss: 4.7044 - val_rmse: 4.7060\n",
            "Epoch 23/500\n",
            "4767/4767 - 20s - loss: 4.9276 - rmse: 4.9272 - val_loss: 4.6676 - val_rmse: 4.6693\n",
            "Epoch 24/500\n",
            "4767/4767 - 20s - loss: 4.8627 - rmse: 4.8624 - val_loss: 4.7189 - val_rmse: 4.7207\n",
            "Epoch 25/500\n",
            "4767/4767 - 23s - loss: 4.8163 - rmse: 4.8166 - val_loss: 4.6978 - val_rmse: 4.6998\n",
            "Epoch 26/500\n",
            "4767/4767 - 20s - loss: 4.7769 - rmse: 4.7776 - val_loss: 4.6355 - val_rmse: 4.6373\n",
            "Epoch 27/500\n",
            "4767/4767 - 20s - loss: 4.7175 - rmse: 4.7177 - val_loss: 4.6146 - val_rmse: 4.6160\n",
            "Epoch 28/500\n",
            "4767/4767 - 19s - loss: 4.7331 - rmse: 4.7328 - val_loss: 4.5989 - val_rmse: 4.6006\n",
            "Epoch 29/500\n",
            "4767/4767 - 20s - loss: 4.6901 - rmse: 4.6902 - val_loss: 4.5730 - val_rmse: 4.5742\n",
            "Epoch 30/500\n",
            "4767/4767 - 19s - loss: 4.6432 - rmse: 4.6428 - val_loss: 4.5990 - val_rmse: 4.6003\n",
            "Epoch 31/500\n",
            "4767/4767 - 20s - loss: 4.6040 - rmse: 4.6038 - val_loss: 4.5556 - val_rmse: 4.5567\n",
            "Epoch 32/500\n",
            "4767/4767 - 21s - loss: 4.5648 - rmse: 4.5652 - val_loss: 4.5558 - val_rmse: 4.5566\n",
            "Epoch 33/500\n",
            "4767/4767 - 20s - loss: 4.5287 - rmse: 4.5285 - val_loss: 4.5315 - val_rmse: 4.5322\n",
            "Epoch 34/500\n",
            "4767/4767 - 20s - loss: 4.5090 - rmse: 4.5087 - val_loss: 4.5271 - val_rmse: 4.5281\n",
            "Epoch 35/500\n",
            "4767/4767 - 19s - loss: 4.4489 - rmse: 4.4485 - val_loss: 4.5102 - val_rmse: 4.5114\n",
            "Epoch 36/500\n",
            "4767/4767 - 19s - loss: 4.4542 - rmse: 4.4540 - val_loss: 4.4784 - val_rmse: 4.4794\n",
            "Epoch 37/500\n",
            "4767/4767 - 19s - loss: 4.3837 - rmse: 4.3836 - val_loss: 4.5170 - val_rmse: 4.5178\n",
            "Epoch 38/500\n",
            "4767/4767 - 20s - loss: 4.3718 - rmse: 4.3720 - val_loss: 4.5150 - val_rmse: 4.5158\n",
            "Epoch 39/500\n",
            "4767/4767 - 20s - loss: 4.3303 - rmse: 4.3308 - val_loss: 4.4420 - val_rmse: 4.4428\n",
            "Epoch 40/500\n",
            "4767/4767 - 19s - loss: 4.3354 - rmse: 4.3353 - val_loss: 4.4375 - val_rmse: 4.4381\n",
            "Epoch 41/500\n",
            "4767/4767 - 29s - loss: 4.3013 - rmse: 4.3011 - val_loss: 4.4744 - val_rmse: 4.4753\n",
            "Epoch 42/500\n",
            "4767/4767 - 20s - loss: 4.2464 - rmse: 4.2464 - val_loss: 4.3921 - val_rmse: 4.3927\n",
            "Epoch 43/500\n",
            "4767/4767 - 20s - loss: 4.2237 - rmse: 4.2239 - val_loss: 4.4112 - val_rmse: 4.4117\n",
            "Epoch 44/500\n",
            "4767/4767 - 20s - loss: 4.2029 - rmse: 4.2025 - val_loss: 4.3894 - val_rmse: 4.3903\n",
            "Epoch 45/500\n",
            "4767/4767 - 20s - loss: 4.1682 - rmse: 4.1688 - val_loss: 4.3992 - val_rmse: 4.3999\n",
            "Epoch 46/500\n",
            "4767/4767 - 20s - loss: 4.1319 - rmse: 4.1320 - val_loss: 4.4425 - val_rmse: 4.4432\n",
            "Epoch 47/500\n",
            "4767/4767 - 21s - loss: 4.1196 - rmse: 4.1203 - val_loss: 4.3849 - val_rmse: 4.3855\n",
            "Epoch 48/500\n",
            "4767/4767 - 20s - loss: 4.1173 - rmse: 4.1171 - val_loss: 4.4041 - val_rmse: 4.4053\n",
            "Epoch 49/500\n",
            "4767/4767 - 19s - loss: 4.1049 - rmse: 4.1046 - val_loss: 4.4007 - val_rmse: 4.4017\n",
            "Epoch 50/500\n",
            "4767/4767 - 19s - loss: 4.0503 - rmse: 4.0510 - val_loss: 4.3496 - val_rmse: 4.3502\n",
            "Epoch 51/500\n",
            "4767/4767 - 20s - loss: 4.0358 - rmse: 4.0358 - val_loss: 4.3438 - val_rmse: 4.3448\n",
            "Epoch 52/500\n",
            "4767/4767 - 22s - loss: 4.0140 - rmse: 4.0139 - val_loss: 4.3500 - val_rmse: 4.3507\n",
            "Epoch 53/500\n",
            "4767/4767 - 20s - loss: 3.9938 - rmse: 3.9940 - val_loss: 4.3557 - val_rmse: 4.3564\n",
            "Epoch 54/500\n",
            "4767/4767 - 19s - loss: 3.9857 - rmse: 3.9854 - val_loss: 4.3276 - val_rmse: 4.3284\n",
            "Epoch 55/500\n",
            "4767/4767 - 19s - loss: 3.9715 - rmse: 3.9715 - val_loss: 4.3470 - val_rmse: 4.3479\n",
            "Epoch 56/500\n",
            "4767/4767 - 19s - loss: 3.9215 - rmse: 3.9211 - val_loss: 4.3506 - val_rmse: 4.3509\n",
            "Epoch 57/500\n",
            "4767/4767 - 23s - loss: 3.9385 - rmse: 3.9381 - val_loss: 4.3321 - val_rmse: 4.3326\n",
            "Epoch 58/500\n",
            "4767/4767 - 20s - loss: 3.9053 - rmse: 3.9050 - val_loss: 4.3072 - val_rmse: 4.3075\n",
            "Epoch 59/500\n",
            "4767/4767 - 20s - loss: 3.8822 - rmse: 3.8818 - val_loss: 4.3154 - val_rmse: 4.3161\n",
            "Epoch 60/500\n",
            "4767/4767 - 19s - loss: 3.8536 - rmse: 3.8536 - val_loss: 4.3434 - val_rmse: 4.3438\n",
            "Epoch 61/500\n",
            "4767/4767 - 20s - loss: 3.8717 - rmse: 3.8713 - val_loss: 4.3437 - val_rmse: 4.3442\n",
            "Epoch 62/500\n",
            "4767/4767 - 20s - loss: 3.8327 - rmse: 3.8325 - val_loss: 4.3197 - val_rmse: 4.3199\n",
            "Epoch 63/500\n",
            "4767/4767 - 22s - loss: 3.8299 - rmse: 3.8301 - val_loss: 4.3123 - val_rmse: 4.3125\n",
            "Epoch 64/500\n",
            "4767/4767 - 21s - loss: 3.8346 - rmse: 3.8343 - val_loss: 4.3052 - val_rmse: 4.3053\n",
            "Epoch 65/500\n",
            "4767/4767 - 21s - loss: 3.7914 - rmse: 3.7911 - val_loss: 4.2720 - val_rmse: 4.2726\n",
            "Epoch 66/500\n",
            "4767/4767 - 20s - loss: 3.7924 - rmse: 3.7923 - val_loss: 4.2968 - val_rmse: 4.2971\n",
            "Epoch 67/500\n",
            "4767/4767 - 20s - loss: 3.7585 - rmse: 3.7582 - val_loss: 4.2880 - val_rmse: 4.2883\n",
            "Epoch 68/500\n",
            "4767/4767 - 19s - loss: 3.7709 - rmse: 3.7710 - val_loss: 4.2816 - val_rmse: 4.2815\n",
            "Epoch 69/500\n",
            "4767/4767 - 20s - loss: 3.7265 - rmse: 3.7270 - val_loss: 4.2726 - val_rmse: 4.2726\n",
            "Epoch 70/500\n",
            "4767/4767 - 19s - loss: 3.7114 - rmse: 3.7115 - val_loss: 4.2833 - val_rmse: 4.2835\n",
            "Epoch 71/500\n",
            "4767/4767 - 19s - loss: 3.7172 - rmse: 3.7171 - val_loss: 4.2836 - val_rmse: 4.2836\n",
            "Epoch 72/500\n",
            "4767/4767 - 19s - loss: 3.7105 - rmse: 3.7103 - val_loss: 4.2615 - val_rmse: 4.2616\n",
            "Epoch 73/500\n",
            "4767/4767 - 21s - loss: 3.7117 - rmse: 3.7117 - val_loss: 4.2489 - val_rmse: 4.2489\n",
            "Epoch 74/500\n",
            "4767/4767 - 20s - loss: 3.6709 - rmse: 3.6712 - val_loss: 4.2646 - val_rmse: 4.2647\n",
            "Epoch 75/500\n",
            "4767/4767 - 19s - loss: 3.6777 - rmse: 3.6776 - val_loss: 4.2594 - val_rmse: 4.2592\n",
            "Epoch 76/500\n",
            "4767/4767 - 19s - loss: 3.6676 - rmse: 3.6676 - val_loss: 4.2679 - val_rmse: 4.2676\n",
            "Epoch 77/500\n",
            "4767/4767 - 20s - loss: 3.6693 - rmse: 3.6694 - val_loss: 4.2735 - val_rmse: 4.2735\n",
            "Epoch 78/500\n",
            "4767/4767 - 21s - loss: 3.6404 - rmse: 3.6400 - val_loss: 4.2508 - val_rmse: 4.2509\n",
            "Epoch 79/500\n",
            "4767/4767 - 19s - loss: 3.6208 - rmse: 3.6223 - val_loss: 4.2708 - val_rmse: 4.2704\n",
            "Epoch 80/500\n",
            "4767/4767 - 20s - loss: 3.6260 - rmse: 3.6267 - val_loss: 4.2522 - val_rmse: 4.2522\n",
            "Epoch 81/500\n",
            "4767/4767 - 19s - loss: 3.6141 - rmse: 3.6139 - val_loss: 4.2496 - val_rmse: 4.2489\n",
            "Epoch 82/500\n",
            "4767/4767 - 19s - loss: 3.6078 - rmse: 3.6079 - val_loss: 4.2549 - val_rmse: 4.2549\n",
            "Epoch 83/500\n",
            "4767/4767 - 21s - loss: 3.6047 - rmse: 3.6045 - val_loss: 4.2294 - val_rmse: 4.2296\n",
            "Epoch 84/500\n",
            "4767/4767 - 19s - loss: 3.5912 - rmse: 3.5910 - val_loss: 4.2483 - val_rmse: 4.2480\n",
            "Epoch 85/500\n",
            "4767/4767 - 19s - loss: 3.5719 - rmse: 3.5718 - val_loss: 4.2659 - val_rmse: 4.2655\n",
            "Epoch 86/500\n",
            "4767/4767 - 19s - loss: 3.5568 - rmse: 3.5582 - val_loss: 4.2500 - val_rmse: 4.2494\n",
            "Epoch 87/500\n",
            "4767/4767 - 19s - loss: 3.5683 - rmse: 3.5680 - val_loss: 4.2370 - val_rmse: 4.2364\n",
            "Epoch 88/500\n",
            "4767/4767 - 19s - loss: 3.5456 - rmse: 3.5454 - val_loss: 4.2644 - val_rmse: 4.2640\n",
            "Epoch 89/500\n",
            "4767/4767 - 20s - loss: 3.5355 - rmse: 3.5357 - val_loss: 4.2591 - val_rmse: 4.2585\n",
            "Epoch 90/500\n",
            "4767/4767 - 21s - loss: 3.5026 - rmse: 3.5026 - val_loss: 4.2345 - val_rmse: 4.2340\n",
            "Epoch 91/500\n",
            "4767/4767 - 19s - loss: 3.5049 - rmse: 3.5045 - val_loss: 4.2632 - val_rmse: 4.2626\n",
            "Epoch 92/500\n",
            "4767/4767 - 19s - loss: 3.5059 - rmse: 3.5055 - val_loss: 4.2409 - val_rmse: 4.2403\n",
            "Epoch 93/500\n",
            "4767/4767 - 20s - loss: 3.4883 - rmse: 3.4886 - val_loss: 4.2456 - val_rmse: 4.2450\n",
            "Train Score: 3.37 RMSE\n",
            "Validation Score: 4.68 RMSE\n",
            "Test Score: 4.92 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "4        10.0\n",
            "5        41.0\n",
            "8        18.0\n",
            "14       15.0\n",
            "20       21.8\n",
            "         ... \n",
            "26434    19.0\n",
            "26441    31.0\n",
            "26442    11.3\n",
            "26467    22.0\n",
            "26471    14.2\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 21s - loss: 8.9381 - rmse: 8.9379 - val_loss: 6.6234 - val_rmse: 6.6254\n",
            "Epoch 2/500\n",
            "4767/4767 - 20s - loss: 6.9743 - rmse: 6.9748 - val_loss: 6.1138 - val_rmse: 6.1157\n",
            "Epoch 3/500\n",
            "4767/4767 - 19s - loss: 6.4505 - rmse: 6.4509 - val_loss: 5.7582 - val_rmse: 5.7595\n",
            "Epoch 4/500\n",
            "4767/4767 - 19s - loss: 6.0996 - rmse: 6.0993 - val_loss: 5.5812 - val_rmse: 5.5822\n",
            "Epoch 5/500\n",
            "4767/4767 - 19s - loss: 5.9424 - rmse: 5.9423 - val_loss: 5.4478 - val_rmse: 5.4491\n",
            "Epoch 6/500\n",
            "4767/4767 - 19s - loss: 5.7564 - rmse: 5.7567 - val_loss: 5.3707 - val_rmse: 5.3723\n",
            "Epoch 7/500\n",
            "4767/4767 - 20s - loss: 5.7148 - rmse: 5.7144 - val_loss: 5.2941 - val_rmse: 5.2948\n",
            "Epoch 8/500\n",
            "4767/4767 - 21s - loss: 5.6261 - rmse: 5.6255 - val_loss: 5.2471 - val_rmse: 5.2468\n",
            "Epoch 9/500\n",
            "4767/4767 - 21s - loss: 5.5410 - rmse: 5.5412 - val_loss: 5.2013 - val_rmse: 5.2012\n",
            "Epoch 10/500\n",
            "4767/4767 - 19s - loss: 5.5144 - rmse: 5.5139 - val_loss: 5.2216 - val_rmse: 5.2209\n",
            "Epoch 11/500\n",
            "4767/4767 - 20s - loss: 5.4677 - rmse: 5.4677 - val_loss: 5.1353 - val_rmse: 5.1352\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.3862 - rmse: 5.3858 - val_loss: 5.0848 - val_rmse: 5.0850\n",
            "Epoch 13/500\n",
            "4767/4767 - 23s - loss: 5.3369 - rmse: 5.3370 - val_loss: 5.0610 - val_rmse: 5.0606\n",
            "Epoch 14/500\n",
            "4767/4767 - 20s - loss: 5.2763 - rmse: 5.2763 - val_loss: 5.0262 - val_rmse: 5.0254\n",
            "Epoch 15/500\n",
            "4767/4767 - 20s - loss: 5.2672 - rmse: 5.2668 - val_loss: 5.0696 - val_rmse: 5.0682\n",
            "Epoch 16/500\n",
            "4767/4767 - 22s - loss: 5.2078 - rmse: 5.2078 - val_loss: 5.0774 - val_rmse: 5.0757\n",
            "Epoch 17/500\n",
            "4767/4767 - 20s - loss: 5.1507 - rmse: 5.1505 - val_loss: 4.9609 - val_rmse: 4.9604\n",
            "Epoch 18/500\n",
            "4767/4767 - 20s - loss: 5.1031 - rmse: 5.1031 - val_loss: 4.9521 - val_rmse: 4.9515\n",
            "Epoch 19/500\n",
            "4767/4767 - 19s - loss: 5.0866 - rmse: 5.0868 - val_loss: 4.9590 - val_rmse: 4.9582\n",
            "Epoch 20/500\n",
            "4767/4767 - 22s - loss: 5.0482 - rmse: 5.0480 - val_loss: 4.9016 - val_rmse: 4.9005\n",
            "Epoch 21/500\n",
            "4767/4767 - 19s - loss: 4.9649 - rmse: 4.9653 - val_loss: 4.8997 - val_rmse: 4.8988\n",
            "Epoch 22/500\n",
            "4767/4767 - 19s - loss: 4.9302 - rmse: 4.9309 - val_loss: 4.8774 - val_rmse: 4.8770\n",
            "Epoch 23/500\n",
            "4767/4767 - 19s - loss: 4.8974 - rmse: 4.8975 - val_loss: 4.8517 - val_rmse: 4.8502\n",
            "Epoch 24/500\n",
            "4767/4767 - 20s - loss: 4.8523 - rmse: 4.8521 - val_loss: 4.8320 - val_rmse: 4.8309\n",
            "Epoch 25/500\n",
            "4767/4767 - 20s - loss: 4.8687 - rmse: 4.8685 - val_loss: 4.8049 - val_rmse: 4.8033\n",
            "Epoch 26/500\n",
            "4767/4767 - 19s - loss: 4.7902 - rmse: 4.7904 - val_loss: 4.7958 - val_rmse: 4.7939\n",
            "Epoch 27/500\n",
            "4767/4767 - 19s - loss: 4.7708 - rmse: 4.7711 - val_loss: 4.7633 - val_rmse: 4.7617\n",
            "Epoch 28/500\n",
            "4767/4767 - 20s - loss: 4.7065 - rmse: 4.7061 - val_loss: 4.7541 - val_rmse: 4.7528\n",
            "Epoch 29/500\n",
            "4767/4767 - 22s - loss: 4.6800 - rmse: 4.6798 - val_loss: 4.7510 - val_rmse: 4.7495\n",
            "Epoch 30/500\n",
            "4767/4767 - 19s - loss: 4.6149 - rmse: 4.6159 - val_loss: 4.7310 - val_rmse: 4.7297\n",
            "Epoch 31/500\n",
            "4767/4767 - 20s - loss: 4.6090 - rmse: 4.6093 - val_loss: 4.7118 - val_rmse: 4.7098\n",
            "Epoch 32/500\n",
            "4767/4767 - 20s - loss: 4.5854 - rmse: 4.5853 - val_loss: 4.7015 - val_rmse: 4.6992\n",
            "Epoch 33/500\n",
            "4767/4767 - 19s - loss: 4.5177 - rmse: 4.5178 - val_loss: 4.6955 - val_rmse: 4.6933\n",
            "Epoch 34/500\n",
            "4767/4767 - 19s - loss: 4.5048 - rmse: 4.5044 - val_loss: 4.6525 - val_rmse: 4.6505\n",
            "Epoch 35/500\n",
            "4767/4767 - 19s - loss: 4.4637 - rmse: 4.4642 - val_loss: 4.6532 - val_rmse: 4.6516\n",
            "Epoch 36/500\n",
            "4767/4767 - 19s - loss: 4.4246 - rmse: 4.4243 - val_loss: 4.6279 - val_rmse: 4.6263\n",
            "Epoch 37/500\n",
            "4767/4767 - 19s - loss: 4.3730 - rmse: 4.3735 - val_loss: 4.6208 - val_rmse: 4.6193\n",
            "Epoch 38/500\n",
            "4767/4767 - 20s - loss: 4.3439 - rmse: 4.3436 - val_loss: 4.5995 - val_rmse: 4.5982\n",
            "Epoch 39/500\n",
            "4767/4767 - 20s - loss: 4.3094 - rmse: 4.3093 - val_loss: 4.6591 - val_rmse: 4.6573\n",
            "Epoch 40/500\n",
            "4767/4767 - 20s - loss: 4.2880 - rmse: 4.2878 - val_loss: 4.6187 - val_rmse: 4.6176\n",
            "Epoch 41/500\n",
            "4767/4767 - 21s - loss: 4.2762 - rmse: 4.2768 - val_loss: 4.6033 - val_rmse: 4.6019\n",
            "Epoch 42/500\n",
            "4767/4767 - 20s - loss: 4.2393 - rmse: 4.2392 - val_loss: 4.5463 - val_rmse: 4.5450\n",
            "Epoch 43/500\n",
            "4767/4767 - 21s - loss: 4.2112 - rmse: 4.2110 - val_loss: 4.5895 - val_rmse: 4.5878\n",
            "Epoch 44/500\n",
            "4767/4767 - 21s - loss: 4.1671 - rmse: 4.1676 - val_loss: 4.5428 - val_rmse: 4.5413\n",
            "Epoch 45/500\n",
            "4767/4767 - 25s - loss: 4.1389 - rmse: 4.1386 - val_loss: 4.5214 - val_rmse: 4.5198\n",
            "Epoch 46/500\n",
            "4767/4767 - 23s - loss: 4.1209 - rmse: 4.1215 - val_loss: 4.5336 - val_rmse: 4.5323\n",
            "Epoch 47/500\n",
            "4767/4767 - 21s - loss: 4.0910 - rmse: 4.0911 - val_loss: 4.5185 - val_rmse: 4.5173\n",
            "Epoch 48/500\n",
            "4767/4767 - 21s - loss: 4.0684 - rmse: 4.0684 - val_loss: 4.5138 - val_rmse: 4.5120\n",
            "Epoch 49/500\n",
            "4767/4767 - 21s - loss: 4.0928 - rmse: 4.0928 - val_loss: 4.4914 - val_rmse: 4.4897\n",
            "Epoch 50/500\n",
            "4767/4767 - 23s - loss: 4.0520 - rmse: 4.0519 - val_loss: 4.4850 - val_rmse: 4.4834\n",
            "Epoch 51/500\n",
            "4767/4767 - 21s - loss: 4.0133 - rmse: 4.0135 - val_loss: 4.5106 - val_rmse: 4.5090\n",
            "Epoch 52/500\n",
            "4767/4767 - 21s - loss: 3.9970 - rmse: 3.9966 - val_loss: 4.4951 - val_rmse: 4.4939\n",
            "Epoch 53/500\n",
            "4767/4767 - 21s - loss: 3.9822 - rmse: 3.9825 - val_loss: 4.4801 - val_rmse: 4.4784\n",
            "Epoch 54/500\n",
            "4767/4767 - 21s - loss: 3.9545 - rmse: 3.9548 - val_loss: 4.4862 - val_rmse: 4.4844\n",
            "Epoch 55/500\n",
            "4767/4767 - 21s - loss: 3.9220 - rmse: 3.9220 - val_loss: 4.4782 - val_rmse: 4.4768\n",
            "Epoch 56/500\n",
            "4767/4767 - 21s - loss: 3.9412 - rmse: 3.9423 - val_loss: 4.4720 - val_rmse: 4.4706\n",
            "Epoch 57/500\n",
            "4767/4767 - 21s - loss: 3.9167 - rmse: 3.9171 - val_loss: 4.4810 - val_rmse: 4.4794\n",
            "Epoch 58/500\n",
            "4767/4767 - 21s - loss: 3.8799 - rmse: 3.8796 - val_loss: 4.4893 - val_rmse: 4.4874\n",
            "Epoch 59/500\n",
            "4767/4767 - 21s - loss: 3.8689 - rmse: 3.8688 - val_loss: 4.4955 - val_rmse: 4.4937\n",
            "Epoch 60/500\n",
            "4767/4767 - 24s - loss: 3.8643 - rmse: 3.8640 - val_loss: 4.4486 - val_rmse: 4.4472\n",
            "Epoch 61/500\n",
            "4767/4767 - 23s - loss: 3.8328 - rmse: 3.8326 - val_loss: 4.4334 - val_rmse: 4.4318\n",
            "Epoch 62/500\n",
            "4767/4767 - 21s - loss: 3.8084 - rmse: 3.8082 - val_loss: 4.4436 - val_rmse: 4.4422\n",
            "Epoch 63/500\n",
            "4767/4767 - 21s - loss: 3.7946 - rmse: 3.7944 - val_loss: 4.4490 - val_rmse: 4.4474\n",
            "Epoch 64/500\n",
            "4767/4767 - 21s - loss: 3.8059 - rmse: 3.8056 - val_loss: 4.4204 - val_rmse: 4.4186\n",
            "Epoch 65/500\n",
            "4767/4767 - 21s - loss: 3.7914 - rmse: 3.7913 - val_loss: 4.4093 - val_rmse: 4.4077\n",
            "Epoch 66/500\n",
            "4767/4767 - 21s - loss: 3.7682 - rmse: 3.7682 - val_loss: 4.4199 - val_rmse: 4.4187\n",
            "Epoch 67/500\n",
            "4767/4767 - 21s - loss: 3.7701 - rmse: 3.7700 - val_loss: 4.4581 - val_rmse: 4.4561\n",
            "Epoch 68/500\n",
            "4767/4767 - 21s - loss: 3.7423 - rmse: 3.7421 - val_loss: 4.4266 - val_rmse: 4.4253\n",
            "Epoch 69/500\n",
            "4767/4767 - 21s - loss: 3.7325 - rmse: 3.7329 - val_loss: 4.4226 - val_rmse: 4.4208\n",
            "Epoch 70/500\n",
            "4767/4767 - 21s - loss: 3.6964 - rmse: 3.6972 - val_loss: 4.4071 - val_rmse: 4.4053\n",
            "Epoch 71/500\n",
            "4767/4767 - 21s - loss: 3.7085 - rmse: 3.7089 - val_loss: 4.4318 - val_rmse: 4.4302\n",
            "Epoch 72/500\n",
            "4767/4767 - 21s - loss: 3.6907 - rmse: 3.6915 - val_loss: 4.4090 - val_rmse: 4.4073\n",
            "Epoch 73/500\n",
            "4767/4767 - 21s - loss: 3.6865 - rmse: 3.6866 - val_loss: 4.4049 - val_rmse: 4.4029\n",
            "Epoch 74/500\n",
            "4767/4767 - 21s - loss: 3.6788 - rmse: 3.6786 - val_loss: 4.4001 - val_rmse: 4.3982\n",
            "Epoch 75/500\n",
            "4767/4767 - 29s - loss: 3.6696 - rmse: 3.6700 - val_loss: 4.3900 - val_rmse: 4.3882\n",
            "Epoch 76/500\n",
            "4767/4767 - 23s - loss: 3.6330 - rmse: 3.6330 - val_loss: 4.4195 - val_rmse: 4.4178\n",
            "Epoch 77/500\n",
            "4767/4767 - 21s - loss: 3.6517 - rmse: 3.6521 - val_loss: 4.4127 - val_rmse: 4.4105\n",
            "Epoch 78/500\n",
            "4767/4767 - 22s - loss: 3.6116 - rmse: 3.6116 - val_loss: 4.4049 - val_rmse: 4.4032\n",
            "Epoch 79/500\n",
            "4767/4767 - 22s - loss: 3.6143 - rmse: 3.6139 - val_loss: 4.3952 - val_rmse: 4.3933\n",
            "Epoch 80/500\n",
            "4767/4767 - 21s - loss: 3.6182 - rmse: 3.6186 - val_loss: 4.3797 - val_rmse: 4.3776\n",
            "Epoch 81/500\n",
            "4767/4767 - 21s - loss: 3.5931 - rmse: 3.5929 - val_loss: 4.3956 - val_rmse: 4.3935\n",
            "Epoch 82/500\n",
            "4767/4767 - 21s - loss: 3.5936 - rmse: 3.5935 - val_loss: 4.4032 - val_rmse: 4.4008\n",
            "Epoch 83/500\n",
            "4767/4767 - 21s - loss: 3.5735 - rmse: 3.5731 - val_loss: 4.4131 - val_rmse: 4.4113\n",
            "Epoch 84/500\n",
            "4767/4767 - 21s - loss: 3.5556 - rmse: 3.5555 - val_loss: 4.3886 - val_rmse: 4.3865\n",
            "Epoch 85/500\n",
            "4767/4767 - 21s - loss: 3.5838 - rmse: 3.5838 - val_loss: 4.3890 - val_rmse: 4.3873\n",
            "Epoch 86/500\n",
            "4767/4767 - 20s - loss: 3.5645 - rmse: 3.5649 - val_loss: 4.3737 - val_rmse: 4.3718\n",
            "Epoch 87/500\n",
            "4767/4767 - 21s - loss: 3.5382 - rmse: 3.5389 - val_loss: 4.3997 - val_rmse: 4.3979\n",
            "Epoch 88/500\n",
            "4767/4767 - 21s - loss: 3.5494 - rmse: 3.5492 - val_loss: 4.4076 - val_rmse: 4.4055\n",
            "Epoch 89/500\n",
            "4767/4767 - 21s - loss: 3.5080 - rmse: 3.5076 - val_loss: 4.3842 - val_rmse: 4.3824\n",
            "Epoch 90/500\n",
            "4767/4767 - 30s - loss: 3.5244 - rmse: 3.5244 - val_loss: 4.3899 - val_rmse: 4.3881\n",
            "Epoch 91/500\n",
            "4767/4767 - 21s - loss: 3.5076 - rmse: 3.5081 - val_loss: 4.3916 - val_rmse: 4.3896\n",
            "Epoch 92/500\n",
            "4767/4767 - 22s - loss: 3.5089 - rmse: 3.5088 - val_loss: 4.3942 - val_rmse: 4.3918\n",
            "Epoch 93/500\n",
            "4767/4767 - 22s - loss: 3.4936 - rmse: 3.4932 - val_loss: 4.4021 - val_rmse: 4.4006\n",
            "Epoch 94/500\n",
            "4767/4767 - 21s - loss: 3.4799 - rmse: 3.4796 - val_loss: 4.3727 - val_rmse: 4.3707\n",
            "Epoch 95/500\n",
            "4767/4767 - 21s - loss: 3.4986 - rmse: 3.4984 - val_loss: 4.3718 - val_rmse: 4.3697\n",
            "Epoch 96/500\n",
            "4767/4767 - 21s - loss: 3.4960 - rmse: 3.4956 - val_loss: 4.3607 - val_rmse: 4.3588\n",
            "Epoch 97/500\n",
            "4767/4767 - 21s - loss: 3.4829 - rmse: 3.4826 - val_loss: 4.3697 - val_rmse: 4.3682\n",
            "Epoch 98/500\n",
            "4767/4767 - 21s - loss: 3.4553 - rmse: 3.4553 - val_loss: 4.3819 - val_rmse: 4.3801\n",
            "Epoch 99/500\n",
            "4767/4767 - 21s - loss: 3.4705 - rmse: 3.4703 - val_loss: 4.3746 - val_rmse: 4.3726\n",
            "Epoch 100/500\n",
            "4767/4767 - 21s - loss: 3.4577 - rmse: 3.4575 - val_loss: 4.3645 - val_rmse: 4.3630\n",
            "Epoch 101/500\n",
            "4767/4767 - 21s - loss: 3.4507 - rmse: 3.4507 - val_loss: 4.3702 - val_rmse: 4.3682\n",
            "Epoch 102/500\n",
            "4767/4767 - 21s - loss: 3.4345 - rmse: 3.4341 - val_loss: 4.3798 - val_rmse: 4.3780\n",
            "Epoch 103/500\n",
            "4767/4767 - 21s - loss: 3.4184 - rmse: 3.4181 - val_loss: 4.3829 - val_rmse: 4.3811\n",
            "Epoch 104/500\n",
            "4767/4767 - 23s - loss: 3.4099 - rmse: 3.4099 - val_loss: 4.3897 - val_rmse: 4.3879\n",
            "Epoch 105/500\n",
            "4767/4767 - 25s - loss: 3.3986 - rmse: 3.3984 - val_loss: 4.3722 - val_rmse: 4.3702\n",
            "Epoch 106/500\n",
            "4767/4767 - 22s - loss: 3.4052 - rmse: 3.4054 - val_loss: 4.3819 - val_rmse: 4.3799\n",
            "Train Score: 3.30 RMSE\n",
            "Validation Score: 4.85 RMSE\n",
            "Test Score: 4.89 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "15       16.0\n",
            "23       14.0\n",
            "36       29.3\n",
            "39       24.0\n",
            "43       33.0\n",
            "         ... \n",
            "26422    17.0\n",
            "26427    15.3\n",
            "26459    30.0\n",
            "26470    39.0\n",
            "26474    35.0\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 22s - loss: 8.9332 - rmse: 8.9330 - val_loss: 6.7267 - val_rmse: 6.7283\n",
            "Epoch 2/500\n",
            "4767/4767 - 22s - loss: 6.9546 - rmse: 6.9547 - val_loss: 6.1960 - val_rmse: 6.1974\n",
            "Epoch 3/500\n",
            "4767/4767 - 22s - loss: 6.4388 - rmse: 6.4386 - val_loss: 5.8111 - val_rmse: 5.8121\n",
            "Epoch 4/500\n",
            "4767/4767 - 22s - loss: 6.1112 - rmse: 6.1109 - val_loss: 5.6300 - val_rmse: 5.6312\n",
            "Epoch 5/500\n",
            "4767/4767 - 21s - loss: 5.9031 - rmse: 5.9028 - val_loss: 5.4554 - val_rmse: 5.4563\n",
            "Epoch 6/500\n",
            "4767/4767 - 22s - loss: 5.7796 - rmse: 5.7798 - val_loss: 5.3891 - val_rmse: 5.3898\n",
            "Epoch 7/500\n",
            "4767/4767 - 22s - loss: 5.6793 - rmse: 5.6794 - val_loss: 5.2866 - val_rmse: 5.2869\n",
            "Epoch 8/500\n",
            "4767/4767 - 22s - loss: 5.6471 - rmse: 5.6470 - val_loss: 5.2664 - val_rmse: 5.2670\n",
            "Epoch 9/500\n",
            "4767/4767 - 21s - loss: 5.5581 - rmse: 5.5583 - val_loss: 5.2156 - val_rmse: 5.2166\n",
            "Epoch 10/500\n",
            "4767/4767 - 21s - loss: 5.4892 - rmse: 5.4893 - val_loss: 5.1642 - val_rmse: 5.1642\n",
            "Epoch 11/500\n",
            "4767/4767 - 21s - loss: 5.4586 - rmse: 5.4583 - val_loss: 5.1000 - val_rmse: 5.1002\n",
            "Epoch 12/500\n",
            "4767/4767 - 22s - loss: 5.3935 - rmse: 5.3934 - val_loss: 5.1553 - val_rmse: 5.1561\n",
            "Epoch 13/500\n",
            "4767/4767 - 23s - loss: 5.3467 - rmse: 5.3469 - val_loss: 5.0262 - val_rmse: 5.0265\n",
            "Epoch 14/500\n",
            "4767/4767 - 22s - loss: 5.2908 - rmse: 5.2912 - val_loss: 5.0035 - val_rmse: 5.0033\n",
            "Epoch 15/500\n",
            "4767/4767 - 21s - loss: 5.2610 - rmse: 5.2619 - val_loss: 5.0060 - val_rmse: 5.0068\n",
            "Epoch 16/500\n",
            "4767/4767 - 21s - loss: 5.2102 - rmse: 5.2101 - val_loss: 4.9799 - val_rmse: 4.9805\n",
            "Epoch 17/500\n",
            "4767/4767 - 21s - loss: 5.1571 - rmse: 5.1578 - val_loss: 4.9288 - val_rmse: 4.9289\n",
            "Epoch 18/500\n",
            "4767/4767 - 21s - loss: 5.0781 - rmse: 5.0777 - val_loss: 4.9278 - val_rmse: 4.9286\n",
            "Epoch 19/500\n",
            "4767/4767 - 21s - loss: 5.0874 - rmse: 5.0875 - val_loss: 4.8767 - val_rmse: 4.8766\n",
            "Epoch 20/500\n",
            "4767/4767 - 21s - loss: 5.0353 - rmse: 5.0357 - val_loss: 4.8425 - val_rmse: 4.8431\n",
            "Epoch 21/500\n",
            "4767/4767 - 21s - loss: 4.9824 - rmse: 4.9822 - val_loss: 4.8499 - val_rmse: 4.8507\n",
            "Epoch 22/500\n",
            "4767/4767 - 21s - loss: 4.9332 - rmse: 4.9333 - val_loss: 4.8497 - val_rmse: 4.8507\n",
            "Epoch 23/500\n",
            "4767/4767 - 21s - loss: 4.9318 - rmse: 4.9315 - val_loss: 4.7792 - val_rmse: 4.7797\n",
            "Epoch 24/500\n",
            "4767/4767 - 21s - loss: 4.8548 - rmse: 4.8545 - val_loss: 4.7752 - val_rmse: 4.7758\n",
            "Epoch 25/500\n",
            "4767/4767 - 21s - loss: 4.8496 - rmse: 4.8492 - val_loss: 4.7456 - val_rmse: 4.7463\n",
            "Epoch 26/500\n",
            "4767/4767 - 24s - loss: 4.7995 - rmse: 4.7993 - val_loss: 4.7060 - val_rmse: 4.7069\n",
            "Epoch 27/500\n",
            "4767/4767 - 21s - loss: 4.7558 - rmse: 4.7556 - val_loss: 4.7380 - val_rmse: 4.7389\n",
            "Epoch 28/500\n",
            "4767/4767 - 28s - loss: 4.6968 - rmse: 4.6967 - val_loss: 4.6952 - val_rmse: 4.6958\n",
            "Epoch 29/500\n",
            "4767/4767 - 21s - loss: 4.6606 - rmse: 4.6608 - val_loss: 4.6756 - val_rmse: 4.6762\n",
            "Epoch 30/500\n",
            "4767/4767 - 21s - loss: 4.6590 - rmse: 4.6590 - val_loss: 4.6846 - val_rmse: 4.6857\n",
            "Epoch 31/500\n",
            "4767/4767 - 21s - loss: 4.6006 - rmse: 4.6007 - val_loss: 4.6845 - val_rmse: 4.6858\n",
            "Epoch 32/500\n",
            "4767/4767 - 21s - loss: 4.5958 - rmse: 4.5956 - val_loss: 4.6478 - val_rmse: 4.6488\n",
            "Epoch 33/500\n",
            "4767/4767 - 21s - loss: 4.5413 - rmse: 4.5415 - val_loss: 4.6671 - val_rmse: 4.6681\n",
            "Epoch 34/500\n",
            "4767/4767 - 21s - loss: 4.5051 - rmse: 4.5053 - val_loss: 4.5906 - val_rmse: 4.5919\n",
            "Epoch 35/500\n",
            "4767/4767 - 21s - loss: 4.4646 - rmse: 4.4644 - val_loss: 4.6079 - val_rmse: 4.6089\n",
            "Epoch 36/500\n",
            "4767/4767 - 22s - loss: 4.4387 - rmse: 4.4382 - val_loss: 4.5785 - val_rmse: 4.5791\n",
            "Epoch 37/500\n",
            "4767/4767 - 22s - loss: 4.3937 - rmse: 4.3937 - val_loss: 4.5649 - val_rmse: 4.5658\n",
            "Epoch 38/500\n",
            "4767/4767 - 21s - loss: 4.3855 - rmse: 4.3858 - val_loss: 4.5849 - val_rmse: 4.5864\n",
            "Epoch 39/500\n",
            "4767/4767 - 21s - loss: 4.3622 - rmse: 4.3618 - val_loss: 4.5472 - val_rmse: 4.5479\n",
            "Epoch 40/500\n",
            "4767/4767 - 23s - loss: 4.3136 - rmse: 4.3139 - val_loss: 4.6656 - val_rmse: 4.6669\n",
            "Epoch 41/500\n",
            "4767/4767 - 23s - loss: 4.2751 - rmse: 4.2750 - val_loss: 4.5470 - val_rmse: 4.5482\n",
            "Epoch 42/500\n",
            "4767/4767 - 23s - loss: 4.2483 - rmse: 4.2486 - val_loss: 4.5433 - val_rmse: 4.5441\n",
            "Epoch 43/500\n",
            "4767/4767 - 24s - loss: 4.2188 - rmse: 4.2187 - val_loss: 4.5158 - val_rmse: 4.5171\n",
            "Epoch 44/500\n",
            "4767/4767 - 21s - loss: 4.1872 - rmse: 4.1873 - val_loss: 4.4989 - val_rmse: 4.5001\n",
            "Epoch 45/500\n",
            "4767/4767 - 22s - loss: 4.1749 - rmse: 4.1747 - val_loss: 4.5064 - val_rmse: 4.5073\n",
            "Epoch 46/500\n",
            "4767/4767 - 22s - loss: 4.1524 - rmse: 4.1524 - val_loss: 4.4980 - val_rmse: 4.4991\n",
            "Epoch 47/500\n",
            "4767/4767 - 22s - loss: 4.1186 - rmse: 4.1185 - val_loss: 4.4799 - val_rmse: 4.4810\n",
            "Epoch 48/500\n",
            "4767/4767 - 21s - loss: 4.0875 - rmse: 4.0877 - val_loss: 4.4853 - val_rmse: 4.4865\n",
            "Epoch 49/500\n",
            "4767/4767 - 21s - loss: 4.0821 - rmse: 4.0818 - val_loss: 4.4762 - val_rmse: 4.4775\n",
            "Epoch 50/500\n",
            "4767/4767 - 22s - loss: 4.0789 - rmse: 4.0792 - val_loss: 4.4592 - val_rmse: 4.4603\n",
            "Epoch 51/500\n",
            "4767/4767 - 21s - loss: 4.0082 - rmse: 4.0087 - val_loss: 4.4499 - val_rmse: 4.4512\n",
            "Epoch 52/500\n",
            "4767/4767 - 21s - loss: 3.9873 - rmse: 3.9880 - val_loss: 4.4433 - val_rmse: 4.4445\n",
            "Epoch 53/500\n",
            "4767/4767 - 21s - loss: 3.9810 - rmse: 3.9819 - val_loss: 4.4868 - val_rmse: 4.4882\n",
            "Epoch 54/500\n",
            "4767/4767 - 23s - loss: 3.9596 - rmse: 3.9598 - val_loss: 4.4424 - val_rmse: 4.4435\n",
            "Epoch 55/500\n",
            "4767/4767 - 23s - loss: 3.9426 - rmse: 3.9425 - val_loss: 4.4347 - val_rmse: 4.4362\n",
            "Epoch 56/500\n",
            "4767/4767 - 24s - loss: 3.9377 - rmse: 3.9381 - val_loss: 4.4762 - val_rmse: 4.4777\n",
            "Epoch 57/500\n",
            "4767/4767 - 26s - loss: 3.9055 - rmse: 3.9053 - val_loss: 4.4013 - val_rmse: 4.4021\n",
            "Epoch 58/500\n",
            "4767/4767 - 22s - loss: 3.9174 - rmse: 3.9180 - val_loss: 4.4202 - val_rmse: 4.4212\n",
            "Epoch 59/500\n",
            "4767/4767 - 21s - loss: 3.8985 - rmse: 3.8983 - val_loss: 4.4239 - val_rmse: 4.4250\n",
            "Epoch 60/500\n",
            "4767/4767 - 21s - loss: 3.8738 - rmse: 3.8740 - val_loss: 4.4161 - val_rmse: 4.4171\n",
            "Epoch 61/500\n",
            "4767/4767 - 21s - loss: 3.8538 - rmse: 3.8535 - val_loss: 4.4181 - val_rmse: 4.4189\n",
            "Epoch 62/500\n",
            "4767/4767 - 21s - loss: 3.8439 - rmse: 3.8437 - val_loss: 4.4032 - val_rmse: 4.4041\n",
            "Epoch 63/500\n",
            "4767/4767 - 21s - loss: 3.8334 - rmse: 3.8333 - val_loss: 4.4391 - val_rmse: 4.4405\n",
            "Epoch 64/500\n",
            "4767/4767 - 21s - loss: 3.7919 - rmse: 3.7917 - val_loss: 4.4103 - val_rmse: 4.4109\n",
            "Epoch 65/500\n",
            "4767/4767 - 21s - loss: 3.7719 - rmse: 3.7722 - val_loss: 4.4091 - val_rmse: 4.4099\n",
            "Epoch 66/500\n",
            "4767/4767 - 21s - loss: 3.7841 - rmse: 3.7841 - val_loss: 4.3990 - val_rmse: 4.4000\n",
            "Epoch 67/500\n",
            "4767/4767 - 21s - loss: 3.7733 - rmse: 3.7731 - val_loss: 4.3712 - val_rmse: 4.3719\n",
            "Epoch 68/500\n",
            "4767/4767 - 22s - loss: 3.7325 - rmse: 3.7323 - val_loss: 4.3890 - val_rmse: 4.3901\n",
            "Epoch 69/500\n",
            "4767/4767 - 23s - loss: 3.7458 - rmse: 3.7456 - val_loss: 4.3675 - val_rmse: 4.3686\n",
            "Epoch 70/500\n",
            "4767/4767 - 21s - loss: 3.7191 - rmse: 3.7186 - val_loss: 4.3542 - val_rmse: 4.3548\n",
            "Epoch 71/500\n",
            "4767/4767 - 21s - loss: 3.7166 - rmse: 3.7171 - val_loss: 4.3616 - val_rmse: 4.3626\n",
            "Epoch 72/500\n",
            "4767/4767 - 23s - loss: 3.6923 - rmse: 3.6927 - val_loss: 4.3587 - val_rmse: 4.3597\n",
            "Epoch 73/500\n",
            "4767/4767 - 22s - loss: 3.6856 - rmse: 3.6861 - val_loss: 4.3353 - val_rmse: 4.3363\n",
            "Epoch 74/500\n",
            "4767/4767 - 21s - loss: 3.6956 - rmse: 3.6954 - val_loss: 4.3811 - val_rmse: 4.3823\n",
            "Epoch 75/500\n",
            "4767/4767 - 21s - loss: 3.6690 - rmse: 3.6691 - val_loss: 4.3688 - val_rmse: 4.3701\n",
            "Epoch 76/500\n",
            "4767/4767 - 21s - loss: 3.6512 - rmse: 3.6509 - val_loss: 4.3294 - val_rmse: 4.3304\n",
            "Epoch 77/500\n",
            "4767/4767 - 21s - loss: 3.6339 - rmse: 3.6335 - val_loss: 4.3686 - val_rmse: 4.3701\n",
            "Epoch 78/500\n",
            "4767/4767 - 21s - loss: 3.6458 - rmse: 3.6455 - val_loss: 4.3383 - val_rmse: 4.3393\n",
            "Epoch 79/500\n",
            "4767/4767 - 21s - loss: 3.6224 - rmse: 3.6222 - val_loss: 4.3376 - val_rmse: 4.3387\n",
            "Epoch 80/500\n",
            "4767/4767 - 21s - loss: 3.5885 - rmse: 3.5887 - val_loss: 4.3572 - val_rmse: 4.3586\n",
            "Epoch 81/500\n",
            "4767/4767 - 21s - loss: 3.5869 - rmse: 3.5867 - val_loss: 4.3293 - val_rmse: 4.3305\n",
            "Epoch 82/500\n",
            "4767/4767 - 21s - loss: 3.5904 - rmse: 3.5902 - val_loss: 4.3222 - val_rmse: 4.3232\n",
            "Epoch 83/500\n",
            "4767/4767 - 23s - loss: 3.5759 - rmse: 3.5767 - val_loss: 4.3454 - val_rmse: 4.3469\n",
            "Epoch 84/500\n",
            "4767/4767 - 21s - loss: 3.5593 - rmse: 3.5590 - val_loss: 4.3469 - val_rmse: 4.3479\n",
            "Epoch 85/500\n",
            "4767/4767 - 23s - loss: 3.5616 - rmse: 3.5613 - val_loss: 4.3468 - val_rmse: 4.3479\n",
            "Epoch 86/500\n",
            "4767/4767 - 21s - loss: 3.5762 - rmse: 3.5759 - val_loss: 4.3421 - val_rmse: 4.3430\n",
            "Epoch 87/500\n",
            "4767/4767 - 23s - loss: 3.5541 - rmse: 3.5540 - val_loss: 4.3818 - val_rmse: 4.3831\n",
            "Epoch 88/500\n",
            "4767/4767 - 23s - loss: 3.5364 - rmse: 3.5360 - val_loss: 4.3339 - val_rmse: 4.3351\n",
            "Epoch 89/500\n",
            "4767/4767 - 21s - loss: 3.5182 - rmse: 3.5182 - val_loss: 4.3461 - val_rmse: 4.3474\n",
            "Epoch 90/500\n",
            "4767/4767 - 21s - loss: 3.4897 - rmse: 3.4894 - val_loss: 4.3747 - val_rmse: 4.3756\n",
            "Epoch 91/500\n",
            "4767/4767 - 21s - loss: 3.5091 - rmse: 3.5089 - val_loss: 4.3234 - val_rmse: 4.3242\n",
            "Epoch 92/500\n",
            "4767/4767 - 21s - loss: 3.5249 - rmse: 3.5246 - val_loss: 4.3227 - val_rmse: 4.3235\n",
            "Train Score: 3.37 RMSE\n",
            "Validation Score: 4.84 RMSE\n",
            "Test Score: 4.93 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:115: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:121: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "2        24.0\n",
            "7        23.0\n",
            "10       33.0\n",
            "12       10.0\n",
            "21       19.0\n",
            "         ... \n",
            "26383    23.2\n",
            "26398     7.7\n",
            "26423    11.0\n",
            "26473    23.0\n",
            "26479    25.5\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 21s - loss: 8.9087 - rmse: 8.9089 - val_loss: 6.7173 - val_rmse: 6.7176\n",
            "Epoch 2/500\n",
            "4767/4767 - 21s - loss: 6.9856 - rmse: 6.9856 - val_loss: 6.1395 - val_rmse: 6.1388\n",
            "Epoch 3/500\n",
            "4767/4767 - 21s - loss: 6.4435 - rmse: 6.4429 - val_loss: 5.7261 - val_rmse: 5.7241\n",
            "Epoch 4/500\n",
            "4767/4767 - 20s - loss: 6.1195 - rmse: 6.1202 - val_loss: 5.5590 - val_rmse: 5.5561\n",
            "Epoch 5/500\n",
            "4767/4767 - 21s - loss: 5.9219 - rmse: 5.9217 - val_loss: 5.3495 - val_rmse: 5.3475\n",
            "Epoch 6/500\n",
            "4767/4767 - 20s - loss: 5.7987 - rmse: 5.7983 - val_loss: 5.2587 - val_rmse: 5.2563\n",
            "Epoch 7/500\n",
            "4767/4767 - 20s - loss: 5.6849 - rmse: 5.6842 - val_loss: 5.1786 - val_rmse: 5.1757\n",
            "Epoch 8/500\n",
            "4767/4767 - 20s - loss: 5.6774 - rmse: 5.6769 - val_loss: 5.1692 - val_rmse: 5.1662\n",
            "Epoch 9/500\n",
            "4767/4767 - 20s - loss: 5.5710 - rmse: 5.5713 - val_loss: 5.1087 - val_rmse: 5.1069\n",
            "Epoch 10/500\n",
            "4767/4767 - 20s - loss: 5.5003 - rmse: 5.5001 - val_loss: 5.0697 - val_rmse: 5.0675\n",
            "Epoch 11/500\n",
            "4767/4767 - 22s - loss: 5.4537 - rmse: 5.4539 - val_loss: 5.0838 - val_rmse: 5.0816\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.4024 - rmse: 5.4029 - val_loss: 5.0069 - val_rmse: 5.0045\n",
            "Epoch 13/500\n",
            "4767/4767 - 20s - loss: 5.3221 - rmse: 5.3217 - val_loss: 4.9848 - val_rmse: 4.9830\n",
            "Epoch 14/500\n",
            "4767/4767 - 20s - loss: 5.2883 - rmse: 5.2880 - val_loss: 4.9519 - val_rmse: 4.9497\n",
            "Epoch 15/500\n",
            "4767/4767 - 20s - loss: 5.2669 - rmse: 5.2664 - val_loss: 4.9620 - val_rmse: 4.9601\n",
            "Epoch 16/500\n",
            "4767/4767 - 20s - loss: 5.2045 - rmse: 5.2052 - val_loss: 4.9612 - val_rmse: 4.9597\n",
            "Epoch 17/500\n",
            "4767/4767 - 19s - loss: 5.1256 - rmse: 5.1255 - val_loss: 4.8968 - val_rmse: 4.8949\n",
            "Epoch 18/500\n",
            "4767/4767 - 19s - loss: 5.0959 - rmse: 5.0960 - val_loss: 4.8795 - val_rmse: 4.8777\n",
            "Epoch 19/500\n",
            "4767/4767 - 20s - loss: 5.0716 - rmse: 5.0720 - val_loss: 4.8544 - val_rmse: 4.8530\n",
            "Epoch 20/500\n",
            "4767/4767 - 19s - loss: 5.0386 - rmse: 5.0383 - val_loss: 4.8245 - val_rmse: 4.8225\n",
            "Epoch 21/500\n",
            "4767/4767 - 21s - loss: 4.9801 - rmse: 4.9800 - val_loss: 4.8128 - val_rmse: 4.8112\n",
            "Epoch 22/500\n",
            "4767/4767 - 22s - loss: 4.9317 - rmse: 4.9321 - val_loss: 4.7816 - val_rmse: 4.7798\n",
            "Epoch 23/500\n",
            "4767/4767 - 20s - loss: 4.8994 - rmse: 4.8994 - val_loss: 4.7574 - val_rmse: 4.7555\n",
            "Epoch 24/500\n",
            "4767/4767 - 20s - loss: 4.8799 - rmse: 4.8795 - val_loss: 4.7371 - val_rmse: 4.7352\n",
            "Epoch 25/500\n",
            "4767/4767 - 20s - loss: 4.7904 - rmse: 4.7904 - val_loss: 4.7082 - val_rmse: 4.7061\n",
            "Epoch 26/500\n",
            "4767/4767 - 20s - loss: 4.7888 - rmse: 4.7883 - val_loss: 4.6956 - val_rmse: 4.6934\n",
            "Epoch 27/500\n",
            "4767/4767 - 23s - loss: 4.7434 - rmse: 4.7432 - val_loss: 4.6648 - val_rmse: 4.6625\n",
            "Epoch 28/500\n",
            "4767/4767 - 20s - loss: 4.6913 - rmse: 4.6913 - val_loss: 4.6591 - val_rmse: 4.6570\n",
            "Epoch 29/500\n",
            "4767/4767 - 20s - loss: 4.6667 - rmse: 4.6662 - val_loss: 4.6510 - val_rmse: 4.6492\n",
            "Epoch 30/500\n",
            "4767/4767 - 20s - loss: 4.6377 - rmse: 4.6374 - val_loss: 4.5997 - val_rmse: 4.5977\n",
            "Epoch 31/500\n",
            "4767/4767 - 20s - loss: 4.5969 - rmse: 4.5966 - val_loss: 4.5897 - val_rmse: 4.5880\n",
            "Epoch 32/500\n",
            "4767/4767 - 20s - loss: 4.5597 - rmse: 4.5592 - val_loss: 4.5760 - val_rmse: 4.5740\n",
            "Epoch 33/500\n",
            "4767/4767 - 21s - loss: 4.5272 - rmse: 4.5274 - val_loss: 4.5723 - val_rmse: 4.5707\n",
            "Epoch 34/500\n",
            "4767/4767 - 20s - loss: 4.4512 - rmse: 4.4513 - val_loss: 4.5324 - val_rmse: 4.5300\n",
            "Epoch 35/500\n",
            "4767/4767 - 20s - loss: 4.4653 - rmse: 4.4650 - val_loss: 4.5357 - val_rmse: 4.5336\n",
            "Epoch 36/500\n",
            "4767/4767 - 21s - loss: 4.3956 - rmse: 4.3955 - val_loss: 4.5214 - val_rmse: 4.5194\n",
            "Epoch 37/500\n",
            "4767/4767 - 20s - loss: 4.3877 - rmse: 4.3878 - val_loss: 4.5088 - val_rmse: 4.5071\n",
            "Epoch 38/500\n",
            "4767/4767 - 20s - loss: 4.3450 - rmse: 4.3448 - val_loss: 4.4847 - val_rmse: 4.4829\n",
            "Epoch 39/500\n",
            "4767/4767 - 20s - loss: 4.3007 - rmse: 4.3011 - val_loss: 4.4748 - val_rmse: 4.4727\n",
            "Epoch 40/500\n",
            "4767/4767 - 20s - loss: 4.2859 - rmse: 4.2857 - val_loss: 4.4703 - val_rmse: 4.4680\n",
            "Epoch 41/500\n",
            "4767/4767 - 20s - loss: 4.2501 - rmse: 4.2496 - val_loss: 4.5266 - val_rmse: 4.5247\n",
            "Epoch 42/500\n",
            "4767/4767 - 22s - loss: 4.2281 - rmse: 4.2281 - val_loss: 4.4289 - val_rmse: 4.4267\n",
            "Epoch 43/500\n",
            "4767/4767 - 23s - loss: 4.2056 - rmse: 4.2054 - val_loss: 4.4147 - val_rmse: 4.4126\n",
            "Epoch 44/500\n",
            "4767/4767 - 21s - loss: 4.1886 - rmse: 4.1881 - val_loss: 4.4374 - val_rmse: 4.4352\n",
            "Epoch 45/500\n",
            "4767/4767 - 20s - loss: 4.1412 - rmse: 4.1409 - val_loss: 4.4052 - val_rmse: 4.4035\n",
            "Epoch 46/500\n",
            "4767/4767 - 20s - loss: 4.1478 - rmse: 4.1475 - val_loss: 4.3871 - val_rmse: 4.3850\n",
            "Epoch 47/500\n",
            "4767/4767 - 20s - loss: 4.1002 - rmse: 4.1004 - val_loss: 4.3891 - val_rmse: 4.3871\n",
            "Epoch 48/500\n",
            "4767/4767 - 20s - loss: 4.0804 - rmse: 4.0803 - val_loss: 4.4443 - val_rmse: 4.4428\n",
            "Epoch 49/500\n",
            "4767/4767 - 20s - loss: 4.0612 - rmse: 4.0611 - val_loss: 4.3836 - val_rmse: 4.3816\n",
            "Epoch 50/500\n",
            "4767/4767 - 20s - loss: 4.0532 - rmse: 4.0528 - val_loss: 4.4086 - val_rmse: 4.4068\n",
            "Epoch 51/500\n",
            "4767/4767 - 23s - loss: 4.0272 - rmse: 4.0269 - val_loss: 4.3525 - val_rmse: 4.3506\n",
            "Epoch 52/500\n",
            "4767/4767 - 23s - loss: 4.0211 - rmse: 4.0206 - val_loss: 4.3346 - val_rmse: 4.3322\n",
            "Epoch 53/500\n",
            "4767/4767 - 21s - loss: 3.9808 - rmse: 3.9812 - val_loss: 4.3372 - val_rmse: 4.3353\n",
            "Epoch 54/500\n",
            "4767/4767 - 20s - loss: 3.9562 - rmse: 3.9557 - val_loss: 4.3411 - val_rmse: 4.3389\n",
            "Epoch 55/500\n",
            "4767/4767 - 21s - loss: 3.9563 - rmse: 3.9565 - val_loss: 4.3449 - val_rmse: 4.3429\n",
            "Epoch 56/500\n",
            "4767/4767 - 21s - loss: 3.9225 - rmse: 3.9221 - val_loss: 4.3051 - val_rmse: 4.3028\n",
            "Epoch 57/500\n",
            "4767/4767 - 20s - loss: 3.9052 - rmse: 3.9049 - val_loss: 4.3134 - val_rmse: 4.3110\n",
            "Epoch 58/500\n",
            "4767/4767 - 26s - loss: 3.8892 - rmse: 3.8890 - val_loss: 4.3094 - val_rmse: 4.3072\n",
            "Epoch 59/500\n",
            "4767/4767 - 22s - loss: 3.8898 - rmse: 3.8897 - val_loss: 4.3675 - val_rmse: 4.3655\n",
            "Epoch 60/500\n",
            "4767/4767 - 21s - loss: 3.8529 - rmse: 3.8529 - val_loss: 4.3079 - val_rmse: 4.3056\n",
            "Epoch 61/500\n",
            "4767/4767 - 20s - loss: 3.8347 - rmse: 3.8351 - val_loss: 4.2905 - val_rmse: 4.2880\n",
            "Epoch 62/500\n",
            "4767/4767 - 20s - loss: 3.8331 - rmse: 3.8329 - val_loss: 4.3043 - val_rmse: 4.3021\n",
            "Epoch 63/500\n",
            "4767/4767 - 19s - loss: 3.8152 - rmse: 3.8148 - val_loss: 4.2719 - val_rmse: 4.2697\n",
            "Epoch 64/500\n",
            "4767/4767 - 20s - loss: 3.7836 - rmse: 3.7836 - val_loss: 4.2905 - val_rmse: 4.2886\n",
            "Epoch 65/500\n",
            "4767/4767 - 20s - loss: 3.7912 - rmse: 3.7909 - val_loss: 4.2819 - val_rmse: 4.2800\n",
            "Epoch 66/500\n",
            "4767/4767 - 21s - loss: 3.7529 - rmse: 3.7527 - val_loss: 4.3046 - val_rmse: 4.3024\n",
            "Epoch 67/500\n",
            "4767/4767 - 20s - loss: 3.7803 - rmse: 3.7803 - val_loss: 4.2788 - val_rmse: 4.2761\n",
            "Epoch 68/500\n",
            "4767/4767 - 20s - loss: 3.7426 - rmse: 3.7423 - val_loss: 4.2793 - val_rmse: 4.2768\n",
            "Epoch 69/500\n",
            "4767/4767 - 20s - loss: 3.7350 - rmse: 3.7348 - val_loss: 4.3261 - val_rmse: 4.3238\n",
            "Epoch 70/500\n",
            "4767/4767 - 20s - loss: 3.6943 - rmse: 3.6941 - val_loss: 4.2816 - val_rmse: 4.2789\n",
            "Epoch 71/500\n",
            "4767/4767 - 20s - loss: 3.7094 - rmse: 3.7092 - val_loss: 4.3027 - val_rmse: 4.3005\n",
            "Epoch 72/500\n",
            "4767/4767 - 20s - loss: 3.6842 - rmse: 3.6844 - val_loss: 4.2848 - val_rmse: 4.2821\n",
            "Epoch 73/500\n",
            "4767/4767 - 20s - loss: 3.7212 - rmse: 3.7210 - val_loss: 4.3120 - val_rmse: 4.3097\n",
            "Train Score: 3.60 RMSE\n",
            "Validation Score: 4.76 RMSE\n",
            "Test Score: 4.96 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:125: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:131: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "1        43.0\n",
            "18       46.0\n",
            "48       36.1\n",
            "66       33.9\n",
            "74       18.0\n",
            "         ... \n",
            "26412    14.0\n",
            "26416    27.8\n",
            "26426    16.3\n",
            "26446    13.3\n",
            "26453    18.0\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 24s - loss: 8.8920 - rmse: 8.8912 - val_loss: 6.5140 - val_rmse: 6.5128\n",
            "Epoch 2/500\n",
            "4767/4767 - 20s - loss: 6.9689 - rmse: 6.9684 - val_loss: 6.0579 - val_rmse: 6.0560\n",
            "Epoch 3/500\n",
            "4767/4767 - 20s - loss: 6.4432 - rmse: 6.4431 - val_loss: 5.5425 - val_rmse: 5.5402\n",
            "Epoch 4/500\n",
            "4767/4767 - 20s - loss: 6.1311 - rmse: 6.1318 - val_loss: 5.3036 - val_rmse: 5.3011\n",
            "Epoch 5/500\n",
            "4767/4767 - 20s - loss: 5.9527 - rmse: 5.9524 - val_loss: 5.1183 - val_rmse: 5.1159\n",
            "Epoch 6/500\n",
            "4767/4767 - 20s - loss: 5.8311 - rmse: 5.8318 - val_loss: 5.0541 - val_rmse: 5.0517\n",
            "Epoch 7/500\n",
            "4767/4767 - 23s - loss: 5.7213 - rmse: 5.7217 - val_loss: 5.0544 - val_rmse: 5.0522\n",
            "Epoch 8/500\n",
            "4767/4767 - 23s - loss: 5.6321 - rmse: 5.6317 - val_loss: 4.9282 - val_rmse: 4.9264\n",
            "Epoch 9/500\n",
            "4767/4767 - 20s - loss: 5.5780 - rmse: 5.5781 - val_loss: 4.8472 - val_rmse: 4.8455\n",
            "Epoch 10/500\n",
            "4767/4767 - 21s - loss: 5.5383 - rmse: 5.5394 - val_loss: 4.8275 - val_rmse: 4.8257\n",
            "Epoch 11/500\n",
            "4767/4767 - 21s - loss: 5.4764 - rmse: 5.4770 - val_loss: 4.8199 - val_rmse: 4.8183\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.4179 - rmse: 5.4180 - val_loss: 4.7520 - val_rmse: 4.7504\n",
            "Epoch 13/500\n",
            "4767/4767 - 20s - loss: 5.3777 - rmse: 5.3777 - val_loss: 4.7250 - val_rmse: 4.7237\n",
            "Epoch 14/500\n",
            "4767/4767 - 20s - loss: 5.3254 - rmse: 5.3256 - val_loss: 4.6906 - val_rmse: 4.6894\n",
            "Epoch 15/500\n",
            "4767/4767 - 20s - loss: 5.2721 - rmse: 5.2719 - val_loss: 4.6879 - val_rmse: 4.6865\n",
            "Epoch 16/500\n",
            "4767/4767 - 22s - loss: 5.2142 - rmse: 5.2139 - val_loss: 4.7151 - val_rmse: 4.7136\n",
            "Epoch 17/500\n",
            "4767/4767 - 21s - loss: 5.1527 - rmse: 5.1522 - val_loss: 4.6787 - val_rmse: 4.6774\n",
            "Epoch 18/500\n",
            "4767/4767 - 20s - loss: 5.1230 - rmse: 5.1224 - val_loss: 4.6898 - val_rmse: 4.6886\n",
            "Epoch 19/500\n",
            "4767/4767 - 20s - loss: 5.1086 - rmse: 5.1090 - val_loss: 4.5944 - val_rmse: 4.5931\n",
            "Epoch 20/500\n",
            "4767/4767 - 20s - loss: 5.0524 - rmse: 5.0526 - val_loss: 4.5870 - val_rmse: 4.5857\n",
            "Epoch 21/500\n",
            "4767/4767 - 20s - loss: 5.0027 - rmse: 5.0025 - val_loss: 4.5744 - val_rmse: 4.5734\n",
            "Epoch 22/500\n",
            "4767/4767 - 21s - loss: 4.9704 - rmse: 4.9704 - val_loss: 4.5501 - val_rmse: 4.5486\n",
            "Epoch 23/500\n",
            "4767/4767 - 21s - loss: 4.9171 - rmse: 4.9169 - val_loss: 4.5320 - val_rmse: 4.5304\n",
            "Epoch 24/500\n",
            "4767/4767 - 20s - loss: 4.8753 - rmse: 4.8749 - val_loss: 4.5442 - val_rmse: 4.5428\n",
            "Epoch 25/500\n",
            "4767/4767 - 20s - loss: 4.8263 - rmse: 4.8263 - val_loss: 4.5212 - val_rmse: 4.5200\n",
            "Epoch 26/500\n",
            "4767/4767 - 21s - loss: 4.7866 - rmse: 4.7863 - val_loss: 4.4998 - val_rmse: 4.4985\n",
            "Epoch 27/500\n",
            "4767/4767 - 20s - loss: 4.7549 - rmse: 4.7550 - val_loss: 4.5171 - val_rmse: 4.5156\n",
            "Epoch 28/500\n",
            "4767/4767 - 20s - loss: 4.7154 - rmse: 4.7165 - val_loss: 4.4986 - val_rmse: 4.4972\n",
            "Epoch 29/500\n",
            "4767/4767 - 20s - loss: 4.6839 - rmse: 4.6835 - val_loss: 4.4477 - val_rmse: 4.4464\n",
            "Epoch 30/500\n",
            "4767/4767 - 20s - loss: 4.6520 - rmse: 4.6521 - val_loss: 4.4579 - val_rmse: 4.4564\n",
            "Epoch 31/500\n",
            "4767/4767 - 20s - loss: 4.6339 - rmse: 4.6337 - val_loss: 4.4270 - val_rmse: 4.4256\n",
            "Epoch 32/500\n",
            "4767/4767 - 22s - loss: 4.5693 - rmse: 4.5705 - val_loss: 4.4008 - val_rmse: 4.3995\n",
            "Epoch 33/500\n",
            "4767/4767 - 21s - loss: 4.5338 - rmse: 4.5335 - val_loss: 4.4131 - val_rmse: 4.4114\n",
            "Epoch 34/500\n",
            "4767/4767 - 20s - loss: 4.4828 - rmse: 4.4824 - val_loss: 4.4133 - val_rmse: 4.4121\n",
            "Epoch 35/500\n",
            "4767/4767 - 20s - loss: 4.4610 - rmse: 4.4607 - val_loss: 4.3739 - val_rmse: 4.3725\n",
            "Epoch 36/500\n",
            "4767/4767 - 20s - loss: 4.4350 - rmse: 4.4351 - val_loss: 4.3582 - val_rmse: 4.3566\n",
            "Epoch 37/500\n",
            "4767/4767 - 19s - loss: 4.4038 - rmse: 4.4036 - val_loss: 4.3679 - val_rmse: 4.3662\n",
            "Epoch 38/500\n",
            "4767/4767 - 22s - loss: 4.3738 - rmse: 4.3740 - val_loss: 4.4327 - val_rmse: 4.4309\n",
            "Epoch 39/500\n",
            "4767/4767 - 20s - loss: 4.3270 - rmse: 4.3265 - val_loss: 4.3299 - val_rmse: 4.3281\n",
            "Epoch 40/500\n",
            "4767/4767 - 19s - loss: 4.2900 - rmse: 4.2899 - val_loss: 4.3144 - val_rmse: 4.3125\n",
            "Epoch 41/500\n",
            "4767/4767 - 20s - loss: 4.2702 - rmse: 4.2703 - val_loss: 4.3167 - val_rmse: 4.3152\n",
            "Epoch 42/500\n",
            "4767/4767 - 20s - loss: 4.2456 - rmse: 4.2453 - val_loss: 4.3284 - val_rmse: 4.3271\n",
            "Epoch 43/500\n",
            "4767/4767 - 20s - loss: 4.2157 - rmse: 4.2155 - val_loss: 4.2867 - val_rmse: 4.2850\n",
            "Epoch 44/500\n",
            "4767/4767 - 20s - loss: 4.1914 - rmse: 4.1917 - val_loss: 4.2946 - val_rmse: 4.2931\n",
            "Epoch 45/500\n",
            "4767/4767 - 20s - loss: 4.1724 - rmse: 4.1723 - val_loss: 4.2624 - val_rmse: 4.2606\n",
            "Epoch 46/500\n",
            "4767/4767 - 20s - loss: 4.1405 - rmse: 4.1404 - val_loss: 4.2877 - val_rmse: 4.2861\n",
            "Epoch 47/500\n",
            "4767/4767 - 20s - loss: 4.1238 - rmse: 4.1238 - val_loss: 4.2442 - val_rmse: 4.2427\n",
            "Epoch 48/500\n",
            "4767/4767 - 23s - loss: 4.1105 - rmse: 4.1103 - val_loss: 4.2390 - val_rmse: 4.2376\n",
            "Epoch 49/500\n",
            "4767/4767 - 21s - loss: 4.0542 - rmse: 4.0543 - val_loss: 4.2487 - val_rmse: 4.2473\n",
            "Epoch 50/500\n",
            "4767/4767 - 20s - loss: 4.0232 - rmse: 4.0230 - val_loss: 4.2186 - val_rmse: 4.2171\n",
            "Epoch 51/500\n",
            "4767/4767 - 20s - loss: 4.0100 - rmse: 4.0097 - val_loss: 4.2643 - val_rmse: 4.2630\n",
            "Epoch 52/500\n",
            "4767/4767 - 20s - loss: 3.9903 - rmse: 3.9904 - val_loss: 4.2278 - val_rmse: 4.2263\n",
            "Epoch 53/500\n",
            "4767/4767 - 21s - loss: 3.9814 - rmse: 3.9813 - val_loss: 4.2428 - val_rmse: 4.2413\n",
            "Epoch 54/500\n",
            "4767/4767 - 20s - loss: 3.9582 - rmse: 3.9578 - val_loss: 4.2211 - val_rmse: 4.2197\n",
            "Epoch 55/500\n",
            "4767/4767 - 20s - loss: 3.9391 - rmse: 3.9393 - val_loss: 4.2202 - val_rmse: 4.2187\n",
            "Epoch 56/500\n",
            "4767/4767 - 20s - loss: 3.9156 - rmse: 3.9152 - val_loss: 4.2030 - val_rmse: 4.2018\n",
            "Epoch 57/500\n",
            "4767/4767 - 19s - loss: 3.9004 - rmse: 3.9006 - val_loss: 4.1840 - val_rmse: 4.1828\n",
            "Epoch 58/500\n",
            "4767/4767 - 20s - loss: 3.8922 - rmse: 3.8927 - val_loss: 4.2061 - val_rmse: 4.2049\n",
            "Epoch 59/500\n",
            "4767/4767 - 20s - loss: 3.8546 - rmse: 3.8550 - val_loss: 4.1997 - val_rmse: 4.1984\n",
            "Epoch 60/500\n",
            "4767/4767 - 20s - loss: 3.8436 - rmse: 3.8433 - val_loss: 4.2018 - val_rmse: 4.2005\n",
            "Epoch 61/500\n",
            "4767/4767 - 20s - loss: 3.8327 - rmse: 3.8327 - val_loss: 4.2070 - val_rmse: 4.2057\n",
            "Epoch 62/500\n",
            "4767/4767 - 20s - loss: 3.8287 - rmse: 3.8287 - val_loss: 4.1829 - val_rmse: 4.1814\n",
            "Epoch 63/500\n",
            "4767/4767 - 19s - loss: 3.8214 - rmse: 3.8210 - val_loss: 4.1941 - val_rmse: 4.1929\n",
            "Epoch 64/500\n",
            "4767/4767 - 21s - loss: 3.8005 - rmse: 3.8001 - val_loss: 4.1969 - val_rmse: 4.1958\n",
            "Epoch 65/500\n",
            "4767/4767 - 21s - loss: 3.7829 - rmse: 3.7826 - val_loss: 4.1673 - val_rmse: 4.1659\n",
            "Epoch 66/500\n",
            "4767/4767 - 19s - loss: 3.7805 - rmse: 3.7804 - val_loss: 4.1702 - val_rmse: 4.1687\n",
            "Epoch 67/500\n",
            "4767/4767 - 19s - loss: 3.7523 - rmse: 3.7523 - val_loss: 4.1610 - val_rmse: 4.1591\n",
            "Epoch 68/500\n",
            "4767/4767 - 23s - loss: 3.7429 - rmse: 3.7427 - val_loss: 4.2098 - val_rmse: 4.2084\n",
            "Epoch 69/500\n",
            "4767/4767 - 20s - loss: 3.7261 - rmse: 3.7259 - val_loss: 4.2023 - val_rmse: 4.2011\n",
            "Epoch 70/500\n",
            "4767/4767 - 20s - loss: 3.7045 - rmse: 3.7045 - val_loss: 4.1898 - val_rmse: 4.1885\n",
            "Epoch 71/500\n",
            "4767/4767 - 20s - loss: 3.6816 - rmse: 3.6817 - val_loss: 4.1724 - val_rmse: 4.1708\n",
            "Epoch 72/500\n",
            "4767/4767 - 20s - loss: 3.6814 - rmse: 3.6810 - val_loss: 4.1869 - val_rmse: 4.1857\n",
            "Epoch 73/500\n",
            "4767/4767 - 21s - loss: 3.6668 - rmse: 3.6665 - val_loss: 4.1707 - val_rmse: 4.1694\n",
            "Epoch 74/500\n",
            "4767/4767 - 20s - loss: 3.6489 - rmse: 3.6492 - val_loss: 4.1712 - val_rmse: 4.1700\n",
            "Epoch 75/500\n",
            "4767/4767 - 20s - loss: 3.6517 - rmse: 3.6517 - val_loss: 4.1628 - val_rmse: 4.1614\n",
            "Epoch 76/500\n",
            "4767/4767 - 20s - loss: 3.6334 - rmse: 3.6338 - val_loss: 4.1623 - val_rmse: 4.1609\n",
            "Epoch 77/500\n",
            "4767/4767 - 20s - loss: 3.6186 - rmse: 3.6183 - val_loss: 4.1592 - val_rmse: 4.1583\n",
            "Epoch 78/500\n",
            "4767/4767 - 20s - loss: 3.6394 - rmse: 3.6396 - val_loss: 4.1323 - val_rmse: 4.1312\n",
            "Epoch 79/500\n",
            "4767/4767 - 20s - loss: 3.5909 - rmse: 3.5906 - val_loss: 4.1878 - val_rmse: 4.1867\n",
            "Epoch 80/500\n",
            "4767/4767 - 23s - loss: 3.5968 - rmse: 3.5965 - val_loss: 4.1660 - val_rmse: 4.1650\n",
            "Epoch 81/500\n",
            "4767/4767 - 20s - loss: 3.5719 - rmse: 3.5720 - val_loss: 4.1614 - val_rmse: 4.1603\n",
            "Epoch 82/500\n",
            "4767/4767 - 20s - loss: 3.6100 - rmse: 3.6099 - val_loss: 4.1715 - val_rmse: 4.1701\n",
            "Epoch 83/500\n",
            "4767/4767 - 21s - loss: 3.5755 - rmse: 3.5752 - val_loss: 4.2091 - val_rmse: 4.2081\n",
            "Epoch 84/500\n",
            "4767/4767 - 20s - loss: 3.5863 - rmse: 3.5864 - val_loss: 4.1551 - val_rmse: 4.1537\n",
            "Epoch 85/500\n",
            "4767/4767 - 20s - loss: 3.5413 - rmse: 3.5412 - val_loss: 4.1678 - val_rmse: 4.1670\n",
            "Epoch 86/500\n",
            "4767/4767 - 20s - loss: 3.5452 - rmse: 3.5450 - val_loss: 4.1616 - val_rmse: 4.1604\n",
            "Epoch 87/500\n",
            "4767/4767 - 20s - loss: 3.5480 - rmse: 3.5479 - val_loss: 4.1529 - val_rmse: 4.1518\n",
            "Epoch 88/500\n",
            "4767/4767 - 20s - loss: 3.5400 - rmse: 3.5401 - val_loss: 4.1669 - val_rmse: 4.1655\n",
            "Train Score: 3.42 RMSE\n",
            "Validation Score: 4.62 RMSE\n",
            "Test Score: 4.95 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:141: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "16       25.0\n",
            "24       34.0\n",
            "25       13.0\n",
            "40       26.0\n",
            "53       36.6\n",
            "         ... \n",
            "26430    28.0\n",
            "26439    34.0\n",
            "26457    42.0\n",
            "26469    32.0\n",
            "26475    33.0\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 20s - loss: 8.9219 - rmse: 8.9209 - val_loss: 6.7324 - val_rmse: 6.7338\n",
            "Epoch 2/500\n",
            "4767/4767 - 20s - loss: 6.9649 - rmse: 6.9652 - val_loss: 6.1704 - val_rmse: 6.1712\n",
            "Epoch 3/500\n",
            "4767/4767 - 21s - loss: 6.4358 - rmse: 6.4370 - val_loss: 5.7413 - val_rmse: 5.7414\n",
            "Epoch 4/500\n",
            "4767/4767 - 20s - loss: 6.1130 - rmse: 6.1129 - val_loss: 5.4893 - val_rmse: 5.4896\n",
            "Epoch 5/500\n",
            "4767/4767 - 20s - loss: 5.9098 - rmse: 5.9091 - val_loss: 5.4210 - val_rmse: 5.4213\n",
            "Epoch 6/500\n",
            "4767/4767 - 21s - loss: 5.7992 - rmse: 5.7989 - val_loss: 5.2735 - val_rmse: 5.2740\n",
            "Epoch 7/500\n",
            "4767/4767 - 22s - loss: 5.7269 - rmse: 5.7265 - val_loss: 5.2156 - val_rmse: 5.2161\n",
            "Epoch 8/500\n",
            "4767/4767 - 25s - loss: 5.6110 - rmse: 5.6107 - val_loss: 5.1568 - val_rmse: 5.1573\n",
            "Epoch 9/500\n",
            "4767/4767 - 24s - loss: 5.5543 - rmse: 5.5541 - val_loss: 5.1055 - val_rmse: 5.1062\n",
            "Epoch 10/500\n",
            "4767/4767 - 25s - loss: 5.4987 - rmse: 5.4982 - val_loss: 5.0846 - val_rmse: 5.0851\n",
            "Epoch 11/500\n",
            "4767/4767 - 21s - loss: 5.4152 - rmse: 5.4157 - val_loss: 5.0564 - val_rmse: 5.0569\n",
            "Epoch 12/500\n",
            "4767/4767 - 21s - loss: 5.3907 - rmse: 5.3907 - val_loss: 5.0140 - val_rmse: 5.0143\n",
            "Epoch 13/500\n",
            "4767/4767 - 21s - loss: 5.3497 - rmse: 5.3490 - val_loss: 4.9862 - val_rmse: 4.9865\n",
            "Epoch 14/500\n",
            "4767/4767 - 20s - loss: 5.2853 - rmse: 5.2852 - val_loss: 5.0383 - val_rmse: 5.0389\n",
            "Epoch 15/500\n",
            "4767/4767 - 20s - loss: 5.2596 - rmse: 5.2591 - val_loss: 4.9554 - val_rmse: 4.9559\n",
            "Epoch 16/500\n",
            "4767/4767 - 20s - loss: 5.1676 - rmse: 5.1677 - val_loss: 4.9324 - val_rmse: 4.9327\n",
            "Epoch 17/500\n",
            "4767/4767 - 21s - loss: 5.1478 - rmse: 5.1474 - val_loss: 4.9355 - val_rmse: 4.9362\n",
            "Epoch 18/500\n",
            "4767/4767 - 20s - loss: 5.0704 - rmse: 5.0700 - val_loss: 4.8676 - val_rmse: 4.8681\n",
            "Epoch 19/500\n",
            "4767/4767 - 21s - loss: 5.0812 - rmse: 5.0808 - val_loss: 4.8577 - val_rmse: 4.8583\n",
            "Epoch 20/500\n",
            "4767/4767 - 21s - loss: 5.0072 - rmse: 5.0071 - val_loss: 4.8197 - val_rmse: 4.8201\n",
            "Epoch 21/500\n",
            "4767/4767 - 20s - loss: 4.9752 - rmse: 4.9749 - val_loss: 4.8038 - val_rmse: 4.8043\n",
            "Epoch 22/500\n",
            "4767/4767 - 20s - loss: 4.9252 - rmse: 4.9259 - val_loss: 4.7897 - val_rmse: 4.7901\n",
            "Epoch 23/500\n",
            "4767/4767 - 24s - loss: 4.9164 - rmse: 4.9170 - val_loss: 4.8186 - val_rmse: 4.8190\n",
            "Epoch 24/500\n",
            "4767/4767 - 21s - loss: 4.8905 - rmse: 4.8903 - val_loss: 4.7495 - val_rmse: 4.7502\n",
            "Epoch 25/500\n",
            "4767/4767 - 20s - loss: 4.8344 - rmse: 4.8344 - val_loss: 4.7217 - val_rmse: 4.7221\n",
            "Epoch 26/500\n",
            "4767/4767 - 20s - loss: 4.7807 - rmse: 4.7815 - val_loss: 4.7044 - val_rmse: 4.7048\n",
            "Epoch 27/500\n",
            "4767/4767 - 20s - loss: 4.7478 - rmse: 4.7476 - val_loss: 4.6929 - val_rmse: 4.6929\n",
            "Epoch 28/500\n",
            "4767/4767 - 20s - loss: 4.7380 - rmse: 4.7380 - val_loss: 4.6774 - val_rmse: 4.6777\n",
            "Epoch 29/500\n",
            "4767/4767 - 20s - loss: 4.6941 - rmse: 4.6940 - val_loss: 4.6770 - val_rmse: 4.6773\n",
            "Epoch 30/500\n",
            "4767/4767 - 21s - loss: 4.6337 - rmse: 4.6339 - val_loss: 4.6754 - val_rmse: 4.6757\n",
            "Epoch 31/500\n",
            "4767/4767 - 20s - loss: 4.6039 - rmse: 4.6035 - val_loss: 4.6154 - val_rmse: 4.6161\n",
            "Epoch 32/500\n",
            "4767/4767 - 21s - loss: 4.5892 - rmse: 4.5898 - val_loss: 4.5961 - val_rmse: 4.5968\n",
            "Epoch 33/500\n",
            "4767/4767 - 20s - loss: 4.5184 - rmse: 4.5184 - val_loss: 4.5726 - val_rmse: 4.5730\n",
            "Epoch 34/500\n",
            "4767/4767 - 20s - loss: 4.5141 - rmse: 4.5146 - val_loss: 4.5762 - val_rmse: 4.5764\n",
            "Epoch 35/500\n",
            "4767/4767 - 20s - loss: 4.4669 - rmse: 4.4671 - val_loss: 4.5422 - val_rmse: 4.5429\n",
            "Epoch 36/500\n",
            "4767/4767 - 20s - loss: 4.4291 - rmse: 4.4293 - val_loss: 4.5281 - val_rmse: 4.5288\n",
            "Epoch 37/500\n",
            "4767/4767 - 20s - loss: 4.3941 - rmse: 4.3939 - val_loss: 4.5476 - val_rmse: 4.5482\n",
            "Epoch 38/500\n",
            "4767/4767 - 23s - loss: 4.3770 - rmse: 4.3767 - val_loss: 4.5110 - val_rmse: 4.5118\n",
            "Epoch 39/500\n",
            "4767/4767 - 24s - loss: 4.3145 - rmse: 4.3143 - val_loss: 4.4929 - val_rmse: 4.4933\n",
            "Epoch 40/500\n",
            "4767/4767 - 20s - loss: 4.3180 - rmse: 4.3178 - val_loss: 4.4625 - val_rmse: 4.4632\n",
            "Epoch 41/500\n",
            "4767/4767 - 20s - loss: 4.2740 - rmse: 4.2735 - val_loss: 4.4597 - val_rmse: 4.4604\n",
            "Epoch 42/500\n",
            "4767/4767 - 20s - loss: 4.2463 - rmse: 4.2460 - val_loss: 4.4683 - val_rmse: 4.4688\n",
            "Epoch 43/500\n",
            "4767/4767 - 20s - loss: 4.2196 - rmse: 4.2198 - val_loss: 4.4747 - val_rmse: 4.4750\n",
            "Epoch 44/500\n",
            "4767/4767 - 20s - loss: 4.2065 - rmse: 4.2064 - val_loss: 4.4592 - val_rmse: 4.4595\n",
            "Epoch 45/500\n",
            "4767/4767 - 20s - loss: 4.1801 - rmse: 4.1797 - val_loss: 4.4505 - val_rmse: 4.4507\n",
            "Epoch 46/500\n",
            "4767/4767 - 20s - loss: 4.1773 - rmse: 4.1768 - val_loss: 4.4341 - val_rmse: 4.4348\n",
            "Epoch 47/500\n",
            "4767/4767 - 20s - loss: 4.1246 - rmse: 4.1258 - val_loss: 4.4483 - val_rmse: 4.4487\n",
            "Epoch 48/500\n",
            "4767/4767 - 20s - loss: 4.0688 - rmse: 4.0685 - val_loss: 4.4561 - val_rmse: 4.4566\n",
            "Epoch 49/500\n",
            "4767/4767 - 20s - loss: 4.0729 - rmse: 4.0725 - val_loss: 4.4337 - val_rmse: 4.4341\n",
            "Epoch 50/500\n",
            "4767/4767 - 20s - loss: 4.0421 - rmse: 4.0418 - val_loss: 4.4186 - val_rmse: 4.4191\n",
            "Epoch 51/500\n",
            "4767/4767 - 20s - loss: 4.0348 - rmse: 4.0344 - val_loss: 4.3944 - val_rmse: 4.3947\n",
            "Epoch 52/500\n",
            "4767/4767 - 20s - loss: 4.0231 - rmse: 4.0231 - val_loss: 4.3924 - val_rmse: 4.3926\n",
            "Epoch 53/500\n",
            "4767/4767 - 20s - loss: 4.0146 - rmse: 4.0142 - val_loss: 4.3640 - val_rmse: 4.3643\n",
            "Epoch 54/500\n",
            "4767/4767 - 21s - loss: 3.9531 - rmse: 3.9534 - val_loss: 4.3707 - val_rmse: 4.3708\n",
            "Epoch 55/500\n",
            "4767/4767 - 25s - loss: 3.9485 - rmse: 3.9487 - val_loss: 4.3591 - val_rmse: 4.3596\n",
            "Epoch 56/500\n",
            "4767/4767 - 20s - loss: 3.9019 - rmse: 3.9020 - val_loss: 4.3664 - val_rmse: 4.3663\n",
            "Epoch 57/500\n",
            "4767/4767 - 20s - loss: 3.9404 - rmse: 3.9411 - val_loss: 4.3601 - val_rmse: 4.3598\n",
            "Epoch 58/500\n",
            "4767/4767 - 20s - loss: 3.9051 - rmse: 3.9048 - val_loss: 4.3555 - val_rmse: 4.3553\n",
            "Epoch 59/500\n",
            "4767/4767 - 21s - loss: 3.8864 - rmse: 3.8862 - val_loss: 4.3597 - val_rmse: 4.3596\n",
            "Epoch 60/500\n",
            "4767/4767 - 21s - loss: 3.8515 - rmse: 3.8511 - val_loss: 4.3689 - val_rmse: 4.3691\n",
            "Epoch 61/500\n",
            "4767/4767 - 21s - loss: 3.8384 - rmse: 3.8380 - val_loss: 4.3854 - val_rmse: 4.3858\n",
            "Epoch 62/500\n",
            "4767/4767 - 22s - loss: 3.8490 - rmse: 3.8486 - val_loss: 4.3455 - val_rmse: 4.3453\n",
            "Epoch 63/500\n",
            "4767/4767 - 21s - loss: 3.8386 - rmse: 3.8386 - val_loss: 4.3236 - val_rmse: 4.3235\n",
            "Epoch 64/500\n",
            "4767/4767 - 20s - loss: 3.7991 - rmse: 3.7993 - val_loss: 4.3615 - val_rmse: 4.3612\n",
            "Epoch 65/500\n",
            "4767/4767 - 20s - loss: 3.7979 - rmse: 3.7975 - val_loss: 4.3455 - val_rmse: 4.3451\n",
            "Epoch 66/500\n",
            "4767/4767 - 20s - loss: 3.7868 - rmse: 3.7867 - val_loss: 4.3276 - val_rmse: 4.3276\n",
            "Epoch 67/500\n",
            "4767/4767 - 20s - loss: 3.7680 - rmse: 3.7678 - val_loss: 4.3296 - val_rmse: 4.3298\n",
            "Epoch 68/500\n",
            "4767/4767 - 23s - loss: 3.7723 - rmse: 3.7722 - val_loss: 4.3306 - val_rmse: 4.3303\n",
            "Epoch 69/500\n",
            "4767/4767 - 21s - loss: 3.7340 - rmse: 3.7337 - val_loss: 4.3598 - val_rmse: 4.3599\n",
            "Epoch 70/500\n",
            "4767/4767 - 26s - loss: 3.7221 - rmse: 3.7218 - val_loss: 4.3182 - val_rmse: 4.3181\n",
            "Epoch 71/500\n",
            "4767/4767 - 20s - loss: 3.7088 - rmse: 3.7085 - val_loss: 4.3159 - val_rmse: 4.3158\n",
            "Epoch 72/500\n",
            "4767/4767 - 21s - loss: 3.7066 - rmse: 3.7065 - val_loss: 4.2957 - val_rmse: 4.2955\n",
            "Epoch 73/500\n",
            "4767/4767 - 20s - loss: 3.6818 - rmse: 3.6815 - val_loss: 4.3050 - val_rmse: 4.3047\n",
            "Epoch 74/500\n",
            "4767/4767 - 20s - loss: 3.6791 - rmse: 3.6790 - val_loss: 4.3087 - val_rmse: 4.3084\n",
            "Epoch 75/500\n",
            "4767/4767 - 20s - loss: 3.6742 - rmse: 3.6739 - val_loss: 4.3155 - val_rmse: 4.3148\n",
            "Epoch 76/500\n",
            "4767/4767 - 21s - loss: 3.6737 - rmse: 3.6737 - val_loss: 4.3109 - val_rmse: 4.3105\n",
            "Epoch 77/500\n",
            "4767/4767 - 20s - loss: 3.6666 - rmse: 3.6671 - val_loss: 4.3164 - val_rmse: 4.3161\n",
            "Epoch 78/500\n",
            "4767/4767 - 20s - loss: 3.6211 - rmse: 3.6209 - val_loss: 4.2983 - val_rmse: 4.2977\n",
            "Epoch 79/500\n",
            "4767/4767 - 20s - loss: 3.6260 - rmse: 3.6263 - val_loss: 4.3096 - val_rmse: 4.3090\n",
            "Epoch 80/500\n",
            "4767/4767 - 21s - loss: 3.6225 - rmse: 3.6222 - val_loss: 4.3022 - val_rmse: 4.3016\n",
            "Epoch 81/500\n",
            "4767/4767 - 21s - loss: 3.6168 - rmse: 3.6164 - val_loss: 4.3082 - val_rmse: 4.3078\n",
            "Epoch 82/500\n",
            "4767/4767 - 20s - loss: 3.6040 - rmse: 3.6039 - val_loss: 4.2948 - val_rmse: 4.2940\n",
            "Epoch 83/500\n",
            "4767/4767 - 20s - loss: 3.5768 - rmse: 3.5769 - val_loss: 4.3074 - val_rmse: 4.3072\n",
            "Epoch 84/500\n",
            "4767/4767 - 22s - loss: 3.5757 - rmse: 3.5756 - val_loss: 4.2878 - val_rmse: 4.2872\n",
            "Epoch 85/500\n",
            "4767/4767 - 22s - loss: 3.5747 - rmse: 3.5748 - val_loss: 4.2620 - val_rmse: 4.2615\n",
            "Epoch 86/500\n",
            "4767/4767 - 23s - loss: 3.5541 - rmse: 3.5537 - val_loss: 4.2916 - val_rmse: 4.2910\n",
            "Epoch 87/500\n",
            "4767/4767 - 21s - loss: 3.5354 - rmse: 3.5356 - val_loss: 4.2795 - val_rmse: 4.2789\n",
            "Epoch 88/500\n",
            "4767/4767 - 20s - loss: 3.5473 - rmse: 3.5472 - val_loss: 4.2921 - val_rmse: 4.2914\n",
            "Epoch 89/500\n",
            "4767/4767 - 20s - loss: 3.5571 - rmse: 3.5573 - val_loss: 4.2881 - val_rmse: 4.2880\n",
            "Epoch 90/500\n",
            "4767/4767 - 20s - loss: 3.5091 - rmse: 3.5102 - val_loss: 4.2578 - val_rmse: 4.2574\n",
            "Epoch 91/500\n",
            "4767/4767 - 20s - loss: 3.5149 - rmse: 3.5146 - val_loss: 4.3010 - val_rmse: 4.3009\n",
            "Epoch 92/500\n",
            "4767/4767 - 20s - loss: 3.5015 - rmse: 3.5012 - val_loss: 4.2879 - val_rmse: 4.2875\n",
            "Epoch 93/500\n",
            "4767/4767 - 20s - loss: 3.4985 - rmse: 3.4985 - val_loss: 4.2845 - val_rmse: 4.2838\n",
            "Epoch 94/500\n",
            "4767/4767 - 20s - loss: 3.4997 - rmse: 3.5001 - val_loss: 4.2731 - val_rmse: 4.2726\n",
            "Epoch 95/500\n",
            "4767/4767 - 21s - loss: 3.4935 - rmse: 3.4934 - val_loss: 4.2755 - val_rmse: 4.2751\n",
            "Epoch 96/500\n",
            "4767/4767 - 21s - loss: 3.4794 - rmse: 3.4790 - val_loss: 4.2560 - val_rmse: 4.2554\n",
            "Epoch 97/500\n",
            "4767/4767 - 23s - loss: 3.4822 - rmse: 3.4819 - val_loss: 4.2610 - val_rmse: 4.2605\n",
            "Epoch 98/500\n",
            "4767/4767 - 21s - loss: 3.4698 - rmse: 3.4697 - val_loss: 4.2493 - val_rmse: 4.2484\n",
            "Epoch 99/500\n",
            "4767/4767 - 22s - loss: 3.4687 - rmse: 3.4686 - val_loss: 4.2597 - val_rmse: 4.2589\n",
            "Epoch 100/500\n",
            "4767/4767 - 21s - loss: 3.4447 - rmse: 3.4444 - val_loss: 4.2463 - val_rmse: 4.2450\n",
            "Epoch 101/500\n",
            "4767/4767 - 25s - loss: 3.4284 - rmse: 3.4283 - val_loss: 4.2786 - val_rmse: 4.2775\n",
            "Epoch 102/500\n",
            "4767/4767 - 21s - loss: 3.4207 - rmse: 3.4205 - val_loss: 4.2658 - val_rmse: 4.2649\n",
            "Epoch 103/500\n",
            "4767/4767 - 21s - loss: 3.4362 - rmse: 3.4361 - val_loss: 4.2555 - val_rmse: 4.2546\n",
            "Epoch 104/500\n",
            "4767/4767 - 21s - loss: 3.4094 - rmse: 3.4091 - val_loss: 4.2439 - val_rmse: 4.2430\n",
            "Epoch 105/500\n",
            "4767/4767 - 20s - loss: 3.4120 - rmse: 3.4119 - val_loss: 4.2635 - val_rmse: 4.2620\n",
            "Epoch 106/500\n",
            "4767/4767 - 21s - loss: 3.4089 - rmse: 3.4092 - val_loss: 4.2513 - val_rmse: 4.2508\n",
            "Epoch 107/500\n",
            "4767/4767 - 20s - loss: 3.4111 - rmse: 3.4116 - val_loss: 4.2332 - val_rmse: 4.2326\n",
            "Epoch 108/500\n",
            "4767/4767 - 20s - loss: 3.4020 - rmse: 3.4019 - val_loss: 4.2432 - val_rmse: 4.2427\n",
            "Epoch 109/500\n",
            "4767/4767 - 20s - loss: 3.3971 - rmse: 3.3977 - val_loss: 4.2568 - val_rmse: 4.2561\n",
            "Epoch 110/500\n",
            "4767/4767 - 20s - loss: 3.3706 - rmse: 3.3713 - val_loss: 4.2360 - val_rmse: 4.2359\n",
            "Epoch 111/500\n",
            "4767/4767 - 20s - loss: 3.3737 - rmse: 3.3738 - val_loss: 4.2550 - val_rmse: 4.2545\n",
            "Epoch 112/500\n",
            "4767/4767 - 20s - loss: 3.3635 - rmse: 3.3633 - val_loss: 4.2578 - val_rmse: 4.2570\n",
            "Epoch 113/500\n",
            "4767/4767 - 21s - loss: 3.3594 - rmse: 3.3593 - val_loss: 4.2499 - val_rmse: 4.2490\n",
            "Epoch 114/500\n",
            "4767/4767 - 22s - loss: 3.3591 - rmse: 3.3588 - val_loss: 4.2784 - val_rmse: 4.2773\n",
            "Epoch 115/500\n",
            "4767/4767 - 21s - loss: 3.3527 - rmse: 3.3532 - val_loss: 4.2789 - val_rmse: 4.2779\n",
            "Epoch 116/500\n",
            "4767/4767 - 22s - loss: 3.3672 - rmse: 3.3672 - val_loss: 4.2400 - val_rmse: 4.2394\n",
            "Epoch 117/500\n",
            "4767/4767 - 22s - loss: 3.3406 - rmse: 3.3408 - val_loss: 4.2622 - val_rmse: 4.2617\n",
            "Train Score: 3.19 RMSE\n",
            "Validation Score: 4.70 RMSE\n",
            "Test Score: 4.88 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:145: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:148: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:151: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please show me the shape of x_train: (23832, 1858)\n",
            "Please show me the shape of x_test: (2648, 1858)\n",
            "Please show me the shape of y_train: (23832,)\n",
            "Please show me the shape of y_test: (2648,)\n",
            "y_test:\n",
            "9        28.0\n",
            "11       21.0\n",
            "13       30.0\n",
            "55        6.0\n",
            "60       37.0\n",
            "         ... \n",
            "26460    27.6\n",
            "26461    36.0\n",
            "26462    14.0\n",
            "26476    24.0\n",
            "26478    19.0\n",
            "Name: Milk, Length: 2648, dtype: float64\n",
            "Epoch 1/500\n",
            "4767/4767 - 20s - loss: 8.9178 - rmse: 8.9178 - val_loss: 6.8404 - val_rmse: 6.8390\n",
            "Epoch 2/500\n",
            "4767/4767 - 20s - loss: 6.9712 - rmse: 6.9709 - val_loss: 6.3569 - val_rmse: 6.3563\n",
            "Epoch 3/500\n",
            "4767/4767 - 19s - loss: 6.4397 - rmse: 6.4396 - val_loss: 6.0245 - val_rmse: 6.0234\n",
            "Epoch 4/500\n",
            "4767/4767 - 19s - loss: 6.0667 - rmse: 6.0675 - val_loss: 5.7727 - val_rmse: 5.7719\n",
            "Epoch 5/500\n",
            "4767/4767 - 20s - loss: 5.9263 - rmse: 5.9261 - val_loss: 5.5865 - val_rmse: 5.5860\n",
            "Epoch 6/500\n",
            "4767/4767 - 19s - loss: 5.8199 - rmse: 5.8197 - val_loss: 5.5552 - val_rmse: 5.5539\n",
            "Epoch 7/500\n",
            "4767/4767 - 19s - loss: 5.6604 - rmse: 5.6606 - val_loss: 5.3986 - val_rmse: 5.3974\n",
            "Epoch 8/500\n",
            "4767/4767 - 19s - loss: 5.6018 - rmse: 5.6025 - val_loss: 5.3515 - val_rmse: 5.3505\n",
            "Epoch 9/500\n",
            "4767/4767 - 20s - loss: 5.5311 - rmse: 5.5309 - val_loss: 5.3246 - val_rmse: 5.3231\n",
            "Epoch 10/500\n",
            "4767/4767 - 20s - loss: 5.4995 - rmse: 5.4999 - val_loss: 5.2780 - val_rmse: 5.2766\n",
            "Epoch 11/500\n",
            "4767/4767 - 19s - loss: 5.4439 - rmse: 5.4441 - val_loss: 5.2327 - val_rmse: 5.2316\n",
            "Epoch 12/500\n",
            "4767/4767 - 20s - loss: 5.4070 - rmse: 5.4068 - val_loss: 5.2051 - val_rmse: 5.2037\n",
            "Epoch 13/500\n",
            "4767/4767 - 19s - loss: 5.3701 - rmse: 5.3701 - val_loss: 5.1636 - val_rmse: 5.1625\n",
            "Epoch 14/500\n",
            "4767/4767 - 19s - loss: 5.2655 - rmse: 5.2658 - val_loss: 5.1562 - val_rmse: 5.1552\n",
            "Epoch 15/500\n",
            "4767/4767 - 20s - loss: 5.2314 - rmse: 5.2312 - val_loss: 5.1593 - val_rmse: 5.1580\n",
            "Epoch 16/500\n",
            "4767/4767 - 21s - loss: 5.2031 - rmse: 5.2029 - val_loss: 5.1005 - val_rmse: 5.0992\n",
            "Epoch 17/500\n",
            "4767/4767 - 19s - loss: 5.1311 - rmse: 5.1312 - val_loss: 5.0832 - val_rmse: 5.0819\n",
            "Epoch 18/500\n",
            "4767/4767 - 19s - loss: 5.0831 - rmse: 5.0826 - val_loss: 5.0488 - val_rmse: 5.0478\n",
            "Epoch 19/500\n",
            "4767/4767 - 19s - loss: 5.0692 - rmse: 5.0697 - val_loss: 5.0461 - val_rmse: 5.0452\n",
            "Epoch 20/500\n",
            "4767/4767 - 19s - loss: 5.0332 - rmse: 5.0333 - val_loss: 5.0152 - val_rmse: 5.0141\n",
            "Epoch 21/500\n",
            "4767/4767 - 19s - loss: 4.9458 - rmse: 4.9454 - val_loss: 4.9845 - val_rmse: 4.9832\n",
            "Epoch 22/500\n",
            "4767/4767 - 19s - loss: 4.9135 - rmse: 4.9136 - val_loss: 4.9616 - val_rmse: 4.9605\n",
            "Epoch 23/500\n",
            "4767/4767 - 19s - loss: 4.9103 - rmse: 4.9100 - val_loss: 4.9433 - val_rmse: 4.9423\n",
            "Epoch 24/500\n",
            "4767/4767 - 19s - loss: 4.8565 - rmse: 4.8565 - val_loss: 4.9394 - val_rmse: 4.9383\n",
            "Epoch 25/500\n",
            "4767/4767 - 19s - loss: 4.8135 - rmse: 4.8137 - val_loss: 4.9188 - val_rmse: 4.9178\n",
            "Epoch 26/500\n",
            "4767/4767 - 19s - loss: 4.7422 - rmse: 4.7417 - val_loss: 4.8987 - val_rmse: 4.8977\n",
            "Epoch 27/500\n",
            "4767/4767 - 19s - loss: 4.6982 - rmse: 4.6982 - val_loss: 4.9041 - val_rmse: 4.9031\n",
            "Epoch 28/500\n",
            "4767/4767 - 21s - loss: 4.6991 - rmse: 4.6996 - val_loss: 4.8594 - val_rmse: 4.8584\n",
            "Epoch 29/500\n",
            "4767/4767 - 19s - loss: 4.6549 - rmse: 4.6546 - val_loss: 4.8668 - val_rmse: 4.8658\n",
            "Epoch 30/500\n",
            "4767/4767 - 19s - loss: 4.6028 - rmse: 4.6025 - val_loss: 4.8385 - val_rmse: 4.8375\n",
            "Epoch 31/500\n",
            "4767/4767 - 19s - loss: 4.5797 - rmse: 4.5795 - val_loss: 4.8109 - val_rmse: 4.8100\n",
            "Epoch 32/500\n",
            "4767/4767 - 20s - loss: 4.5228 - rmse: 4.5225 - val_loss: 4.7974 - val_rmse: 4.7965\n",
            "Epoch 33/500\n",
            "4767/4767 - 21s - loss: 4.5007 - rmse: 4.5006 - val_loss: 4.7902 - val_rmse: 4.7891\n",
            "Epoch 34/500\n",
            "4767/4767 - 19s - loss: 4.4465 - rmse: 4.4461 - val_loss: 4.7823 - val_rmse: 4.7814\n",
            "Epoch 35/500\n",
            "4767/4767 - 19s - loss: 4.4381 - rmse: 4.4383 - val_loss: 4.7937 - val_rmse: 4.7924\n",
            "Epoch 36/500\n",
            "4767/4767 - 19s - loss: 4.3684 - rmse: 4.3681 - val_loss: 4.8018 - val_rmse: 4.8005\n",
            "Epoch 37/500\n",
            "4767/4767 - 19s - loss: 4.3813 - rmse: 4.3810 - val_loss: 4.7717 - val_rmse: 4.7706\n",
            "Epoch 38/500\n",
            "4767/4767 - 19s - loss: 4.3278 - rmse: 4.3276 - val_loss: 4.7395 - val_rmse: 4.7384\n",
            "Epoch 39/500\n",
            "4767/4767 - 19s - loss: 4.3082 - rmse: 4.3083 - val_loss: 4.7139 - val_rmse: 4.7128\n",
            "Epoch 40/500\n",
            "4767/4767 - 19s - loss: 4.2795 - rmse: 4.2811 - val_loss: 4.6996 - val_rmse: 4.6983\n",
            "Epoch 41/500\n",
            "4767/4767 - 22s - loss: 4.2220 - rmse: 4.2219 - val_loss: 4.6945 - val_rmse: 4.6932\n",
            "Epoch 42/500\n",
            "4767/4767 - 19s - loss: 4.1858 - rmse: 4.1855 - val_loss: 4.6910 - val_rmse: 4.6898\n",
            "Epoch 43/500\n",
            "4767/4767 - 19s - loss: 4.1734 - rmse: 4.1736 - val_loss: 4.6713 - val_rmse: 4.6699\n",
            "Epoch 44/500\n",
            "4767/4767 - 20s - loss: 4.1537 - rmse: 4.1541 - val_loss: 4.6596 - val_rmse: 4.6581\n",
            "Epoch 45/500\n",
            "4767/4767 - 19s - loss: 4.1286 - rmse: 4.1296 - val_loss: 4.6704 - val_rmse: 4.6690\n",
            "Epoch 46/500\n",
            "4767/4767 - 19s - loss: 4.1003 - rmse: 4.0998 - val_loss: 4.6530 - val_rmse: 4.6516\n",
            "Epoch 47/500\n",
            "4767/4767 - 19s - loss: 4.0867 - rmse: 4.0864 - val_loss: 4.6552 - val_rmse: 4.6536\n",
            "Epoch 48/500\n",
            "4767/4767 - 19s - loss: 4.0753 - rmse: 4.0752 - val_loss: 4.6376 - val_rmse: 4.6361\n",
            "Epoch 49/500\n",
            "4767/4767 - 22s - loss: 4.0459 - rmse: 4.0460 - val_loss: 4.6245 - val_rmse: 4.6229\n",
            "Epoch 50/500\n",
            "4767/4767 - 19s - loss: 4.0424 - rmse: 4.0423 - val_loss: 4.6284 - val_rmse: 4.6270\n",
            "Epoch 51/500\n",
            "4767/4767 - 19s - loss: 4.0115 - rmse: 4.0113 - val_loss: 4.6244 - val_rmse: 4.6230\n",
            "Epoch 52/500\n",
            "4767/4767 - 19s - loss: 3.9877 - rmse: 3.9875 - val_loss: 4.6229 - val_rmse: 4.6211\n",
            "Epoch 53/500\n",
            "4767/4767 - 19s - loss: 3.9613 - rmse: 3.9613 - val_loss: 4.5979 - val_rmse: 4.5965\n",
            "Epoch 54/500\n",
            "4767/4767 - 19s - loss: 3.9476 - rmse: 3.9477 - val_loss: 4.6349 - val_rmse: 4.6337\n",
            "Epoch 55/500\n",
            "4767/4767 - 19s - loss: 3.9092 - rmse: 3.9089 - val_loss: 4.5927 - val_rmse: 4.5913\n",
            "Epoch 56/500\n",
            "4767/4767 - 19s - loss: 3.9083 - rmse: 3.9081 - val_loss: 4.5792 - val_rmse: 4.5777\n",
            "Epoch 57/500\n",
            "4767/4767 - 19s - loss: 3.8828 - rmse: 3.8827 - val_loss: 4.5990 - val_rmse: 4.5975\n",
            "Epoch 58/500\n",
            "4767/4767 - 19s - loss: 3.8639 - rmse: 3.8639 - val_loss: 4.5586 - val_rmse: 4.5573\n",
            "Epoch 59/500\n",
            "4767/4767 - 19s - loss: 3.8614 - rmse: 3.8611 - val_loss: 4.5727 - val_rmse: 4.5711\n",
            "Epoch 60/500\n",
            "4767/4767 - 20s - loss: 3.8552 - rmse: 3.8551 - val_loss: 4.5757 - val_rmse: 4.5743\n",
            "Epoch 61/500\n",
            "4767/4767 - 19s - loss: 3.8055 - rmse: 3.8051 - val_loss: 4.5711 - val_rmse: 4.5698\n",
            "Epoch 62/500\n",
            "4767/4767 - 19s - loss: 3.8059 - rmse: 3.8055 - val_loss: 4.5672 - val_rmse: 4.5658\n",
            "Epoch 63/500\n",
            "4767/4767 - 19s - loss: 3.7891 - rmse: 3.7889 - val_loss: 4.5691 - val_rmse: 4.5676\n",
            "Epoch 64/500\n",
            "4767/4767 - 19s - loss: 3.7648 - rmse: 3.7647 - val_loss: 4.5646 - val_rmse: 4.5630\n",
            "Epoch 65/500\n",
            "4767/4767 - 19s - loss: 3.7697 - rmse: 3.7699 - val_loss: 4.5578 - val_rmse: 4.5561\n",
            "Epoch 66/500\n",
            "4767/4767 - 21s - loss: 3.7554 - rmse: 3.7553 - val_loss: 4.5510 - val_rmse: 4.5493\n",
            "Epoch 67/500\n",
            "4767/4767 - 19s - loss: 3.7253 - rmse: 3.7252 - val_loss: 4.5757 - val_rmse: 4.5740\n",
            "Epoch 68/500\n",
            "4767/4767 - 19s - loss: 3.7064 - rmse: 3.7061 - val_loss: 4.5467 - val_rmse: 4.5450\n",
            "Epoch 69/500\n",
            "4767/4767 - 19s - loss: 3.7292 - rmse: 3.7290 - val_loss: 4.5507 - val_rmse: 4.5488\n",
            "Epoch 70/500\n",
            "4767/4767 - 19s - loss: 3.7015 - rmse: 3.7012 - val_loss: 4.5573 - val_rmse: 4.5557\n",
            "Epoch 71/500\n",
            "4767/4767 - 19s - loss: 3.6559 - rmse: 3.6556 - val_loss: 4.5450 - val_rmse: 4.5433\n",
            "Epoch 72/500\n",
            "4767/4767 - 20s - loss: 3.6950 - rmse: 3.6951 - val_loss: 4.5666 - val_rmse: 4.5649\n",
            "Epoch 73/500\n",
            "4767/4767 - 20s - loss: 3.6479 - rmse: 3.6477 - val_loss: 4.5358 - val_rmse: 4.5339\n",
            "Epoch 74/500\n",
            "4767/4767 - 19s - loss: 3.6384 - rmse: 3.6381 - val_loss: 4.5374 - val_rmse: 4.5358\n",
            "Epoch 75/500\n",
            "4767/4767 - 20s - loss: 3.6141 - rmse: 3.6138 - val_loss: 4.5308 - val_rmse: 4.5290\n",
            "Epoch 76/500\n",
            "4767/4767 - 20s - loss: 3.6031 - rmse: 3.6028 - val_loss: 4.5398 - val_rmse: 4.5381\n",
            "Epoch 77/500\n",
            "4767/4767 - 19s - loss: 3.5971 - rmse: 3.5970 - val_loss: 4.5390 - val_rmse: 4.5373\n",
            "Epoch 78/500\n",
            "4767/4767 - 19s - loss: 3.6151 - rmse: 3.6149 - val_loss: 4.5524 - val_rmse: 4.5507\n",
            "Epoch 79/500\n",
            "4767/4767 - 19s - loss: 3.5897 - rmse: 3.5894 - val_loss: 4.5457 - val_rmse: 4.5439\n",
            "Epoch 80/500\n",
            "4767/4767 - 19s - loss: 3.5910 - rmse: 3.5912 - val_loss: 4.5316 - val_rmse: 4.5298\n",
            "Epoch 81/500\n",
            "4767/4767 - 19s - loss: 3.5549 - rmse: 3.5547 - val_loss: 4.5308 - val_rmse: 4.5289\n",
            "Epoch 82/500\n",
            "4767/4767 - 22s - loss: 3.5709 - rmse: 3.5708 - val_loss: 4.5310 - val_rmse: 4.5289\n",
            "Epoch 83/500\n",
            "4767/4767 - 22s - loss: 3.5621 - rmse: 3.5619 - val_loss: 4.5431 - val_rmse: 4.5413\n",
            "Epoch 84/500\n",
            "4767/4767 - 20s - loss: 3.5604 - rmse: 3.5603 - val_loss: 4.5214 - val_rmse: 4.5197\n",
            "Epoch 85/500\n",
            "4767/4767 - 20s - loss: 3.5253 - rmse: 3.5255 - val_loss: 4.5280 - val_rmse: 4.5262\n",
            "Epoch 86/500\n",
            "4767/4767 - 20s - loss: 3.5259 - rmse: 3.5259 - val_loss: 4.5351 - val_rmse: 4.5332\n",
            "Epoch 87/500\n",
            "4767/4767 - 20s - loss: 3.5044 - rmse: 3.5041 - val_loss: 4.5347 - val_rmse: 4.5328\n",
            "Epoch 88/500\n",
            "4767/4767 - 19s - loss: 3.5141 - rmse: 3.5139 - val_loss: 4.5327 - val_rmse: 4.5310\n",
            "Epoch 89/500\n",
            "4767/4767 - 19s - loss: 3.5055 - rmse: 3.5056 - val_loss: 4.5222 - val_rmse: 4.5202\n",
            "Epoch 90/500\n",
            "4767/4767 - 19s - loss: 3.5190 - rmse: 3.5186 - val_loss: 4.5227 - val_rmse: 4.5209\n",
            "Epoch 91/500\n",
            "4767/4767 - 20s - loss: 3.4767 - rmse: 3.4770 - val_loss: 4.5256 - val_rmse: 4.5238\n",
            "Epoch 92/500\n",
            "4767/4767 - 19s - loss: 3.4983 - rmse: 3.4982 - val_loss: 4.5398 - val_rmse: 4.5379\n",
            "Epoch 93/500\n",
            "4767/4767 - 20s - loss: 3.4791 - rmse: 3.4799 - val_loss: 4.5205 - val_rmse: 4.5189\n",
            "Epoch 94/500\n",
            "4767/4767 - 20s - loss: 3.4893 - rmse: 3.4900 - val_loss: 4.5293 - val_rmse: 4.5274\n",
            "Epoch 95/500\n",
            "4767/4767 - 20s - loss: 3.4522 - rmse: 3.4520 - val_loss: 4.5397 - val_rmse: 4.5379\n",
            "Epoch 96/500\n",
            "4767/4767 - 20s - loss: 3.4505 - rmse: 3.4504 - val_loss: 4.5367 - val_rmse: 4.5349\n",
            "Epoch 97/500\n",
            "4767/4767 - 20s - loss: 3.4491 - rmse: 3.4490 - val_loss: 4.5276 - val_rmse: 4.5259\n",
            "Epoch 98/500\n",
            "4767/4767 - 22s - loss: 3.4485 - rmse: 3.4482 - val_loss: 4.5246 - val_rmse: 4.5229\n",
            "Epoch 99/500\n",
            "4767/4767 - 23s - loss: 3.4160 - rmse: 3.4159 - val_loss: 4.5273 - val_rmse: 4.5257\n",
            "Epoch 100/500\n",
            "4767/4767 - 20s - loss: 3.4396 - rmse: 3.4395 - val_loss: 4.5125 - val_rmse: 4.5109\n",
            "Epoch 101/500\n",
            "4767/4767 - 19s - loss: 3.4194 - rmse: 3.4196 - val_loss: 4.5259 - val_rmse: 4.5242\n",
            "Epoch 102/500\n",
            "4767/4767 - 19s - loss: 3.3964 - rmse: 3.3963 - val_loss: 4.5279 - val_rmse: 4.5262\n",
            "Epoch 103/500\n",
            "4767/4767 - 22s - loss: 3.4043 - rmse: 3.4039 - val_loss: 4.5209 - val_rmse: 4.5192\n",
            "Epoch 104/500\n",
            "4767/4767 - 20s - loss: 3.3950 - rmse: 3.3951 - val_loss: 4.5201 - val_rmse: 4.5185\n",
            "Epoch 105/500\n",
            "4767/4767 - 20s - loss: 3.3976 - rmse: 3.3977 - val_loss: 4.5241 - val_rmse: 4.5225\n",
            "Epoch 106/500\n",
            "4767/4767 - 21s - loss: 3.3999 - rmse: 3.3998 - val_loss: 4.5180 - val_rmse: 4.5163\n",
            "Epoch 107/500\n",
            "4767/4767 - 20s - loss: 3.3855 - rmse: 3.3858 - val_loss: 4.5171 - val_rmse: 4.5155\n",
            "Epoch 108/500\n",
            "4767/4767 - 19s - loss: 3.3835 - rmse: 3.3833 - val_loss: 4.5280 - val_rmse: 4.5265\n",
            "Epoch 109/500\n",
            "4767/4767 - 19s - loss: 3.3730 - rmse: 3.3733 - val_loss: 4.5129 - val_rmse: 4.5111\n",
            "Epoch 110/500\n",
            "4767/4767 - 19s - loss: 3.3442 - rmse: 3.3442 - val_loss: 4.5114 - val_rmse: 4.5095\n",
            "Epoch 111/500\n",
            "4767/4767 - 19s - loss: 3.3523 - rmse: 3.3522 - val_loss: 4.5228 - val_rmse: 4.5210\n",
            "Epoch 112/500\n",
            "4767/4767 - 20s - loss: 3.3543 - rmse: 3.3556 - val_loss: 4.5224 - val_rmse: 4.5204\n",
            "Epoch 113/500\n",
            "4767/4767 - 19s - loss: 3.3242 - rmse: 3.3241 - val_loss: 4.5271 - val_rmse: 4.5256\n",
            "Epoch 114/500\n",
            "4767/4767 - 22s - loss: 3.3399 - rmse: 3.3407 - val_loss: 4.5161 - val_rmse: 4.5147\n",
            "Epoch 115/500\n",
            "4767/4767 - 22s - loss: 3.3216 - rmse: 3.3215 - val_loss: 4.5168 - val_rmse: 4.5150\n",
            "Epoch 116/500\n",
            "4767/4767 - 21s - loss: 3.3101 - rmse: 3.3101 - val_loss: 4.5346 - val_rmse: 4.5330\n",
            "Epoch 117/500\n",
            "4767/4767 - 21s - loss: 3.2952 - rmse: 3.2950 - val_loss: 4.5045 - val_rmse: 4.5028\n",
            "Epoch 118/500\n",
            "4767/4767 - 20s - loss: 3.3193 - rmse: 3.3192 - val_loss: 4.5180 - val_rmse: 4.5165\n",
            "Epoch 119/500\n",
            "4767/4767 - 20s - loss: 3.3206 - rmse: 3.3203 - val_loss: 4.5300 - val_rmse: 4.5286\n",
            "Epoch 120/500\n",
            "4767/4767 - 21s - loss: 3.3030 - rmse: 3.3028 - val_loss: 4.5288 - val_rmse: 4.5272\n",
            "Epoch 121/500\n",
            "4767/4767 - 22s - loss: 3.2835 - rmse: 3.2835 - val_loss: 4.5164 - val_rmse: 4.5145\n",
            "Epoch 122/500\n",
            "4767/4767 - 20s - loss: 3.2924 - rmse: 3.2921 - val_loss: 4.5288 - val_rmse: 4.5273\n",
            "Epoch 123/500\n",
            "4767/4767 - 20s - loss: 3.2872 - rmse: 3.2870 - val_loss: 4.5343 - val_rmse: 4.5330\n",
            "Epoch 124/500\n",
            "4767/4767 - 20s - loss: 3.2740 - rmse: 3.2742 - val_loss: 4.5137 - val_rmse: 4.5121\n",
            "Epoch 125/500\n",
            "4767/4767 - 20s - loss: 3.2795 - rmse: 3.2794 - val_loss: 4.5212 - val_rmse: 4.5198\n",
            "Epoch 126/500\n",
            "4767/4767 - 20s - loss: 3.2638 - rmse: 3.2637 - val_loss: 4.5204 - val_rmse: 4.5189\n",
            "Epoch 127/500\n",
            "4767/4767 - 20s - loss: 3.2522 - rmse: 3.2521 - val_loss: 4.5124 - val_rmse: 4.5107\n",
            "Train Score: 3.10 RMSE\n",
            "Validation Score: 5.01 RMSE\n",
            "Test Score: 4.90 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m--ho-RNs-Lf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "447ccad5-6f33-46b0-ad25-6c1420a363c8"
      },
      "source": [
        "savefornew_train01"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>firm</th>\n",
              "      <th>CowID</th>\n",
              "      <th>MomID</th>\n",
              "      <th>BabyNum</th>\n",
              "      <th>FeedDay</th>\n",
              "      <th>Milk</th>\n",
              "      <th>preMilk</th>\n",
              "      <th>Sampling date</th>\n",
              "      <th>Age</th>\n",
              "      <th>BreedNum</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>T Max</th>\n",
              "      <th>RH</th>\n",
              "      <th>RHMin</th>\n",
              "      <th>Precp</th>\n",
              "      <th>THI</th>\n",
              "      <th>cycle</th>\n",
              "      <th>tcalving number</th>\n",
              "      <th>disease</th>\n",
              "      <th>Sampling D Year</th>\n",
              "      <th>Sampling D Month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10806</td>\n",
              "      <td>2</td>\n",
              "      <td>3126105</td>\n",
              "      <td>116686.0</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.802689</td>\n",
              "      <td>2016/7/26</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>23.967792</td>\n",
              "      <td>27.826169</td>\n",
              "      <td>78.502478</td>\n",
              "      <td>59.891615</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.850519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Summer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10950</td>\n",
              "      <td>2</td>\n",
              "      <td>3126118</td>\n",
              "      <td>116438.0</td>\n",
              "      <td>2</td>\n",
              "      <td>62</td>\n",
              "      <td>43.0</td>\n",
              "      <td>40.369633</td>\n",
              "      <td>2017/4/17</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>34.900000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.093337</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>Spring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30007</td>\n",
              "      <td>2</td>\n",
              "      <td>3126179</td>\n",
              "      <td>99116633.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>24.0</td>\n",
              "      <td>27.622871</td>\n",
              "      <td>2016/11/23</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>23.800000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>24.5</td>\n",
              "      <td>21.498437</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Autumn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2137</td>\n",
              "      <td>1</td>\n",
              "      <td>2052011</td>\n",
              "      <td>41323.0</td>\n",
              "      <td>2</td>\n",
              "      <td>290</td>\n",
              "      <td>18.2</td>\n",
              "      <td>19.157009</td>\n",
              "      <td>2018/3/8</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>26.5</td>\n",
              "      <td>12.100133</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>Spring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20955</td>\n",
              "      <td>2</td>\n",
              "      <td>127993</td>\n",
              "      <td>98111275.0</td>\n",
              "      <td>2</td>\n",
              "      <td>156</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.273954</td>\n",
              "      <td>2016/2/22</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>17.700000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.597478</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Winter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26475</th>\n",
              "      <td>15392</td>\n",
              "      <td>2</td>\n",
              "      <td>2122400</td>\n",
              "      <td>99116273.0</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.756561</td>\n",
              "      <td>2018/5/19</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>31.900000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.146230</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>Spring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26476</th>\n",
              "      <td>25883</td>\n",
              "      <td>2</td>\n",
              "      <td>10837415</td>\n",
              "      <td>99999999.0</td>\n",
              "      <td>1</td>\n",
              "      <td>216</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.847013</td>\n",
              "      <td>2018/10/23</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>24.600000</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.074355</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>Autumn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26477</th>\n",
              "      <td>19848</td>\n",
              "      <td>2</td>\n",
              "      <td>124308</td>\n",
              "      <td>95110546.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>20.4</td>\n",
              "      <td>22.016079</td>\n",
              "      <td>2013/12/29</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>16.200000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.401030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>Winter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26478</th>\n",
              "      <td>3360</td>\n",
              "      <td>1</td>\n",
              "      <td>1051856</td>\n",
              "      <td>96040548.0</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.405935</td>\n",
              "      <td>2015/8/10</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>34.100000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.279941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>Summer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26479</th>\n",
              "      <td>6626</td>\n",
              "      <td>1</td>\n",
              "      <td>96051858</td>\n",
              "      <td>92040133.0</td>\n",
              "      <td>3</td>\n",
              "      <td>321</td>\n",
              "      <td>25.5</td>\n",
              "      <td>24.170444</td>\n",
              "      <td>2013/8/28</td>\n",
              "      <td>70</td>\n",
              "      <td>4</td>\n",
              "      <td>29.100000</td>\n",
              "      <td>33.800000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.861394</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>Summer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26480 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  firm     CowID  ... disease  Sampling D Year  Sampling D Month\n",
              "0      10806     2   3126105  ...     1.0           2016.0            Summer\n",
              "1      10950     2   3126118  ...     0.0           2017.0            Spring\n",
              "2      30007     2   3126179  ...     0.0           2016.0            Autumn\n",
              "3       2137     1   2052011  ...     0.0           2018.0            Spring\n",
              "4      20955     2    127993  ...     0.0           2016.0            Winter\n",
              "...      ...   ...       ...  ...     ...              ...               ...\n",
              "26475  15392     2   2122400  ...     0.0           2018.0            Spring\n",
              "26476  25883     2  10837415  ...     0.0           2018.0            Autumn\n",
              "26477  19848     2    124308  ...     0.0           2013.0            Winter\n",
              "26478   3360     1   1051856  ...     0.0           2015.0            Summer\n",
              "26479   6626     1  96051858  ...     0.0           2013.0            Summer\n",
              "\n",
              "[26480 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GehM5ITtEam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "78f58919-1c89-4415-be6f-a460b148e360"
      },
      "source": [
        "savefornew_train02"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>firm</th>\n",
              "      <th>CowID</th>\n",
              "      <th>MomID</th>\n",
              "      <th>BabyNum</th>\n",
              "      <th>FeedDay</th>\n",
              "      <th>Milk</th>\n",
              "      <th>preMilk</th>\n",
              "      <th>Sampling date</th>\n",
              "      <th>Age</th>\n",
              "      <th>BreedNum</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>T Max</th>\n",
              "      <th>RH</th>\n",
              "      <th>RHMin</th>\n",
              "      <th>Precp</th>\n",
              "      <th>THI</th>\n",
              "      <th>cycle</th>\n",
              "      <th>tcalving number</th>\n",
              "      <th>disease</th>\n",
              "      <th>Sampling D Year</th>\n",
              "      <th>Sampling D Month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10806</td>\n",
              "      <td>2</td>\n",
              "      <td>3126105</td>\n",
              "      <td>116686.0</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.278074</td>\n",
              "      <td>2016/7/26</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>23.967792</td>\n",
              "      <td>27.826169</td>\n",
              "      <td>78.502478</td>\n",
              "      <td>59.891615</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.850519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Summer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10950</td>\n",
              "      <td>2</td>\n",
              "      <td>3126118</td>\n",
              "      <td>116438.0</td>\n",
              "      <td>2</td>\n",
              "      <td>62</td>\n",
              "      <td>43.0</td>\n",
              "      <td>41.734718</td>\n",
              "      <td>2017/4/17</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>34.900000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.093337</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>Spring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30007</td>\n",
              "      <td>2</td>\n",
              "      <td>3126179</td>\n",
              "      <td>99116633.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.850533</td>\n",
              "      <td>2016/11/23</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>23.800000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>24.5</td>\n",
              "      <td>21.498437</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Autumn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2137</td>\n",
              "      <td>1</td>\n",
              "      <td>2052011</td>\n",
              "      <td>41323.0</td>\n",
              "      <td>2</td>\n",
              "      <td>290</td>\n",
              "      <td>18.2</td>\n",
              "      <td>18.646597</td>\n",
              "      <td>2018/3/8</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>26.5</td>\n",
              "      <td>12.100133</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>Spring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20955</td>\n",
              "      <td>2</td>\n",
              "      <td>127993</td>\n",
              "      <td>98111275.0</td>\n",
              "      <td>2</td>\n",
              "      <td>156</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.523809</td>\n",
              "      <td>2016/2/22</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>17.700000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.597478</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Winter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26475</th>\n",
              "      <td>15392</td>\n",
              "      <td>2</td>\n",
              "      <td>2122400</td>\n",
              "      <td>99116273.0</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.306976</td>\n",
              "      <td>2018/5/19</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>31.900000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.146230</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>Spring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26476</th>\n",
              "      <td>25883</td>\n",
              "      <td>2</td>\n",
              "      <td>10837415</td>\n",
              "      <td>99999999.0</td>\n",
              "      <td>1</td>\n",
              "      <td>216</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.393471</td>\n",
              "      <td>2018/10/23</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>24.600000</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.074355</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>Autumn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26477</th>\n",
              "      <td>19848</td>\n",
              "      <td>2</td>\n",
              "      <td>124308</td>\n",
              "      <td>95110546.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.213276</td>\n",
              "      <td>2013/12/29</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>16.200000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.401030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>Winter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26478</th>\n",
              "      <td>3360</td>\n",
              "      <td>1</td>\n",
              "      <td>1051856</td>\n",
              "      <td>96040548.0</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>19.0</td>\n",
              "      <td>21.881302</td>\n",
              "      <td>2015/8/10</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>34.100000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.279941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>Summer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26479</th>\n",
              "      <td>6626</td>\n",
              "      <td>1</td>\n",
              "      <td>96051858</td>\n",
              "      <td>92040133.0</td>\n",
              "      <td>3</td>\n",
              "      <td>321</td>\n",
              "      <td>25.5</td>\n",
              "      <td>25.173195</td>\n",
              "      <td>2013/8/28</td>\n",
              "      <td>70</td>\n",
              "      <td>4</td>\n",
              "      <td>29.100000</td>\n",
              "      <td>33.800000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.861394</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>Summer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26480 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  firm     CowID  ... disease  Sampling D Year  Sampling D Month\n",
              "0      10806     2   3126105  ...     1.0           2016.0            Summer\n",
              "1      10950     2   3126118  ...     0.0           2017.0            Spring\n",
              "2      30007     2   3126179  ...     0.0           2016.0            Autumn\n",
              "3       2137     1   2052011  ...     0.0           2018.0            Spring\n",
              "4      20955     2    127993  ...     0.0           2016.0            Winter\n",
              "...      ...   ...       ...  ...     ...              ...               ...\n",
              "26475  15392     2   2122400  ...     0.0           2018.0            Spring\n",
              "26476  25883     2  10837415  ...     0.0           2018.0            Autumn\n",
              "26477  19848     2    124308  ...     0.0           2013.0            Winter\n",
              "26478   3360     1   1051856  ...     0.0           2015.0            Summer\n",
              "26479   6626     1  96051858  ...     0.0           2013.0            Summer\n",
              "\n",
              "[26480 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEfpNwpMxOVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c4e4f3a5-c3e0-4805-cbb6-6e769de7f90f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_18 (LSTM)               (None, 64)                492288    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 492,353\n",
            "Trainable params: 492,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaQhM5kAziuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#存下做完預處理的train存下做完預處理的train\n",
        "savefornew_train09.to_csv(\"savefornew_train09.csv\",index=False,sep=',')\n",
        "files.download('savefornew_train09.csv')\n",
        "#字典中的key值即為csv中列名\n",
        "savefornew_test09.to_csv(\"savefornew_test09.csv\",index=False,sep=',')\n",
        "files.download('savefornew_train09.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}